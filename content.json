{"meta":{"title":"LoveOps","subtitle":"Devil'Blog","description":"Good Good Study！Day Day Up！","author":"devil","url":"http://blog.loveops.com"},"pages":[{"title":"分类","date":"2017-11-30T09:30:34.000Z","updated":"2017-12-01T14:10:06.073Z","comments":true,"path":"categories/index.html","permalink":"http://blog.loveops.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-11-22T15:01:42.000Z","updated":"2017-11-22T15:04:59.088Z","comments":true,"path":"tags/index.html","permalink":"http://blog.loveops.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Kubernetes集群部署之flannel","slug":"Kubernetes集群部署之flannel","date":"2017-12-28T07:16:14.000Z","updated":"2017-12-28T07:19:31.560Z","comments":true,"path":"2017/12/28/Kubernetes集群部署之flannel/","link":"","permalink":"http://blog.loveops.com/2017/12/28/Kubernetes集群部署之flannel/","excerpt":"","text":"环境介绍 IP地址 系统版本 主机名 角色 172.16.1.2/24 Ubuntu 16.04.2 LTS k8s-master Kubernetes-master/Kubernetes-node/etcd/flannel 172.16.1.6/24 Ubuntu 16.04.2 LTS k8s-node1 Kubernetes-node/etcd/flannel 172.16.1.7/24 Ubuntu 16.04.2 LTS k8s-node2 Kubernetes-node/etcd/flannel 在etcd中设置 flannel节点所使用的IP段 （只需要一个节点执行接口）在上篇文章中，我们已经介绍了etcd集群的搭建。而flannel需要用到etcd，首先我们需要把网络配置放入etcd中：（注意：我们这里虽然etcd版本是3.2.11，但是flannel不支持v3的api，所以需要用v2的api，/coreos.com/network/config是etcd默认存储路径，也可以自己设定） 12345678910111213141516171819root@k8s-node1:~# etcdctl -versionetcdctl version: 3.2.11API version: 2export ENDPOINTS=http://172.16.1.2:2379,http://172.16.1.6:2379,http://172.16.1.7:2379export ETCDCTL_API=2etcdctl --endpoints=$ENDPOINTS set /coreos.com/network/config &lt; config.json config.json内容：&#123; \"Network\": \"10.0.0.0/8\", \"SubnetMin\": \"10.10.0.0\", \"SubnetMax\": \"10.99.0.0\", \"Backend\": &#123; \"Type\": \"vxlan\" &#125;&#125; 123456789root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS get /coreos.com/network/config&#123; \"Network\": \"10.0.0.0/8\", \"SubnetMin\": \"10.10.0.0\", \"SubnetMax\": \"10.99.0.0\", \"Backend\": &#123; \"Type\": \"vxlan\" &#125;&#125; flannel支持不同的backend，一旦设定，在运行时是不能更改的。flannel支持的backend有如下集中，vxlan是官方建议的。 vxlan udp host-gw flannel安装flannel安装比较简单，直接下载相应的版本，然后把二进制和mk-docker-opts.sh两个文件拷贝到PATH变量路径即可。 flannel 版本 12root@k8s-master:~# flanneld -versionv0.9.1 flannel 启动（三个节点都要安装启动，启动命令一样） 1flanneld -etcd-endpoints=\"http://172.16.1.2:2379,http://172.16.1.6:2379,http://172.16.1.7:2379\" -etcd-prefix=/coreos.com/network flannel 启动参数介绍 12345678910111213141516--public-ip =“”：其他节点可以通过IP进行主机间通信。默认为用于通信的接口的IP。--etcd-endpoints = http://127.0.0.1:4001：以逗号分隔的etcd端点列表。--etcd-prefix = /coreos.com/network：etcd前缀。--etcd-keyfile =“”：用于保护etcd通信的SSL密钥文件。--etcd-certfile =“”：用于保护etcd通信的SSL认证文件。--etcd-cafile =“”：用于保护etcd通信的SSL证书颁发机构文件。--kube-subnet-mgr：联系Kubernetes API进行子网分配而不是etcd。--iface = “”：使用（IP或名称）进行主机间通信的接口。默认为机器上默认路由的接口。这可以指定多次，以检查每个选项的顺序。返回找到的第一个匹配项。--iface-regex =“”：正则表达式匹配第一个使用（IP或名字）进行主机间通信的接口。如果未指定，则默认为机器上默认路由的接口。这可以指定多次，以检查每个正则表达式。返回找到的第一个匹配项。此选项被iface选项取代，只有在iface选项中指定的选项没有任何匹配时才会使用该选项。--subnet-file = /run/flannel/subnet.env：filename其中env变量（子网和MTU值）将被写入。--subnet-lease-renew-margin = 60：子网租约更新余量，以分钟为单位。--ip-masq = false：设置目的地为f网络之外的流量的IP伪装。 Flannel假定NAT POSTROUTING链中的默认策略是ACCEPT。-v = 0：V日志的日志级别。设置为1以查看与数据路径相关的消息。--healthz-ip =“0.0.0.0”：healthz服务器侦听的IP地址（默认为“0.0.0.0”）--healthz-port = 0：healthz服务器侦听的端口（0表示禁用）- version：打印版本并退出 修改docker启动参数(三个几点都操作)flannel启动后，会从etcd获取配置信息，然后划分subnet，并在etcd中注册，然后将子网信息写入到/run/flannel/subnet.env 12345root@k8s-node1:~# cat /var/run/flannel/subnet.envFLANNEL_NETWORK=10.0.0.0/8FLANNEL_SUBNET=10.10.40.1/24FLANNEL_MTU=1450FLANNEL_IPMASQ=false 创建docker启动参数： 1234567mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/dockerroot@k8s-node1:~# cat /run/flannel/dockerDOCKER_OPT_BIP=\"--bip=10.10.40.1/24\"DOCKER_OPT_IPMASQ=\"--ip-masq=true\"DOCKER_OPT_MTU=\"--mtu=1450\"DOCKER_NETWORK_OPTIONS=\" --bip=10.10.40.1/24 --ip-masq=true --mtu=1450\" 修改启动参数： 1234567891011121314151617181920212223242526272829303132333435root@k8s-node1:~# cat /lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target docker.socket firewalld.serviceWants=network-online.targetRequires=docker.socket[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd -H fd:// --bip=10.10.40.1/24 --ip-masq=true --mtu=1450ExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=1048576# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.target 重启docker进程： 1234root@k8s-node1:~# systemctl daemon-reloadroot@k8s-node1:~# systemctl restart docker.serviceroot@k8s-node1:~# ps -ef | grep -v grep | grep dockerdroot 6228 1 0 Dec27 ? 00:03:09 /usr/bin/dockerd -H fd:// --bip=10.10.40.1/24 --ip-masq=true --mtu=1450 网络测试上面我们把flannel搭建起来了。现在测试下网络连通性 1234root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS ls /coreos.com/network/subnets/coreos.com/network/subnets/10.10.95.0-24/coreos.com/network/subnets/10.10.50.0-24/coreos.com/network/subnets/10.10.40.0-24 可以看到三台分配的子网，我们可以在主机上直接ping通容器网络。 12345678910111213141516171819202122232425root@k8s-master:~# ping -c 2 10.10.40.2PING 10.10.40.2 (10.10.40.2) 56(84) bytes of data.64 bytes from 10.10.40.2: icmp_seq=1 ttl=63 time=0.699 ms64 bytes from 10.10.40.2: icmp_seq=2 ttl=63 time=0.661 ms--- 10.10.40.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.661/0.680/0.699/0.019 msroot@k8s-master:~# ping -c 2 10.10.50.2PING 10.10.50.2 (10.10.50.2) 56(84) bytes of data.64 bytes from 10.10.50.2: icmp_seq=1 ttl=64 time=0.151 ms64 bytes from 10.10.50.2: icmp_seq=2 ttl=64 time=0.054 ms--- 10.10.50.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 999msrtt min/avg/max/mdev = 0.054/0.102/0.151/0.049 msroot@k8s-master:~# ping -c 2 10.10.95.1PING 10.10.95.1 (10.10.95.1) 56(84) bytes of data.64 bytes from 10.10.95.1: icmp_seq=1 ttl=64 time=0.490 ms64 bytes from 10.10.95.1: icmp_seq=2 ttl=64 time=0.458 ms--- 10.10.95.1 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.458/0.474/0.490/0.016 ms 跨主机容器也是可以，这里不在测试。 flannel实现flannel网络拓扑图如下：(下图是upd是示意图，vxlan基本类似)\b在k8s-master查看路由表，到容器网络10.10.40.0/24 和 10.10.95.0/24 的数据包会发送到flannel.1，flannel.1将数据封装成vxlan，通过网卡eth发送另外主机 12345678root@k8s-master:~# ip rdefault via 172.16.1.1 dev eth010.0.0.0/8 dev flannel.110.10.40.0/24 via 10.10.40.0 dev flannel.1 onlink10.10.50.0/24 dev docker0 proto kernel scope link src 10.10.50.1c via 10.10.95.0 dev flannel.1 onlink172.16.1.0/24 dev eth0 proto kernel scope link src 172.16.1.2172.18.0.0/16 dev docker_gwbridge proto kernel scope link src 172.18.0.1 linkdown flannel网络中容器与外网联通的方式与bridge一样，也是通过nat方式。","categories":[{"name":"docker Kubernetes","slug":"docker-Kubernetes","permalink":"http://blog.loveops.com/categories/docker-Kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/tags/docker/"}]},{"title":"Kubernetes集群部署之etcd","slug":"Kubernetes集群部署之etcd","date":"2017-12-25T11:44:55.000Z","updated":"2017-12-25T11:48:35.498Z","comments":true,"path":"2017/12/25/Kubernetes集群部署之etcd/","link":"","permalink":"http://blog.loveops.com/2017/12/25/Kubernetes集群部署之etcd/","excerpt":"","text":"总体介绍Kubernetes是一个开源平台，旨在自动部署，扩展和运行应用程序容器。 通过Kubernetes，您可以快速高效地响应客户需求： 快速和可预测地部署您的应用程序。 随时扩展您的应用程序。 无缝地推出新功能。 仅限硬件使用情况为所需资源。 我们的目标是建立一个组件和工具的生态系统，减轻在公共和私有云中运行应用程序的负担。 Kubernetes特点： 便携式：公共，私人，混合，多云 可扩展：模块化，可插拔，可挂接，可组合 自我修复：自动放置，自动重启，自动复制，自动缩放 Google在2014年启动了Kubernetes项目.Kubernetes建立在Google大规模运行生产工作量的十五年经验的基础上，结合社区最佳的创意和实践。 从本篇文章开始我们将部署一步一步部署k8s集群。由于k8s的网络我认为是比较复杂的，我们就从网络开始。k8s默认的网络为flannel，那么我们就从flannel开始，由于flannel需要etcd的支持，我们本篇文章就先介绍etcd。 etcd介绍etcd是一个开源的分布式键值存储，提供了一个可靠的方式来存储跨机器集群的数据。 etcd在网络分区时优雅地处理领导选举，并容忍包括领导在内的机器故障。 您的应用程序可以读取和写入数据到etcd。 一个简单的用例是将数据库连接详细信息或功能标志作为关键值对存储在etcd中。 可以监视这些值，允许您的应用在更改时自行重新配置。 环境介绍 IP地址 系统版本 主机名 角色 172.16.1.2/24 Ubuntu 16.04.2 LTS k8s-master Kubernetes-master/Kubernetes-node/etcd/flannel 172.16.1.6/24 Ubuntu 16.04.2 LTS k8s-node1 Kubernetes-node/etcd/flannel 172.16.1.7/24 Ubuntu 16.04.2 LTS k8s-node2 Kubernetes-node/etcd/flannel etcd安装etcd是有go语言编写的，我们直接下载编译好的二进制文件即可，下载解压后有两个二进制文件etcd和etcdctl。把这两个文件放入/usr/local/sbin即可。我们这里采用的版本如下： 12345root@k8s-node1:~# etcd -versionetcd Version: 3.2.11Git SHA: 1e1dbb2Go Version: go1.8.5Go OS/Arch: linux/amd64 启动etcd集群 k8s-master 12345etcd --data-dir=/var/lib/etcd --name etcd_one \\ --initial-advertise-peer-urls http://172.16.1.2:2380 --listen-peer-urls http://172.16.1.2:2380 \\ --advertise-client-urls http://172.16.1.2:2379 --listen-client-urls http://172.16.1.2:2379 \\ --initial-cluster etcd_one=http://172.16.1.2:2380,etcd_two=http://172.16.1.6:2380,etcd_thr=http://172.16.1.7:2380 \\ --initial-cluster-state new --initial-cluster-token test-token k8s-node1 12345etcd --data-dir=/var/lib/etcd --name etcd_two \\ --initial-advertise-peer-urls http://172.16.1.6:2380 --listen-peer-urls http://172.16.1.6:2380 \\ --advertise-client-urls http://172.16.1.6:2379 --listen-client-urls http://172.16.1.6:2379 \\ --initial-cluster etcd_one=http://172.16.1.2:2380,etcd_two=http://172.16.1.6:2380,etcd_thr=http://172.16.1.7:2380 \\ --initial-cluster-state new --initial-cluster-token test-token k8s-node2 12345etcd --data-dir=/var/lib/etcd --name etcd_thr \\ --initial-advertise-peer-urls http://172.16.1.7:2380 --listen-peer-urls http://172.16.1.7:2380 \\ --advertise-client-urls http://172.16.1.7:2379 --listen-client-urls http://172.16.1.7:2379 \\ --initial-cluster etcd_one=http://172.16.1.2:2380,etcd_two=http://172.16.1.6:2380,etcd_thr=http://172.16.1.7:2380 \\ --initial-cluster-state new --initial-cluster-token test-token 注意: –initial-cluster 可以直接指定列表意外，还可以用–discovery具体参考官方文档：https://coreos.com/etcd/docs/latest/op-guide/clustering.html 安装完成后可以验证： 1234567891011root@k8s-master:~# export ETCDCTL_API=3root@k8s-master:~# export ENDPOINTS=172.16.1.2:2379,172.16.1.6:2379,172.16.1.7:2379root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS --write-out=table member list+------------------+---------+----------+------------------------+------------------------+| ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS |+------------------+---------+----------+------------------------+------------------------+| 81555da054c53f2 | started | etcd_one | http://172.16.1.2:2380 | http://172.16.1.2:2379 || d26140195b4d1493 | started | etcd_two | http://172.16.1.6:2380 | http://172.16.1.6:2379 || ffd1352eadf95c93 | started | etcd_two | http://172.16.1.7:2380 | http://172.16.1.7:2379 |+------------------+---------+----------+------------------------+------------------------+ 启动参数说明 -name 12环境变量为： ETCD_NAME 成员的可读名称，默认是default -data-dir 12环境变量为： ETCD_DATA_DIR 数据目录，默认是\"$&#123;name&#125;.etcd\" -wal-dir 123环境变量为： ETCD_WAL_DIR| 专用wal目录的路径。 如果这个标志被设置，etcd会将WAL文件写入walDir而不是dataDir。 这允许使用专用磁盘，并有助于避免记录和其他IO操作之间的竞争。默认是空 –snapshot-count 12环境变量为： ETCD_SNAPSHOT_COUNT 触发快照到磁盘的已提交事务的数量。默认是10000 –heartbeat-interval 12环境变量为：ETCD_HEARTBEAT_INTERVAL心跳间隔的时间（以毫秒为单位）默认是100ms –election-timeout 12环境变量为：ETCD_ELECTION_TIMEOUT选举超时的时间（以毫秒为单位）默认是1000ms –listen-peer-urls 12环境变量为：ETCD_LISTEN_PEER_URLS监听对等流量的URL列表。 这个标志告诉etcd在指定的scheme://IP:port 组合上接受来自其对端的传入请求。 Scheme可以是http或https。如果指定IP为0.0.0.0，则etcd监听所有接口上的给定端口。 如果IP地址和端口一样，etcd将监听给定的端口和接口。 可以使用多个URL来指定要监听的地址和端口的数量。 etcd将响应来自任何列出的地址和端口的请求。默认是http://localhost:2380 | –listen-client-urls 12环境变量为：ETCD_LISTEN_CLIENT_URLS要监听客户端流量的URL列表。 该标志告诉etcd接受来自指定方案的客户端的传入请求：scheme//IP:port。 Scheme可以是http或https。 如果指定IP为0.0.0.0，则etcd监听所有接口上的给定端口。 如果IP地址和端口一样，etcd将监听给定的端口和接口。 可以使用多个URL来指定要监听的地址和端口的数量。 etcd将响应来自任何列出的地址和端口的请求。默认是http://localhost:2379 –max-snapshots 12环境变量为：ETCD_MAX_SNAPSHOTS保留的最大快照文件数量（0无限制）默认是5 –max-wals 12环境变量为：ETCD_MAX_WALS要保留的最大wal文件数（0是无限的）默认是5 –cors 12环境变量为： ETCD_CORS 用逗号分隔的CORS起源白名单（跨源资源共享）。默认是none –initial-advertise-peer-urls 12环境变量为： ETCD_INITIAL_ADVERTISE_PEER_URLS 此成员的对等URL列表以通告给群集的其余部分。 这些地址用于在集群周围传送etcd数据。 至少有一个必须可路由到所有集群成员。 这些URL可以包含域名。默认是http://localhost:2380 –initial-cluster 12环境变量为： ETCD_INITIAL_CLUSTER 引导的初始群集配置。默认是default=http://localhost:2380 –initial-cluster-state 12环境变量为： ETCD_INITIAL_CLUSTER_STATE 初始群集状态（“new”或“existing”）。 在初始静态或DNS引导过程中为所有成员设置为new。 如果此选项设置为existing，etcd将尝试加入现有的集群。 如果设置了错误的值，etcd将尝试启动，但安全失败。默认是new –initial-cluster-token 12环境变量为：TCD_INITIAL_CLUSTER_TOKEN 在引导期间，etcd集群的初始集群令牌。默认是etcd-cluster –advertise-client-urls 12环境变量为：ETCD_ADVERTISE_CLIENT_URLS 此成员的客户端URL列表，以通告给群集的其余部分。 这些URL可以包含域名，默认是http://localhost:2379 –discovery 12环境变量为：ETCD_DISCOVERY 用于引导群集的发现URL。默认是none –discovery-srv 12环境变量为：ETCD_DISCOVERY_SRV用于引导群集的DNS srv域。默认是none –discovery-fallback 12环境变量为： ETCD_DISCOVERY_FALLBACK发现服务失败时的预期行为（“exit”或“proxy”）。 \"proxy\"仅支持v2 API。默认是proxy –discovery-proxy 12环境变量为：ETCD_DISCOVERY_PROXY 用于流量发现服务的HTTP代理。默认是none –strict-reconfig-check 12环境变量为：ETCD_STRICT_RECONFIG_CHECK拒绝会导致法定人数丢失的重新配置请求。默认是false –enable-v2 12环境变量为：ETCD_ENABLE_V2 接受etcd V2客户端的请求，默认是true –auto-compaction-retention 12环境变量为： ETCD_AUTO_COMPACTION_RETENTION 自动压缩保留mvcc键值存储在小时内。 0意味着禁用自动压缩。默认是0 etcd使用用户主要通过putting 或getting key来与etcd进行交互。 本节介绍如何通过使用etcdctl（一个用于与etcd服务器交互的命令行工具）来完成此操作。 这里描述的概念应该适用于gRPC API或客户端库API。 默认情况下，etcdctl会与v2 API与etcd服务器通信以实现向后兼容。 对于etcdctl使用v3 API与etcd对话，API版本必须通过ETCDCTL_API环境变量设置为版本3。 查看版本 12345678root@k8s-master:~# etcdctl versionetcdctl version: 3.2.11API version: 3.2root@k8s-master:~# etcd -versionetcd Version: 3.2.11Git SHA: 1e1dbb2Go Version: go1.8.5Go OS/Arch: linux/amd64 写入key应用程序通过写入key、value存储到etcd集群中。 每个存储的key通过Raft协议复制到所有etcd集群成员，以实现一致性和可靠性。 12root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS put foo barOK 读取key 123root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS get foofoobar 123root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS get foo --hex #格式化为16进制\\x66\\x6f\\x6f\\x62\\x61\\x72 12root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS get foo --print-value-only #只显示valuebar 删除key 12root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS del foo1 1234root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS del --prev-kv foo #删除并显示key、value1foobar 实时监控key的变化 1234root@k8s-master:~# etcdctl --endpoints=$ENDPOINTS watch foo #在另外窗口执行了put操作PUTfoobar 以上是一一些简单的使用，详细请参考官方文档： https://coreos.com/etcd/docs/latest/dev-guide/interacting_v3.html","categories":[{"name":"docker Kubernetes","slug":"docker-Kubernetes","permalink":"http://blog.loveops.com/categories/docker-Kubernetes/"}],"tags":[{"name":"etcd","slug":"etcd","permalink":"http://blog.loveops.com/tags/etcd/"}]},{"title":"docker容器网络三之vxlan","slug":"docker容器网络三之vxlan","date":"2017-12-21T05:26:51.000Z","updated":"2017-12-21T09:44:31.574Z","comments":true,"path":"2017/12/21/docker容器网络三之vxlan/","link":"","permalink":"http://blog.loveops.com/2017/12/21/docker容器网络三之vxlan/","excerpt":"","text":"介绍在上篇文章中，我们已经看到了Docker如何为\boverlay网络创建一个专用的namespace，并将这些容器连接到这个namespace。 我们也看到，Docker主机之间的overlay通信使用VXLAN。 在这篇文章中，我们将详细介绍VXLAN以及Docker如何使用它。 什么是vxlan维基百科：1虚拟局域网扩展（Virtual Extensible LAN, VXLAN）是一种网络虚拟化技术，它试图改善大云计算部署相关的可扩展性问题. XLAN是一种隧道技术，它将L2帧封装在UDP包内,通常在端口4789上。它最初是由VMware，Arista和Cisco开发的。 VXLAN的主要目标是简化在L2层需要多租户的云部署。 它提供： 在L3上隧道化L2以避免集群中所有主机之间的L2连接的必要性 超过4096个隔离网络（VLAN ID限制为4096）在Linux上，Openvswitch支持VXLAN，并且从3.7版本开始，内核就具有原生支持。 另外，VXLAN自内核3.16起使用网络命名空间。下面是VXLAN包的示意图：\b “outer”ip packet用户主机之间的通信，原始的L2 frame 和 VXLAN header元数据（特别是VXLAN ID）封装在一个udp packet中. 我们可以用tcpdump验证主机之间的流量是否使用了vxlan， 我们从docker1上的容器ping C0，并捕获docker0上的流量：12345678910111213docker1:~$ docker run -it --rm --net demonet debian ping 192.168.0.100PING 192.168.0.100 (192.168.0.100): 56 data bytes64 bytes from 192.168.0.100: icmp_seq=0 ttl=64 time=0.680 ms64 bytes from 192.168.0.100: icmp_seq=1 ttl=64 time=0.503 msdocker0:~$ sudo tcpdump -pni eth0 \"port 4789\"tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes12:55:53.652322 IP 10.0.0.11.64667 &gt; 10.0.0.10.4789: VXLAN, flags [I] (0x08), vni 256IP 192.168.0.2 &gt; 192.168.0.100: ICMP echo request, id 1, seq 0, length 6412:55:53.652409 IP 10.0.0.10.47697 &gt; 10.0.0.11.4789: VXLAN, flags [I] (0x08), vni 256IP 192.168.0.100 &gt; 192.168.0.2: ICMP echo reply, id 1, seq 0, length 64 每个数据包在tcpdump中生成两行输出，因为由于VXLAN帧分析（为了便于阅读，有些字段已被删除）：“outer”frame ip是10.0.0.11 和 10.0.0.10 （docker hosts）“inner”frame ip是192.168.0.100 and 192.168.0.2（容器），还有icmp的正常包，我们也能看到容器的mac地址。\b 解决容器名称和位置我们已经看到，我们可以使用VXLAN从docker1上的容器ping docker0上的容器，但我们还不知道每个主机上的容器如何将IP地址映射到MAC地址以及L2帧如何转发到相应的主机。我们在docker1上创建一个容器并查看它的ARP表：12docker1:~$ docker run -it --rm --net demonet debian bashroot@6234b23677b9:/# ip neighbor show 容器内没有ARP信息。 如果我们ping C0，容器将产生ARP流量。 我们先来看看在docker0的overlay命名空间中如何看到这个流量：1docker0:~$ sudo nsenter --net=$overns tcpdump -pni any \"arp\" 回到我们的容器，我们将尝试ping C0，这将产生一个ARP数据包：1root@6234b23677b9:/# ping 192.168.0.100 docker0上的tcpdump中没有任何内容，所以ARP流量不会在VXLAN隧道中发送（您可能会看到ARP请求，但是没有主机192.168.0.100的）。 让我们在docker1的overlay命名空间中创建一个容器，用tcpdump验证我们是否正在收到ARP查询。1docker1:~$ docker run -it --rm --net demonet debian bash 让我们在另一个窗口中运行tcpdump。 我们列出Docker网络名称空间，以标识与叠加层关联的名称空间。 这个命名空间可能会改变，因为当没有容器连接到网络时，覆盖命名空间被删除。12345docker1:~$ sudo ls -1 /var/run/docker/netns102022d57fabx-13fb802253docker1:~$ overns=/var/run/docker/netns/x-13fb802253docker1:~$ sudo nsenter --net=$overns tcpdump -peni any \"arp\" 当我们用容器从窗口ping时，这里是我们在tcpdump中看到的：123419:16:40.658369 Out 02:42:c0:a8:00:02 ethertype ARP (0x0806), length 44: Request who-has 192.168.0.100 tell 192.168.0.2, length 2819:16:40.658352 B 02:42:c0:a8:00:02 ethertype ARP (0x0806), length 44: Request who-has 192.168.0.100 tell 192.168.0.2, length 2819:16:40.658371 In 02:42:c0:a8:00:64 ethertype ARP (0x0806), length 44: Reply 192.168.0.100 is-at 02:42:c0:a8:00:64, length 2819:16:40.658377 Out 02:42:c0:a8:00:64 ethertype ARP (0x0806), length 44: Reply 192.168.0.100 is-at 02:42:c0:a8:00:64, length 28 我们可以看到ARP查询和应答，这意味着overlay命名空间有信息，并且它充当ARP代理。 我们可以轻松验证这一点：12docker1:~$ sudo nsenter --net=$overns ip neigh show192.168.0.100 dev vxlan0 lladdr 02:42:c0:a8:00:64 PERMANENT 该条目被标记为PERMANENT，这意味着它是静态的并且是“手动”添加的，而不是ARP发现的结果。 如果我们在docker0上创建第二个容器会发生什么？12345docker0:~$ docker run -d --ip 192.168.0.200 --net demonet --name C1 debian sleep 3600docker1:~$ sudo nsenter --net=$overns ip neigh show192.168.0.200 dev vxlan0 lladdr 02:42:c0:a8:00:c8 PERMANENT192.168.0.100 dev vxlan0 lladdr 02:42:c0:a8:00:64 PERMANENT 该条目已被自动添加，即使没有流量发送到这个新的容器呢。 这意味着Docker会自动填充覆盖命名空间中的ARP条目，并且vxlan接口将充当代理来回答ARP查询。 如果我们看一下vxlan接口的配置，我们可以看到它具有代理标志集，这解释了这种行为（我们稍后会看到其他选项）。 12345docker1:~$ sudo nsenter --net=$overns ip -d link show vxlan0xx: vxlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master br0 state UNKNOWN mode DEFAULT group default link/ether 5a:71:8f:a4:b8:1b brd ff:ff:ff:ff:ff:ff promiscuity 1 vxlan id 256 srcport 10240 65535 dstport 4789 proxy l2miss l3miss ageing 300 bridge_slav MAC地址的位置（主机是02:42:c0:a8:00:64）呢？ 我们可以看看overlay命名空间中的桥接转发数据库：1234567docker1:~$ sudo nsenter --net=$overns bridge fdb show5a:71:8f:a4:b8:1b dev vxlan0 vlan 0 master br0 permanent9a:ad:35:64:39:39 dev veth2 vlan 0 master br0 permanent02:42:c0:a8:00:c8 dev vxlan0 dst 10.0.0.10 self permanent02:42:c0:a8:00:64 dev vxlan0 dst 10.0.0.10 self permanent33:33:00:00:00:01 dev veth2 self permanent01:00:5e:00:00:01 dev veth2 self permanent 我们可以看到docker0上的两个容器的MAC地址在数据库中有一个永久标志。 这个信息也是由Docker动态填充的。\b MAC/FDB信息的分配我们刚刚发现Docker会自动填充MAC和FDB信息。 这是怎么做的？我们可以先看看consul的内容。 那里存储了什么？现在我们刚开始的时候空的网络包含了信息，我们可以识别overlay的ID：13fb802253b6f0a44e17e2b65505490e0c80527e1d78c4f5c74375aff4bf882a.Consul用户界面太长时不显示键值，但我们可以用curl来查看内容（Docker将信息存储为基于64位编码的JSON，Consul用JSON来回答查询）：1234567891011121314151617181920212223242526net=$(docker network inspect demonet -f &#123;&#123;.Id&#125;&#125;)curl -s http://consul:8500/v1/kv/docker/network/v1.0/network/$&#123;net&#125;/ | jq -r \".[0].Value\" | base64 -d | jq .&#123; \"addrSpace\": \"GlobalDefault\", \"attachable\": false, \"created\": \"2017-04-23T16:33:02.442759329Z\", \"enableIPv6\": false, \"generic\": &#123; \"com.docker.network.enable_ipv6\": false, \"com.docker.network.generic\": &#123;&#125; &#125;, \"id\": \"13fb802253b6f0a44e17e2b65505490e0c80527e1d78c4f5c74375aff4bf882a\", \"inDelete\": false, \"ingress\": false, \"internal\": false, \"ipamOptions\": &#123;&#125;, \"ipamType\": \"default\", \"ipamV4Config\": \"[&#123;\\\"PreferredPool\\\":\\\"192.168.0.0/24\\\",\\\"SubPool\\\":\\\"\\\",\\\"Gateway\\\":\\\"\\\",\\\"AuxAddresses\\\":null&#125;]\", \"ipamV4Info\": \"[&#123;\\\"IPAMData\\\":\\\"&#123;\\\\\\\"AddressSpace\\\\\\\":\\\\\\\"GlobalDefault\\\\\\\",\\\\\\\"Gateway\\\\\\\":\\\\\\\"192.168.0.1/24\\\\\\\",\\\\\\\"Pool\\\\\\\":\\\\\\\"192.168.0.0/24\\\\\\\"&#125;\\\",\\\"PoolID\\\":\\\"GlobalDefault/192.168.0.0/24\\\"&#125;]\", \"labels\": &#123;&#125;, \"name\": \"demonet\", \"networkType\": \"overlay\", \"persist\": true, \"postIPv6\": false, \"scope\": \"global\"&#125; 我们可以在我们的网络上找到所有的元数据： name：demonet id：13fb802253b6f0a44e17e2b65505490e0c80527e1d78c4f5c74375aff4bf882a subnet：192.168.0.0/24 我们也可以检索关于端点的信息，但curl查询很难读取，所以我们将使用这个小的python脚本（https://github.com/lbernail/dockeroverlays） 来检索这些信息：1234567891011121314151617import consulimport json# First we connect to consulc=consul.Consul(host=\"consul\",port=8500)# We retrieve all endpoint keys from Consul(idx,endpoints)=c.kv.get(\"docker/network/v1.0/endpoint/\",recurse=True)epdata=[ ep['Value'] for ep in endpoints if ep['Value'] is not None]# We print some interesting data on these endpointsfor data in epdata: jsondata=json.loads(data.decode(\"utf-8\")) print(\"Endpoint Name: %s\" % jsondata[\"name\"]) print(\"IP address: %s\" % jsondata[\"ep_iface\"][\"addr\"]) print(\"MAC address: %s\" % jsondata[\"ep_iface\"][\"mac\"]) print(\"Locator: %s\\n\" % jsondata[\"locator\"]) 脚本显示容器端点上的主要信息： name IP address MAC address Locator：容器所在的主机 以下是输出结果：12345678910docker1:~$ python/dump_endpoints.pyEndpoint Name: adoring_einsteinIP address: 192.168.0.2/24MAC address: 02:42:c0:a8:00:02Locator: 10.0.0.11Endpoint Name: C1IP address: 192.168.0.200/24MAC address: 02:42:c0:a8:00:c8Locator: 10.0.0.10 Consul被用作所有静态信息的参考存储。 但是，创建容器时动态通知所有主机是不够的。 事实证明，Docker使用Serf和Gossip协议来实现这一点。 我们可以通过订阅docker0上的serf事件来轻松验证这一点，并在docker1上创建一个容器：1234567docker0:~$ serf agent -bind 0.0.0.0:17946 -join 10.0.0.11:7946 -node demo -log-level=debug -event-handler=./serf.sh#########################################New event: member-joindemo 10.0.0.10docker0 10.0.0.10docker1 10.0.0.11######################################### 我删除了大部分输出以关注相关信息：我们可以看到所有参与Gossip的节点。Serf选项解释如下： bind：绑定一个不同于7946的端口（已经被Docker使用） join：to join the serf cluster node：为节点指定一个备用名（docker0已经被占用） event-handler：一个简单的脚本来显示serf事件 log-level = debug：需要查看事件处理程序脚本的输出 serf.sh脚本具有以下内容：123echo \"New event: $&#123;SERF_EVENT&#125;\"while read line; do printf \"$&#123;line&#125;\\n\" 现在让我们在docker 1上创建一个容器并查看docker0上的输出：1docker1:~$ docker run -it --rm --net demonet debian sleep 10 在docker0 我们可以看到：12New event: userjoin 192.168.0.2 255.255.255.0 02:42:c0:a8:00:02 然后在10秒钟之后当容器在docker1上退出：12New event: userleave 192.168.0.2 255.255.255.0 02:42:c0:a8:00:02 Docker守护程序订阅这些事件来创建和删除ARP和FDB表中的条目。 在Swarm模式下，Docker不依赖Serf来同步节点之间的信息，而是依靠自己的Gossip协议实现。 它实现了完全一样的事情。 备用解决选项Docker守护程序根据通过Serf通过Gossip协议接收到的信息自动填充ARP和FDB表，并依靠VLXAN接口进行ARP代理。 但是，VXLAN还为我们提供了其他发现选项。 点对点方式当VXLAN配置了“remote”选项时，它将所有未知流量发送到这个IP，这个设置非常简单，但是仅限于两台主机之间的隧道。 多播方式当VXLAN配置了“group”选项时，它将所有未知流量发送到这个组播组，这个设置非常高效，但是需要所有主机之间的组播连接，这在使用公共云时并不总是可行的。 有关Linux上VXLAN配置的更多详细信息，我推荐这个非常完整的文章： https://vincent.bernat.im/en/blog/2017-vxlan-linux \b原文： http://techblog.d2-si.eu/2017/05/09/deep-dive-into-docker-overlay-networks-part-2.html","categories":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/tags/docker/"},{"name":"网络","slug":"网络","permalink":"http://blog.loveops.com/tags/网络/"}]},{"title":"docker容器网络二之overlay","slug":"docker容器网络二之overlay","date":"2017-12-20T08:32:21.000Z","updated":"2017-12-21T05:19:22.193Z","comments":true,"path":"2017/12/20/docker容器网络二之overlay/","link":"","permalink":"http://blog.loveops.com/2017/12/20/docker容器网络二之overlay/","excerpt":"","text":"\b介绍在上一篇docker网络一中，介绍了docker单主机的几种网络模式，这篇文章将介绍跨主机网络overlay，这个是docker原生的跨主机网络模型。docker的overlay网络依以下技术：namespace、VXLAN、Netlink和分布式键值存储。这篇文章将介绍这些组件怎么联动，从而\b组成docker的\boverlay网络。 \bDocker Overlay Networks\b首先，我们将在Docker主机之间构建一个overlay网络。 在我们的例子中，我们将使用三个主机来执行此操作：两个正在运行的Docker和一个正在运行的Consul。 Docker将使用Consul来存储需要由所有Docker引擎共享的overlay网络元数据：容器IP，MAC地址和位置。 在Docker 1.12之前，Docker需要一个外部键值存储（Etcd或Consul）来创建overlay和Docker Swarms（现在通常被称为“classicSwarm”）。 从Docker 1.12开始，Docker现在可以依靠一个内置的Key-Value存储来创建Swarms和overlay（“Swarm mode”或“new swarm”）。 我们选择使用Consul是因为它允许我们查看Docker存储的密钥并更好地理解Key-Value存储的角色。 我们在单个节点上运行Consul，但是在真实的环境中，我们需要一个至少有三个节点的集群来提供弹性。在我们的示例中，服务器将具有以下IP地址： consul: 10.0.0.5 docker0: 10.0.0.10 docker1: 10.0.0.0.11 启动Consul和\bDocker我们需要做的第一件事是启动一个Consul服务器。 要做到这一点，我们只需从consul官网下载Consul。 然后我们可以用下面的命令启动一个非常小的Consul服务：1$ consul agent -server -dev -ui -client 0.0.0.0 我们使用以下参数： server：以服务器模式启动代理服务器 dev：创建一个没有任何持久性的独立Consul服务器 ui：启动一个小型web界面，使我们可以轻松查看Docker存储的密钥及其值 client 0.0.0.0：绑定客户端访问的所有网络接口（默认为127.0.0.1） 要将Docker引擎配置为使用Consul作为Key-Value存储，我们使用cluster-store选项启动守护进程：123456789101112131415161718192021222324252627282930313233343536$ systemctl cat docker.service# /lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target docker.socket firewalld.serviceWants=network-online.targetRequires=docker.socket[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd -H fd:// --cluster-store=consul://10.0.0.5:8500 --cluster-advertise=eth0:2376ExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=1048576# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.target cluster-advertise选项指定在集群中为docker主机通告哪个IP（此选项不是可选的）。 这个命令假定consul在我们的例子中解析为10.0.0.5。 如果我们看一下Consul UI，我们可以看到Docker创建了一些keys，但是网络keys: http://consul:8500/v1/kv/docker/network/v1.0/network/ 仍然是空的。 创建\b一个overlay现在我们可以在两个主机之间创建一个overlay网络。12docker0:~$ docker network create --driver overlay --subnet 192.168.0.0/24 demonet13fb802253b6f0a44e17e2b65505490e0c80527e1d78c4f5c74375aff4bf882a 我们使用overlay驱动程序，并选择192.168.0.0/24作为overlay的子网（该参数是可选的，但我们希望地址与主机上的地址非常不同，以简化分析）。接着就可以坚持两个主机网络中都有我们创建的overlay网络1234567891011121314docker0:~$ docker network lsNETWORK ID NAME DRIVER SCOPEeb096cb816c0 bridge bridge local13fb802253b6 demonet overlay globald538d58b17e7 host host localf2ee470bb968 none null localdocker1:~$ docker network lsdocker network lsNETWORK ID NAME DRIVER SCOPEeb7a05eba815 bridge bridge local13fb802253b6 demonet overlay global4346f6c422b2 host host local5e8ac997ecfa none null local 这看起来不错：两个Docker节点都知道demonet网络，并且在两台主机上都有相同的id（13fb802253b6）。 现在让我们通过在docker0上创建一个容器并试图从docker1 ping它来检查我们的覆盖是如何工作的。 在docker0上，我们创建一个C0容器，将它附加到我们的overlay网络，明确地给它一个IP地址（192.168.0.100），并让它sleep。 在docker1上，我们创建了一个连接到overlay的容器，并运行一个以C0为目标的ping命令。1234567docker0:~$ docker run -d --ip 192.168.0.100 --net demonet --name C0 debian sleep 3600docker1:~$ docker run -it --rm --net demonet debian bashroot@e37bf5e35f83:/# ping 192.168.0.100PING 192.168.0.100 (192.168.0.100): 56 data bytes64 bytes from 192.168.0.100: icmp_seq=0 ttl=64 time=0.618 ms64 bytes from 192.168.0.100: icmp_seq=1 ttl=64 time=0.483 ms 我们可以看到两个容器之间的连接是可以的。 如果我们试图从docker1 ping C0，它不起作用，因为docker1不知道关于192.168.0.0/24的任何东西，这个192.168.0.0/24被隔离在overlay中。1234docker1:~$ ping 192.168.0.100PING 192.168.0.100 (192.168.0.100) 56(84) bytes of data.^C--- 192.168.0.100 ping statistics ---4 packets transmitted, 0 received, 100% packet loss, time 3024ms 目前我们的拓扑结构是这样的： 更深层次的研究 现在我们已经构建了一个overlay网络，让我们试着看看它是如何工作的。 容器的网络配置docker0上C0的网络配置是什么？ 我们可以进入容器找出：12345678910111213docker0:~$ docker exec C0 ip addr show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever6: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default link/ether 02:42:c0:a8:00:64 brd ff:ff:ff:ff:ff:ff inet 192.168.0.100/24 scope global eth0 valid_lft forever preferred_lft forever9: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff inet 172.18.0.2/16 scope global eth1 valid_lft forever preferred_lft forever 我们有两个接口（和环回）在容器中： eth0：使用192.168.0.0/24范围内的IP进行配置。 这个接口是我们覆overlay的。 eth1：配置为172.18.0.2/16范围内的IP，我们没有\b并没有配置 路由配置:1234docker0:~$ docker exec C0 ip route showdefault via 172.18.0.1 dev eth1172.18.0.0/16 dev eth1 proto kernel scope link src 172.18.0.2192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.100 路由配置表明默认路由是通过eth1，这意味着这个接口可以用来访问overlay之外的资源。 我们可以通过ping外部IP地址来轻松验证。 1234$ docker exec -it C0 ping 8.8.8.8PING 8.8.8.8 (8.8.8.8): 56 data bytes64 bytes from 8.8.8.8: icmp_seq=0 ttl=51 time=0.957 ms64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=0.975 ms 请注意，可以使用–internal参数创建一个overlay，使容器无法访问外部网络。 让我们看看我们是否可以在这些接口上获得更多的信息：123456789docker0:~$ docker exec C0 ip -details link show eth06: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:c0:a8:00:64 brd ff:ff:ff:ff:ff:ff promiscuity 0 vethdocker0:~$ docker exec C0 ip -details link show eth19: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff promiscuity 0 veth 两个接口的类型都是veth。 veth接口总是与虚拟线路连接。 这两个对等的veth可以在不同的网络命名空间中，这允许流量从一个命名空间移动到另一个命名空间。 这两个veth用于获取容器网络命名空间的外部。如下图所示：我们现在需要确定与每个veth对接的接口。 容器是链向了哪里我们可以使用ethtool命令来确定veth的另一端。 但是这个命令在我们的容器中不可用。 我们可以使用“nsenter”在我们的容器中执行这个命令，它允许我们输入一个或多个与进程相关的命名空间，或者使用“ip netns exec”，依靠iproute在给定的网络命名空间中执行一个命令。 Docker不在/var/run/netns目录中创建符号链接，这是ip netns正在寻找网络命名空间的地方。 这就是为什么我们会依赖nsenter来创建由Docker创建的名称空间的原因。要列出由Docker创建的网络名称空间，我们可以简单地运行：123docker0:~$ sudo ls -1 /var/run/docker/netnse4b8ecb7ae7c1-13fb802253 要使用这些信息，我们需要识别容器的网络名称空间。 我们可以通过检查他们来实现这一点，并从SandboxKey中提取我们需要的东西：123docker0:~$ docker inspect C0 -f &#123;&#123;.NetworkSettings.SandboxKey&#125;&#125; /var/run/docker/netns/e4b8ecb7ae7cdocker0:~$ C0netns=$(docker inspect C0 -f &#123;&#123;.NetworkSettings.SandboxKey&#125;&#125;) 我们也可以在容器的网络命名空间内执行主机命令（即使这个容器没有命令）：12345docker0:~$ sudo nsenter --net=$C0netns ip addr show eth06: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default link/ether 02:42:c0:a8:00:64 brd ff:ff:ff:ff:ff:ff inet 192.168.0.100/24 scope global eth0 valid_lft forever preferred_lft forever 我们来看看与eth0和eth1的对等体相关的接口索引是什么：123456docker0:~$ sudo nsenter --net=$C0netns ethtool -S eth0NIC statistics: peer_ifindex: 7docker0:~$ sudo nsenter --net=$C0netns ethtool -S eth1NIC statistics: peer_ifindex: 10 我们现在正在寻找索引7和10的接口。我们可以先看看主机本身：123456789101112131415docker0:~$ ip -details link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 02: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 9001 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 06:e2:c0:20:ec:9f brd ff:ff:ff:ff:ff:ff promiscuity 03: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default link/ether 02:42:a7:17:99:39 brd ff:ff:ff:ff:ff:ff promiscuity 0 bridge8: docker_gwbridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:be:d6:b0:c5 brd ff:ff:ff:ff:ff:ff promiscuity 0 bridge10: vethbc521fc: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker_gwbridge state UP mode DEFAULT group default link/ether 32:a1:47:1a:7f:1e brd ff:ff:ff:ff:ff:ff promiscuity 1 veth bridge_slave 从这个输出我们可以看到，我们没有接口7的踪迹，但是我们已经找到接口10，即eth1的对等体。 另外，这个接口被插在一个名为“docker_gwbridge”的桥上。 这座桥是什么？ 如果我们列出由docker管理的网络，我们可以看到它出现在列表中：1234567docker0:~$ docker network lsNETWORK ID NAME DRIVER SCOPEeb096cb816c0 bridge bridge local13fb802253b6 demonet overlay globalf6823b311fd2 docker_gwbridge bridge locald538d58b17e7 host host localf2ee470bb968 none null local 进一步查看：123456789101112131415161718docker0:~$ docker inspect docker_gwbridge\"Name\": \"docker_gwbridge\",\"Driver\": \"bridge\",\"IPAM\": &#123; \"Driver\": \"default\", \"Options\": null, \"Config\": [ &#123; \"Subnet\": \"172.18.0.0/16\", \"Gateway\": \"172.18.0.1\" &#125; ]&#125;,\"Options\": &#123; \"com.docker.network.bridge.enable_icc\": \"false\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.name\": \"docker_gwbridge\" &#125; 我删除了输出的一部分，以关注重要的信息： 该网络使用网桥（与标准的docker0一样） 它使用子网172.18.0.0/16，与eth1一致 enable_icc被设置为false，这意味着我们不能使用这个桥进行集装箱间通信 enable_ip_masquerade设置为true，这意味着来自容器的流量将被NAT到访问外部网络（我们之前在成功调用8.8.8.8时看到的） 我们可以通过尝试从附加到demonet的docker0的另一个容器的eth1地址（172.18.0.2）ping C0来验证集装箱间通信是否被禁用：1234docker0:~$ docker run --rm -it --net demonet debian ping 172.18.0.2PING 172.18.0.2 (172.18.0.2): 56 data bytes^C--- 172.18.0.2 ping statistics ---3 packets transmitted, 0 packets received, 100% packet loss 现在更新拓扑： 那么eth0是否就是链接\b到overlay网络呢？与eth0对等的接口不在主机网络名称空间中。 它必须在另一个。 如果我们再看网络命名空间：123docker0:~$ sudo ls -1 /var/run/docker/netnse4b8ecb7ae7c1-13fb802253 我们可以看到名为“1-13fb802253”的名称空间。 除了“1-”之外，这个命名空间的名称是我们覆盖网络的网络ID的开始：12docker0:~$ docker network inspect demonet -f &#123;&#123;.Id&#125;&#125;13fb802253b6f0a44e17e2b65505490e0c80527e1d78c4f5c74375aff4bf882a 这个命名空间显然与我们的overlay有关。 我们可以看看这个名字空间中的接口： 12345678910111213docker0:~$ overns=/var/run/docker/netns/1-13fb802253docker0:~$ sudo nsenter --net=$overns ip -d link show2: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default link/ether 3a:2d:44:c0:0e:aa brd ff:ff:ff:ff:ff:ff promiscuity 0 bridge5: vxlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master br0 state UNKNOWN mode DEFAULT group default link/ether 4a:23:72:a3:fc:e3 brd ff:ff:ff:ff:ff:ff promiscuity 1 vxlan id 256 srcport 10240 65535 dstport 4789 proxy l2miss l3miss ageing 300 bridge_slave7: veth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master br0 state UP mode DEFAULT group default link/ether 3a:2d:44:c0:0e:aa brd ff:ff:ff:ff:ff:ff promiscuity 1 veth bridge_slave 覆盖网络命名空间包含三个接口（和lo）： br0：网桥 veth2：一个veth接口，它是我们容器中eth0的对等接口，并连接到网桥 vxlan0：也连接到网桥的“vxlan”类型的接口 vxlan接口显然是“overlay magic ”发生的地方，我们将详细看看它，让我们先更新我们的图表： 原文： http://techblog.d2-si.eu/2017/04/25/deep-dive-into-docker-overlay-networks-part-1.html","categories":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/tags/docker/"},{"name":"网络","slug":"网络","permalink":"http://blog.loveops.com/tags/网络/"}]},{"title":"docker容器网络一","slug":"docker容器网络一","date":"2017-12-19T05:50:31.000Z","updated":"2017-12-21T05:20:21.461Z","comments":true,"path":"2017/12/19/docker容器网络一/","link":"","permalink":"http://blog.loveops.com/2017/12/19/docker容器网络一/","excerpt":"","text":"docker网络docker安装以后默认就有4中网络模式，可以用docker network ls 查看： 12345$ docker network lsNETWORK ID NAME DRIVER SCOPEdb6d3a70094b bridge bridge local7a65f6e2654e host host local34e659778a9d none null local 你会发现查看就有三种。另外一种称为container模式，这个待会儿再说。 四种网络方式的实现方式 host 在这个模式下，docker 不会为容器创建单独的网络 namespace，而是共享主机的 network namespace，也就是说：容器可以直接访问主机上所有的网络信息。既然是共享主机的网络，端口也是共享的，所以容器和主机的端口是不能冲突的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354主机网络$ ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 52:54:b9:09:ff:bd brd ff:ff:ff:ff:ff:ff inet 172.16.1.2/24 brd 172.16.1.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::5054:b9ff:fe09:ffbd/64 scope link valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:fb:c9:10:09 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:fbff:fec9:1009/64 scope link valid_lft forever preferred_lft forever10: docker_gwbridge: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:42:26:36:68 brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 scope global docker_gwbridge valid_lft forever preferred_lft forever inet6 fe80::42:42ff:fe26:3668/64 scope link valid_lft forever preferred_lft forever docker网络 $ docker run -it --net=host busybox/ # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000 link/ether 52:54:b9:09:ff:bd brd ff:ff:ff:ff:ff:ff inet 172.16.1.2/24 brd 172.16.1.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::5054:b9ff:fe09:ffbd/64 scope link valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue link/ether 02:42:fb:c9:10:09 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:fbff:fec9:1009/64 scope link valid_lft forever preferred_lft forever10: docker_gwbridge: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue link/ether 02:42:42:26:36:68 brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 scope global docker_gwbridge valid_lft forever preferred_lft forever inet6 fe80::42:42ff:fe26:3668/64 scope link valid_lft forever preferred_lft forever none 在这种模式下，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信，只有一个会换网卡地址。需要我们自己为Docker容器添加网卡、配置IP等。 123456$ docker run -it --net=none busybox/ # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever container 这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。 12345678910111213141516171819202122232425262728293031创建box1root@k8s-master:~# docker run -it -d --name box1 busybox3a7663f170aa6d5ce67e221b1e015a89fcd24b4968c92ddc33875799ee777902创建box2，并用container网络链接box1root@k8s-master:~# docker run -it -d --name box2 --net=container:box1 busybox06d4c317f5b099c89c99024fee1d0b691d1d5e586d29a3e81c3150783bdabff5查看两个容器网络，会发现他们的网络是一样的，公用namespace$ docker exec box1 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever17: eth0@if18: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 scope global eth0 valid_lft forever preferred_lft forever $ docker exec box2 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever17: eth0@if18: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 scope global eth0 valid_lft forever preferred_lft forever bridge bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到一个虚拟网桥上。docker安装时，默认会创建一个brdge网络，名称为docker0. 12345678910111213141516171819202122232425262728293031323334353637383940414243查看bridge，interfaces是空的$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.024230bab5b8 no深入bridge网络。$ docker inspect bridge[ &#123; \"Name\": \"bridge\", \"Id\": \"02419aedaf4b936f85bb836d6ff3c3b34f1cb62a8e41f613e33c406343b329c5\", \"Created\": \"2017-12-18T11:26:43.870068868+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": &#123; \"Driver\": \"default\", \"Options\": null, \"Config\": [ &#123; \"Subnet\": \"172.17.0.0/16\" &#125; ] &#125;, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": &#123; \"Network\": \"\" &#125;, \"ConfigOnly\": false, \"Containers\": &#123;&#125;, \"Options\": &#123; \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" &#125;, \"Labels\": &#123;&#125; &#125;] 现在启动两个容器，看下bridge的变化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182两个容器已经启动$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES51c530237bf6 busybox \"sh\" 3 seconds ago Up 3 seconds stupefied_swartz1a0a3148c086 busybox \"sh\" 7 seconds ago Up 6 seconds condescending_lalande查看bridge，已经有两个interface，正是两个容器的网络接入$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.024230bab5b8 no veth688fdfd veth7a1077a 深入查看，可以看到容器的IP地址等。root@k8s-node1:~# docker inspect bridge[ &#123; \"Name\": \"bridge\", \"Id\": \"02419aedaf4b936f85bb836d6ff3c3b34f1cb62a8e41f613e33c406343b329c5\", \"Created\": \"2017-12-18T11:26:43.870068868+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": &#123; \"Driver\": \"default\", \"Options\": null, \"Config\": [ &#123; \"Subnet\": \"172.17.0.0/16\" &#125; ] &#125;, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": &#123; \"Network\": \"\" &#125;, \"ConfigOnly\": false, \"Containers\": &#123; \"1a0a3148c0864d19e7f0e6cdba8f00c40dc6726ba2df6c80d62b95eae814ef34\": &#123; \"Name\": \"condescending_lalande\", \"EndpointID\": \"ba380b01c2f9ec4de630e695a79c66a24f3aaddc3de6fd3e225d1d4a5134355e\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" &#125;, \"51c530237bf6bd9fbc806f2396b2c636074ec86be7b106971b58ef4ea71d261b\": &#123; \"Name\": \"stupefied_swartz\", \"EndpointID\": \"82e72c785f0b3f5feaca08baab071582c4dda475beb3d07eb9a632d7893200f2\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" &#125; &#125;, \"Options\": &#123; \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" &#125;, \"Labels\": &#123;&#125; &#125;]查看容器的路由，会发现默认网关都是172.17.0.1,这个地址正式docker0的地址。$ docker exec stupefied_swartz ip routedefault via 172.17.0.1 dev eth0172.17.0.0/16 dev eth0 scope link src 172.17.0.3查看docker0的ip地址。$ ifconfig docker0docker0 Link encap:Ethernet HWaddr 02:42:30:ba:b5:b8 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:30ff:feba:b5b8/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:648 (648.0 B) 网络拓扑从上图可以发现: docker0就是一个虚拟交换机 每个容器都会和主机创建一对儿虚拟网卡veth pair，一端就是docker的eth0，另一端就是容器的eth0网卡。 bridge网络内部是可以通信的，当然通过设置也能组织通信 docker网卡后面的数字是指与主机网卡的对应的编号，例如：（就是前面的 7，这样就能发现对于关系） 12347: veth7a1077a@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 46:a7:aa:ef:27:59 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::44a7:aaff:feef:2759/64 scope link valid_lft forever preferred_lft forever 访问外网 上面的拓扑关系说明了容器与主机是怎么通信的。那么是怎么访问外网的呢? 其实很简单，就是通过iptables。 123Chain POSTROUTING (policy ACCEPT 145 packets, 13093 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 这条规则会将源地址为172.17.0.0/16的包（也就是从Docker容器产生的包），并且不是从docker0网卡发出的，进行源地址转换，转换成主机网卡的地址。 同样的，外部访问容器的服务，也是通过iptables的DNAT映射。 1234567891011121314151617181920212223$ docker run -it -d -p80:80 busybox3e64200eb3a78a91797ce8b108576285dd0e962bd19244e6099f8203acdb33f9root@k8s-node1:~# iptables -t nat -L -n -vChain PREROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 7 424 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destinationChain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 !127.0.0.0/8 ADDRTYPE match dst-type LOCALChain POSTROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 0 0 MASQUERADE tcp -- * * 172.17.0.4 172.17.0.4 tcp dpt:80Chain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.4:80 参考：http://www.infoq.com/cn/articles/docker-network-and-pipework-open-source-explanation-practice","categories":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/tags/docker/"},{"name":"网络","slug":"网络","permalink":"http://blog.loveops.com/tags/网络/"}]},{"title":"sysbench测试磁盘IO","slug":"sysbench测试磁盘IO","date":"2017-12-08T14:53:39.000Z","updated":"2017-12-08T15:21:41.996Z","comments":true,"path":"2017/12/08/sysbench测试磁盘IO/","link":"","permalink":"http://blog.loveops.com/2017/12/08/sysbench测试磁盘IO/","excerpt":"","text":"前面已经介绍了sysbench的参数，本文介绍使用sysbench测试磁盘io环境介绍： 系统：ubuntu16.04 （青云虚拟机） 内存：16G cpu : 8核心 sysbench版本：1.0.10 fileio的基本参数：1234567891011121314151617$ sysbench fileio helpsysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)fileio options: --file-num=N 创建文件数量，默认 [128] --file-block-size=N 测试使用块儿大小，默认 [16384] --file-total-size=SIZE 测试使用文件总大小，默认 [2G] --file-test-mode=STRING 测试模式 &#123;seqwr（顺序写））, seqrewr（顺序读写）, seqrd（顺序读）, rndrd（随机读）, rndwr（随机写）, rndrw(随机读写)&#125; --file-io-mode=STRING 文件操操纵模式 &#123;sync（同步）,async（异步）,mmap（快速map映射））&#125;默认 [sync] --file-async-backlog=N number of asynchronous operatons to queue per thread [128] --file-extra-flags=STRING 使用额外的标志符来打开文件 &#123;sync,dsync,direct&#125; [] --file-fsync-freq=N 在完成N次请求之后，执行fsync()，0表示不使用fsync，默认值：100。 --file-fsync-all[=on|off] 每次写操作后执行fsync()，默认值：off --file-fsync-end[=on|off] 测试结束后执行fsync()，默认值：on。 --file-fsync-mode=STRING 使用fsync或fdatasync方法进行同步，默认值：fsync。 --file-merged-requests=N m尽可能的合并N个IO请求数，0表示不合并，默认值：0。 --file-rw-ratio=N 测试时候的读写比例，默认值：1.5(即3:2)。 测试分为三个阶段 准备（prepare),为测试准备数据 12345678910111213141516171819$ sysbench fileio --file-total-size=8G --file-num=8 preparesysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)Removing test files...root@i-byqycf1n:/fileios# sysbench fileio --file-total-size=8G --file-num=8 preparesysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)8 files, 1048576Kb each, 8192Mb totalCreating files for the test...Extra file open flags: 0Creating file test_file.0Creating file test_file.1Creating file test_file.2Creating file test_file.3Creating file test_file.4Creating file test_file.5Creating file test_file.6Creating file test_file.78589934592 bytes written in 77.55 seconds (105.63 MiB/sec). 测试（run） 随机读写 123456789101112131415161718192021222324252627282930313233343536373839404142434445$ sysbench fileio --file-total-size=8G --file-num=8 --file-test-mode=rndrw --time=1800 --file-rw-ratio=1 --threads=16 runsysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 16Initializing random number generator from current timeExtra file open flags: 08 files, 1GiB each8GiB total file sizeBlock size 16KiBNumber of IO requests: 0Read/Write ratio for combined random IO test: 1.00Periodic FSYNC enabled, calling fsync() each 100 requests.Calling fsync() at the end of test, Enabled.Using synchronous I/O modeDoing random r/w testInitializing worker threads...Threads started!File operations: reads/s: 2000.70 writes/s: 2000.70 fsyncs/s: 320.11Throughput: read, MiB/s: 31.26 written, MiB/s: 31.26General statistics: total time: 1800.0141s total number of events: 7778808Latency (ms): min: 0.00 avg: 3.70 max: 465.40 95th percentile: 9.56 sum: 28782042.44Threads fairness: events (avg/stddev): 486175.5000/1821.33 execution time (avg/stddev): 1798.8777/0.02 顺序读写 12345678910111213141516171819202122232425262728293031323334353637383940414243$ sysbench fileio --file-total-size=8G --file-num=8 --file-test-mode=seqrewr --time=600 --file-rw-ratio=1 --threads=16 runsysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 16Initializing random number generator from current timeExtra file open flags: 08 files, 1GiB each8GiB total file sizeBlock size 16KiBPeriodic FSYNC enabled, calling fsync() each 100 requests.Calling fsync() at the end of test, Enabled.Using synchronous I/O modeDoing sequential rewrite testInitializing worker threads...Threads started!File operations: reads/s: 0.00 writes/s: 8186.76 fsyncs/s: 654.93Throughput: read, MiB/s: 0.00 written, MiB/s: 127.92General statistics: total time: 600.1619s total number of events: 5306467Latency (ms): min: 0.00 avg: 1.81 max: 277.45 95th percentile: 0.75 sum: 9597820.52Threads fairness: events (avg/stddev): 331654.1875/4172.73 execution time (avg/stddev): 599.8638/0.01 顺序写 12345678910111213141516171819202122232425262728293031323334353637383940414243$ sysbench fileio --file-total-size=8G --file-num=8 --file-test-mode=seqwr --time=600 --file-rw-ratio=1 --threads=16 runsysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 16Initializing random number generator from current timeExtra file open flags: 08 files, 1GiB each8GiB total file sizeBlock size 16KiBPeriodic FSYNC enabled, calling fsync() each 100 requests.Calling fsync() at the end of test, Enabled.Using synchronous I/O modeDoing sequential write (creation) testInitializing worker threads...Threads started!File operations: reads/s: 0.00 writes/s: 8186.37 fsyncs/s: 654.90Throughput: read, MiB/s: 0.00 written, MiB/s: 127.91General statistics: total time: 600.1297s total number of events: 5305927Latency (ms): min: 0.00 avg: 1.81 max: 306.93 95th percentile: 0.78 sum: 9597135.97Threads fairness: events (avg/stddev): 331620.4375/5134.81 execution time (avg/stddev): 599.8210/0.01 顺序读 12345678910111213141516171819202122232425262728293031323334353637383940414243$ sysbench fileio --file-total-size=8G --file-num=8 --file-test-mode=seqrd --time=600 --file-rw-ratio=1 --threads=16 runsysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 16Initializing random number generator from current timeExtra file open flags: 08 files, 1GiB each8GiB total file sizeBlock size 16KiBPeriodic FSYNC enabled, calling fsync() each 100 requests.Calling fsync() at the end of test, Enabled.Using synchronous I/O modeDoing sequential read testInitializing worker threads...Threads started!File operations: reads/s: 724368.39 writes/s: 0.00 fsyncs/s: 0.00Throughput: read, MiB/s: 11318.26 written, MiB/s: 0.00General statistics: total time: 600.0003s total number of events: 434622830Latency (ms): min: 0.00 avg: 0.02 max: 20.95 95th percentile: 0.03 sum: 6794650.94Threads fairness: events (avg/stddev): 27163926.8750/1054351.39 execution time (avg/stddev): 424.6657/2.57 清理测试数据（cleanup） 1234$ sysbench fileio --file-total-size=8G --file-num=8 cleanupsysbench 1.0.10 (using bundled LuaJIT 2.1.0-beta2)Removing test files...","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"sysbench","slug":"sysbench","permalink":"http://blog.loveops.com/tags/sysbench/"}]},{"title":"Logstash处理nginx日志grok配置","slug":"Logstash处理nginx日志grok配置","date":"2017-12-07T14:08:47.000Z","updated":"2017-12-08T06:17:32.978Z","comments":true,"path":"2017/12/07/Logstash处理nginx日志grok配置/","link":"","permalink":"http://blog.loveops.com/2017/12/07/Logstash处理nginx日志grok配置/","excerpt":"","text":"nginx日志配置123456log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\"'; access_log /usr/local/var/log/nginx/host.access.log main; logstash配置12345678910111213141516171819202122input &#123; file &#123; path =&gt; \"/usr/local/var/log/nginx/host.access.log\" &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; \"message\" =&gt; \"%&#123;IPV4:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] \\\"%&#123;WORD:method&#125; %&#123;NOTSPACE:verb&#125; HTTP/%&#123;NUMBER:httpversion&#125;\\\" %&#123;NUMBER:response&#125; %&#123;NUMBER:bytes&#125; %&#123;QS:referrer&#125; %&#123;QS:agent&#125;\" &#125; remove_field =&gt; [\"message\"] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [\"127.0.0.1:9200\"] index =&gt; \"nginx-access\" user =&gt; \"elastic\" password =&gt; \"changeme\" &#125;&#125; logstash标准输出123456789101112131415161718192021222324252627282930313233343536&#123; \"agent\" =&gt; \"\\\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36\\\"\", \"geoip\" =&gt; &#123; \"timezone\" =&gt; \"Asia/Tokyo\", \"ip\" =&gt; \"139.162.114.70\", \"latitude\" =&gt; 35.6427, \"continent_code\" =&gt; \"AS\", \"city_name\" =&gt; \"Tokyo\", \"country_name\" =&gt; \"Japan\", \"country_code2\" =&gt; \"JP\", \"country_code3\" =&gt; \"JP\", \"region_name\" =&gt; \"Tokyo\", \"location\" =&gt; &#123; \"lon\" =&gt; 139.7677, \"lat\" =&gt; 35.6427 &#125;, \"postal_code\" =&gt; \"100-0001\", \"region_code\" =&gt; \"13\", \"longitude\" =&gt; 139.7677 &#125;, \"method\" =&gt; \"GET\", \"auth\" =&gt; \"-\", \"ident\" =&gt; \"-\", \"verb\" =&gt; \"/\", \"read_timestamp\" =&gt; \"2017-12-07T02:10:42.947Z\", \"path\" =&gt; \"/usr/local/var/log/nginx/host.access.log\", \"referrer\" =&gt; \"\\\"http://118.193.143.23:80/\\\"\", \"@timestamp\" =&gt; 2017-12-07T02:10:42.947Z, \"response\" =&gt; \"200\", \"bytes\" =&gt; \"56733\", \"@version\" =&gt; \"1\", \"host\" =&gt; \"hanjh-MacBook-Pro.local\", \"client_ip\" =&gt; \"139.162.114.70\", \"httpversion\" =&gt; \"1.1\", \"timestamp\" =&gt; \"07/Dec/2017:07:46:51 +0800\"&#125; 说明：\bgeoip对127.0.0.1匹配不到，测试的时候可以找个\b公网ip，echo到日志文件中。","categories":[{"name":"elk","slug":"elk","permalink":"http://blog.loveops.com/categories/elk/"}],"tags":[{"name":"logstash","slug":"logstash","permalink":"http://blog.loveops.com/tags/logstash/"}]},{"title":"Python 抓取系统CPU负责和内存信息","slug":"Python-抓取系统CPU负责和内存信息","date":"2017-12-01T15:03:57.000Z","updated":"2017-12-01T15:06:40.508Z","comments":true,"path":"2017/12/01/Python-抓取系统CPU负责和内存信息/","link":"","permalink":"http://blog.loveops.com/2017/12/01/Python-抓取系统CPU负责和内存信息/","excerpt":"","text":"CPU负载1234567891011121314151617#!/usr/bin/pythonimport os f = open('/proc/loadavg')l = f.read().split()f.close() dic = &#123;&#125;def load_stat(): dic[\"lavg_1\"]=l[0] dic[\"lavg_5\"]=l[1] dic[\"lavg_15\"]=l[2] dic[\"nr\"]=l[3] dic[\"last_pid\"]=l[4] return dic print \"loadavg\",load_stat()[\"lavg_15\"] 内存信息123456789101112131415161718192021#!/usr/bin/env Python from __future__ import print_functionfrom collections import OrderedDict def meminfo(): ''' Return the information in /proc/meminfo as a dictionary ''' meminfo=OrderedDict() with open('/proc/meminfo') as f: for line in f: meminfo[line.split(':')[0]] = line.split(':')[1].strip() return meminfo if __name__=='__main__': #print(meminfo()) meminfo = meminfo() print('Total memory: &#123;0&#125;'.format(meminfo['MemTotal'])) print('Free memory: &#123;0&#125;'.format(meminfo['MemFree']))","categories":[{"name":"监控","slug":"监控","permalink":"http://blog.loveops.com/categories/监控/"}],"tags":[{"name":"linux python","slug":"linux-python","permalink":"http://blog.loveops.com/tags/linux-python/"}]},{"title":"配置php和nginx环境","slug":"配置php和nginx环境","date":"2017-12-01T15:00:27.000Z","updated":"2017-12-09T15:01:37.974Z","comments":true,"path":"2017/12/01/配置php和nginx环境/","link":"","permalink":"http://blog.loveops.com/2017/12/01/配置php和nginx环境/","excerpt":"","text":"环境介绍 系统版本： ubuntu 16.04 64bit php版本： 7.0.26 nginx版本：nginx/1.10.3 安装环境依赖1apt install gcc libxml2-dev nginx make -y 编译安装php12345tar zxvf php-7.0.26.tar.gzcd ../php-7.0.26./configure --enable-fpm --with-mysqlmakesudo make install 配置php为系统服务拷贝服务脚本到系统服务目录1cp /root/php-7.0.26/sapi/fpm/php-fpm.service /lib/systemd/system/ 查看系统脚本信息1234567891011121314$ systemctl cat php-fpm.service# /lib/systemd/system/php-fpm.service[Unit]Description=The PHP FastCGI Process ManagerAfter=network.target[Service]Type=simplePIDFile=/usr/local/var/run/php-fpm.pidExecStart=/usr/local/sbin/php-fpm --nodaemonize --fpm-config /usr/local/etc/php-fpm.confExecReload=/bin/kill -USR2 $MAINPID[Install]WantedBy=multi-user.target 拷贝配置文件1234$ pwd/usr/local/etc$ cp php-fpm.conf.default php-fpm.conf$ cp php-fpm.d/www.conf.default php-fpm.d/www.conf 修改配置文件12345678$ pwd/usr/local/etcvim php-fpm.confinclude=etc/php-fpm.d/*.conf ##修改最后一行vim php-fpm.d/www.confuser = www-datagroup = www-data ##修改用户和用户组 加载php系统服务并启动1234567891011121314$ systemctl daemon-reload$ systemctl start php-fpm.service$ systemctl status php-fpm.service● php-fpm.service - The PHP FastCGI Process Manager Loaded: loaded (/lib/systemd/system/php-fpm.service; disabled; vendor preset: enabled) Active: active (running) since Sat 2017-12-09 22:04:09 CST; 36min ago Main PID: 27197 (php-fpm) CGroup: /system.slice/php-fpm.service ├─27197 php-fpm: master process (/usr/local/etc/php-fpm.conf) ├─27199 php-fpm: pool www └─27200 php-fpm: pool wwwDec 09 22:04:09 i-byqycf1n systemd[1]: Started The PHP FastCGI Process Manager.Dec 09 22:40:24 i-byqycf1n systemd[1]: Started The PHP FastCGI Process Manager. 修改nginx配置文件12345678910111213141516vim /etc/nginx/sites-available/defaultlocation ~ \\.php$ &#123; include snippets/fastcgi-php.conf; # # # With php7.0-cgi alone: fastcgi_pass 127.0.0.1:9000; # # With php7.0-fpm: # fastcgi_pass unix:/run/php/php7.0-fpm.sock; &#125;$ nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful$ nginx -s reload 创建php测试文件1echo \"&lt;?php phpinfo(); ?&gt;\" &gt;&gt; /var/www/html/index.php 访问php测试文件1curl 127.0.0.1/index.php","categories":[{"name":"web","slug":"web","permalink":"http://blog.loveops.com/categories/web/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.loveops.com/tags/php/"}]},{"title":"nginx监控指标","slug":"nginx监控指标","date":"2017-12-01T14:54:40.000Z","updated":"2017-12-01T14:59:21.996Z","comments":true,"path":"2017/12/01/nginx监控指标/","link":"","permalink":"http://blog.loveops.com/2017/12/01/nginx监控指标/","excerpt":"","text":"nginx自带有个state\b监控页面，以下是监控指标。 指标 说明 类型 nginx.inx.conn.active 当前连接数 数值 nginx.conn.reading 正在读的连接数 数值 nginx.conn.waiting 空闲连接数 数值 nginx.conn.writing 正在写的连接数 数值 nginx.req.accept 已接受请求数 计数器 nginx.req.handled 已处理请求数 计数器 nginx.req.total 请求总数 计数器","categories":[{"name":"监控","slug":"监控","permalink":"http://blog.loveops.com/categories/监控/"}],"tags":[{"name":"nginx linux","slug":"nginx-linux","permalink":"http://blog.loveops.com/tags/nginx-linux/"}]},{"title":"git钩子实现hexo博客自动部署","slug":"git钩子实现hexo博客自动部署","date":"2017-11-29T14:17:30.000Z","updated":"2017-12-01T14:02:21.000Z","comments":true,"path":"2017/11/29/git钩子实现hexo博客自动部署/","link":"","permalink":"http://blog.loveops.com/2017/11/29/git钩子实现hexo博客自动部署/","excerpt":"","text":"最近用hexo搭建了博客，刚开始用了github page，后面用了一台云主机。并用git钩子实现了自动部署，以下是步骤：环境主备 云主机：Ubuntu16.04 git nginx mac（本地主机）hexo 环境 云主机配置 安装环境 123456789101112131415161718192021222324252627281、apt install nginx git -y2、配置nginxroot@blog:~# cat /etc/nginx/sites-available/defaultserver &#123; listen 80; server_name blog.loveops.org; rewrite ^/(.*)$ https://blog.loveops.org/$1 permanent;&#125;server &#123; listen 443 ssl; server_name blog.loveops.org ; charset utf8; #access_log /var/log/nginx/log/host.access.log main; ssl on; ssl_certificate /etc/letsencrypt/live/blog.loveops.org/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/blog.loveops.org/privkey.pem; # managed by Certbot ssl_ciphers 'ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4'; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_session_timeout 5m; root /opt/blog/; index index.html;&#125; git配置 1234567891011121314151617181920211、生成一个本地空仓库cd /optgit init --bare blog.git2、配置钩子，生成孔仓库后，在/opt/blog.git/hooks下有很多hooks模板文件，新建一个post-receive，并添加执行权限。root@blog:/opt/blog.git/hooks# cat post-receive#!/bin/shunset GIT_DIRcd /opt/bloggit pull origin master3、克隆仓库cd /optgit clone ./blog.git/root@blog:/opt# ls ##执行后opt文件夹如下blog blog.git Mac（本地笔记本配置） 1234567891011121314151、首先配置笔记本到云主机的免密钥登录ssh-keygen -t rsassh-copy-id -i .ssh/id_rsa.pub root@blog.loveops.org2、hexo部署，官方文档说的很清楚，这里不在详说3、修改hexo配置文件，修改git地址如下：➜ loveops git:(master) ✗ tail -n 4 _config.ymldeploy: type: git repo: root@blog.loveops.org:/opt/blog.git branch: master hexo提交 123现在在mac上编辑markdown文件后，执行一下命令，云主机的blog直接就更新了。hexo generate &amp;&amp; hexo deploy 提示 还可以把hexo文件保存到远端仓库，以后更换笔记本也无所谓","categories":[{"name":"git","slug":"git","permalink":"http://blog.loveops.com/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.loveops.com/tags/git/"}]},{"title":"Let's Encrypt生成免费的SSL证书","slug":"Let-s-Encrypt生成免费的SSL证书","date":"2017-11-29T05:36:20.000Z","updated":"2017-12-01T14:08:21.187Z","comments":true,"path":"2017/11/29/Let-s-Encrypt生成免费的SSL证书/","link":"","permalink":"http://blog.loveops.com/2017/11/29/Let-s-Encrypt生成免费的SSL证书/","excerpt":"","text":"Let’s Encrypt介绍：Let’s Encrypt是一个免费的自动的开发的证书颁发机构，为公众利益儿运行，是一个服务互联网安全研究小组提供。官方网站：https://letsencrypt.org/ CertbotCertbot是Let’s Encrypt官方推荐的获取证书的客户端，可以帮我们获取免费的Let’s Encrypt 证书。更多关于CertBot可以访问官方网站：https://certbot.eff.org 环境介绍服务器： Ubuntu16.04webserver： nginx 环境准备1234567891、安装nginx，这里不在介绍，直接apt安装就行2、安装Cerbot，如果是其他系统或者是webserver可以直接访问 https://certbot.eff.org/ 然后选择自己的系统和webservre软件，就可以直接查看安装文档。$ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update$ sudo apt-get install python-certbot-nginx 获取证书1234567891011121314151617执行一下命令，按照提示，一步一步来就行，有一点要注意，服务器的443端口要能访问，并且没被占用。certbot --nginx 这条命令certbot会直接在nginx配置文件添加ssl配置：ssl_certificate /etc/letsencrypt/live/blog.loveops.org/fullchain.pem; # managed by Certbotssl_certificate_key /etc/letsencrypt/live/blog.loveops.org/privkey.pem; # managed by Certbot如果你不想让certbot直接操作配置文件，可以执行以下配置文件：certbot --nginx certonly这条命令会在以下文件夹/etc/letsencrypt/live/blog.loveops.org/生成证书文件root@blog:~# ls /etc/letsencrypt/live/blog.loveops.org/cert.pem chain.pem fullchain.pem privkey.pem README 证书自动更新Let’s Encrypt 提供的证书只有90天的有效期，我们必须在证书到期之前，重新获取这些证书，certbot 给我们提供了一个很方便的命令，那就是 certbot renew。通过这个命令，他会自动检查系统内的证书，并且自动更新这些证书。我们可以运行这个命令测试一下： 1certbot renew --dry-run 如果以上命令没有问题，可以写个 crontab计划任务。 1certbot renew --pre-hook \"service nginx stop\" --post-hook \"service nginx start\"","categories":[{"name":"http","slug":"http","permalink":"http://blog.loveops.com/categories/http/"}],"tags":[{"name":"SSL","slug":"SSL","permalink":"http://blog.loveops.com/tags/SSL/"}]},{"title":"ElasticSearch-Index和Type的区别","slug":"ElasticSearch-Index和Type的区别","date":"2017-11-27T13:34:27.000Z","updated":"2017-12-21T05:20:21.484Z","comments":true,"path":"2017/11/27/ElasticSearch-Index和Type的区别/","link":"","permalink":"http://blog.loveops.com/2017/11/27/ElasticSearch-Index和Type的区别/","excerpt":"","text":"对于 ES 的新用户来说，有一个常见的问题：要存储一批新的数据时，应该在已有 index 里新建一个 type，还是给它新建一个index？要想回答这个问题，我们必须先理解这两者是怎么实现的。过去，我们为了让 ES更容易理解，经常用关系型数据库做一个比喻： index 就像关系型数据库里的 database, type 就像 database 里的 table。但是这并不正确。由于两种数据库存储数据的方式是如此不同，任何比喻都是没有意义的。这种比喻往往会导致对 type 的滥用。 Index 是什么Index 存储在多个分片中，其中每一个分片都是一个独立的 Lucene Index。这就应该能提醒你，添加新 index 应该有个限度：每个 Lucene Index 都需要消耗一些磁盘，内存和文件描述符。因此，一个大的 index 比多个小 index 效率更高：Lucene Index 的固定开销被摊分到更多文档上了。 另一个重要因素是你准备怎么搜索你的数据。在搜索时，每个分片都需要搜索一次， 然后 ES 会合并来自所有分片的结果。例如，你要搜索 10 个 index，每个 index 有 5 个分片，那么协调这次搜索的节点就需要合并 5x10=50 个分片的结果。这也是一个你需要注意的地方：如果有太多分片的结果需要合并，或者你发起了一个结果巨大的搜索请求，合并任务会需要大量 CPU 和内存资源。这是第二个让 index 少一些的理由。 Type 是什么使用 type 允许我们在一个 index 里存储多种类型的数据，这样就可以减少 index 的数量了。在使用时，向每个文档加入 _type 字段，在指定 type 搜索时就会被用于过滤。使用 type 的一个好处是，搜索一个 index 下的多个 type，和只搜索一个 type 相比没有额外的开销 —— 需要合并结果的分片数量是一样的。 但是，这也是有限制的： 不同 type 里的字段需要保持一致。例如，一个 index 下的不同 type 里有两个名字相同的字段，他们的类型（string, date 等等）和配置也必须相同。 只在某个 type 里存在的字段，在其他没有该字段的 type 中也会消耗资源。这是 Lucene Index 带来的常见问题：它不喜欢稀疏。由于连续文档之间的差异太大，稀疏的 posting list 的压缩效率不高。这个问题在 doc value 上更为严重：为了提高速度，doc value 通常会为每个文档预留一个固定大小的空间，以便文档可以被高速检索。这意味着，如果 Lucene 确定它需要一个字节来存储某个数字类型的字段，它同样会给没有这个字段的文档预留一个字节。未来版本的 ES 会在这方面做一些改进，但是我仍然建议你在建模的时候尽量避免稀疏。[1] 得分是由 index 内的统计数据来决定的。也就是说，一个 type 中的文档会影响另一个 type 中的文档的得分。这意味着，只有同一个 index 的中的 type 都有类似的映射 (mapping) 时，才应该使用 type。否则，使用多个 type 可能比使用多个 index 消耗的资源更多。 我应该用哪个这是个困难的问题，它的答案取决于你用的硬件、数据和用例。首先你要明白 type 是有用的，因为它能减少 ES 需要管理的 Lucene Index 的数量。但是也有另外一种方式可以减少这个数量：创建 index 的时候让它的分片少一些。例如，与其在一个 index 里塞上 5 个 type，不如创建 5 个只有一个分片的 index。 在你做决定的时候可以问自己下面几个问题： 你需要使用父子文档吗？如果需要，只能在一个 index 里建立多个 type。 你的文档的映射是否相似？如果不相似，使用多个 index。 如果你的每个 type 都有足够多的文档，Lucene Index 的开销可以被分摊掉，你就可以安全的使用多个 index 了。如果有必要的话，可以把分片数量设小一点。 如果文档不够多，你可以考虑把文档放进一个 index 里的多个 type 里，甚至放进一个 type 里。 总之，你可能有点惊讶，因为 type的使用场景没有你想象的多，这是正确的。由于我们上面提到原因，在一个 index 中使用多个 type 的情景其实很少。如果你的数据有不同的映射，那就给他们分配不同的 index。但是请记住，如果不需要很高的写入吞吐量，或者存储的文档数量不多，你可以通过减少 index 的分片来使集群中的分片数量保持合理。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://blog.loveops.com/categories/ELK/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://blog.loveops.com/tags/elasticsearch/"},{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/tags/linux/"}]},{"title":"IP命令集","slug":"IP命令集","date":"2017-11-22T03:45:47.000Z","updated":"2017-12-22T03:46:51.256Z","comments":true,"path":"2017/11/22/IP命令集/","link":"","permalink":"http://blog.loveops.com/2017/11/22/IP命令集/","excerpt":"","text":"介绍linux的ip命令和ifconfig类似，但前者功能更强大，并旨在取代后者。使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。ifconfig是net-tools中已被废弃使用的一个命令，许多年前就已经没有维护了。iproute2套件里提供了许多增强功能的命令，ip命令即是其中之一。 IP查询命令 addr 显示ip地址和属性信息（address的缩写） 123ip addr 显示所有地址信息ip addr show dev eth0 只显示eth0的信息 link 管理和显示所有网络接口的状态 12345ip link 显示所有接口的信息ip link show dev eth0 只显示eth0的信息ip -s link 显示接口统计 route 显示和修改路由表 1ip route 列出内核中所有的路由条目 maddr 管理和显示多播地址 123ip maddr 显示所有接口的多播地址ip maddr show dev eth0 只显示eth0的多播地址 neigh 显示邻居对象，也就是ipv4的arp表 123ip neigh 显示邻居对象ip neigh show dev eth0 显示eth0的邻居对象 help 显示子命令和字命令参数的帮助信息 1234567ip help 显示ip子命令和参数的帮助信息ip addr help 显示 addr 子命令的帮助信息ip link help 显示 link 子命令的帮助信息ip neigh help 显示 neigh 子命令的帮助信息 多播地址管理 maddr add 添加静态链路层多播地址 1ip maddr add 33:33:00:00:00:01 dev eth0 maddr del 删除一个多播地址 1ip maddr del 33:33:00:00:00:01 dev eth0 修改地址和链接属性 addr add 添加一个地址 1ip addr add 192.168.1.1/24 dev eth0 #在eth0上添加192.168.1.1掩码24位的地址 addr del 删除一个地址 1ip addr del 192.168.1.1/24 dev eth0 #从eth0上删除192.168.1.1掩码24位的地址 link set 修改接口状态 1234567ip link set eth0 up #开启eth0ip link set eth0 down #关闭eth0 ip link set eth0 mtu 9000 #设置eth0的mtu为9000ip link ser eth0 promisc on #开启eth0的混杂模式 调整和查看路由表 route add #添加一条路由表条目 12345ip route add default via 192.168.1.1 dev eth0 #在接口eth0上添加默认网关192.168.1.1ip route add 192.168.1.0/24 via 192.168.1.1 #为192.168.0.0/24的地址添加默认网关192.168.1.1ip route add 192.168.1.0/24 dev eth0 #添加访问192.168.1.0/24 可以从eth0接口出去 route delete #删除一条路由条目 1ip route delete 192.168.1.0/24 via 192.168.1.1 route replace #替换路由条目，如果没有定义就添加 1ip route replace 192.168.1.0/24 dev eth0 route get #显示一个地址将要走的路由 1ip route get 192.168.1.5 #显示192.168.1.5将走的路由 管理arp表 neigh add #向arp表添加一条arp条目 1ip neigh add 192.168.1.1 lladdr 1:2:3:4:5:6 dev eth0 neigh del #使arp条目失效 1ip neigh del 192.168.1.1 dev eth0 neigh replace #替换arp条目，如果不存在就添加 1ip neigh replace 192.168.1.1 lladdr 1:2:3:4:5:6 dev eth0 有用的命令（不一定来自iproute） arping #向邻居发送arp请求 123arping -I eth0 192.168.1.1 # 通过eth0向192.168.1.1发送arp请求arping -D -I eth0 192.168.1.1 #在eth0 上检查192.168.1.1重复的mac地址 ethtool #查询或控制网络驱动程序和硬件设置 1234ethtool -g eth0 #显示eth0的环形缓冲区ethtool -i eth0 #显示eth0的驱动程序信息ethtool -p eth0 #通过瞄准识别eth0，通常通过使LED闪烁在网络端口上ethtool -S eth0 #显示eth0的网络和驱动程序统计信息 ss 显示套接字统计。以下选项可以组合使用 12345ss -a #显示所有套接字（不管是否listen）ss -e #显示套接字的详细信息ss -o #显示计时器信息ss -n #不解析地址ss -p #使用套接字显示进程 NETTOOLS与IPROUTE对比 NETTOOLS命令 IPROUTE命令 arp -a ip neigh arp -v ip -s neigh arp -s 192.168.1.1 1:2:3:4:5:6 ip neigh add 192.168.1.1 lladdr 1:2:3:4:5:6 dev eth1 arp -i eth1 -d 192.168.1.1 ip neigh del 192.168.1.1 dev eth1 ifconfig -a ip addr ifconfig eth0 down ip link set eth0 down ifconfig eth0 up ip link set eth0 up ifconfig eth0 192.168.1.1 ip addr add 192.168.1.1/24 dev eth0 ifconfig eth0 netmask 255.255.255.0 ip addr add 192.168.1.1/24 dev eth0 ifconfig eth0 mtu 9000 ip link set eth0 mtu 9000 ifconfig eth0:0 192.168.1.2 ip addr add 192.168.1.2/24 dev eth0 netstat ss netstat -neopa ss -neopa netstat -g ip maddr route ip route route add -net 192.168.1.0 netmask 255.255.255.0 dev eth0 ip route add 192.168.1.0/24 dev eth0 route add default gw 192.168.1.1 ip route add default via 192.168.1.1","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/tags/linux/"}]},{"title":"HTTP基准测试工具AB介绍","slug":"HTTP基准测试工具AB介绍","date":"2016-12-09T12:59:29.000Z","updated":"2017-12-09T13:03:22.573Z","comments":true,"path":"2016/12/09/HTTP基准测试工具AB介绍/","link":"","permalink":"http://blog.loveops.com/2016/12/09/HTTP基准测试工具AB介绍/","excerpt":"","text":"介绍ab是apahce自带的一个http服务器基准测试工具，它不仅可以对apache服务器进行网站访问压力测试，也可以对或其它类型的服务器进行压力测试。比如nginx、tomcat、IIS等。 用法1234567891011121314151617181920212223242526272829303132333435363738Usage: ab [options] [http[s]://]hostname[:port]/pathOptions are: -n requests Number of requests to perform -c concurrency 同时向服务器端发送的请求数目，默认状态下是一次 只执行一个http请求. -t timelimit 设置测试的时间的长短，使用这个选项ab将自动设置测试请求会话数目为50000，然后以你设置的时间为固定周期.默认状态下是没有时限的，也就是直到完成你所设置的请求数目为止. -s timeout 每个请求的超时时间.默认是30秒 -b windowsize 发送/接受TCPbuffer的大小，以字节为单位 -B address 在向外连接时候绑定的地址 -p postfile POST请求包含的数据文件. 配合-T参数使用 -u putfile PUT请求包含的是数据文件. 配合-T参数使用 -T content-type 设置Content-type header信息 用于 POST/PUT请求, 例如'application/x-www-form-urlencoded'，默认 'text/plain' -v verbosity 设置打印输出级别，数字越大显示信息越详细 -w 以HTML格式打印结果 -i 使用HEAD代替GET -x attributes String to insert as table attributes -y attributes String to insert as tr attributes -z attributes String to insert as td or th attributes -C attribute 添加cookie信息, 比如. 'Apache=1234'. (repeatable) -H attribute 增加额外的头部信息, 比如 'Accept-Encoding: gzip' -A attribute 向服务器提供基本认证信息, 冒号分割用户名密码 -P attribute 向代理服务器提供基本认证信息，冒号分割用户名密码 -X proxy:port 代理服务器的地址和端口 -V 显示版本号并退出 -k 使用keep-alive功能 -d 输出结果不显示请求时间百分比信息. -S 不显示平均指的标准误差值（也就是[+/-sd]）. -q 不显示执行超过150个请求进度 -l 接受动态相应结果 (对动态页面比较管用) -g filename 将每个请求的时间输出到一个文件中. -e filename 将每个请求的时间输出到一个csv文件中 -r socket错误时不退出 -m method 方法名称 -h 显示帮助信息 -I Disable TLS Server Name Indication (SNI) extension -Z ciphersuite Specify SSL/TLS cipher suite (See openssl ciphers) -f protocol Specify SSL/TLS protocol (SSL3, TLS1, TLS1.1, TLS1.2 or ALL) 简单测试结果123456789101112131415161718192021222324252627282930313233343536373839404142434445$ ab -c 10 -n 100 https://blog.loveops.org/This is ApacheBench, Version 2.3 &lt;$Revision: 1796539 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking blog.loveops.org (be patient).....doneServer Software: nginx/1.10.3Server Hostname: blog.loveops.orgServer Port: 443SSL/TLS Protocol: TLSv1.2,ECDHE-RSA-AES256-GCM-SHA384,2048,256TLS Server Name: blog.loveops.orgDocument Path: / #请求URI Document Length: 57416 bytes #请求返回文档大小，这个数值如果变化，则被认为是错误Concurrency Level: 10 #并发连接数Time taken for tests: 21.204 seconds #测试时间Complete requests: 100 #完成总请求数Failed requests: 0 #失败请求数Total transferred: 5767500 bytes # 网络传输量HTML transferred: 5741600 bytes # html传输量Requests per second: 4.72 [#/sec] (mean) #每秒请求数（平均）Time per request: 2120.353 [ms] (mean) # （每次请求花费的平均时间）Time per request: 212.035 [ms] (mean, across all concurrent requests) # 服务器平均请求处理时间Transfer rate: 265.63 [Kbytes/sec] received #平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题Connection Times (ms) # 网络上消耗的时间的分解 min mean[+/-sd] median maxConnect: 128 910 1140.1 588 8981Processing: 229 993 711.6 689 3338Waiting: 70 435 517.5 169 2383Total: 379 1903 1268.2 1717 10272Percentage of the requests served within a certain time (ms) #每个请求处理时间的分布情况，比如：50%请求处理时间在1717ms内 50% 1717 66% 2359 75% 2667 80% 2750 90% 3374 95% 3534 98% 3928 99% 10272 100% 10272 (longest request)","categories":[{"name":"http","slug":"http","permalink":"http://blog.loveops.com/categories/http/"}],"tags":[{"name":"ab","slug":"ab","permalink":"http://blog.loveops.com/tags/ab/"}]},{"title":"ES索引设置","slug":"ES索引设置","date":"2016-11-25T13:20:22.000Z","updated":"2017-12-01T14:08:21.206Z","comments":true,"path":"2016/11/25/ES索引设置/","link":"","permalink":"http://blog.loveops.com/2016/11/25/ES索引设置/","excerpt":"","text":"索引级别的设置可以针对每个索引进行单独设置，设置分为两种： 静态设置：只能在索引创建或者状态为关闭的时候设置 动态设置：可以用 update-index-settings API在索引激活时修改 静态索引设置：1234index.number_of_shards：索引主分片的数量，模式值是5，这个只能在索引创建时指定，在关闭的索引上无法修改;注意：分片数量限制为每个索引 1024 个。这是一种安全限制，防止意外创建索引后资源分配导致集群不稳定。可以通过在集群的每个节点上设置环境变量 ES_JAVA_OPTS =\"- Des.index.max_number_of_shards = 128\" 来修改限制 123456789101112index.shard.check_on_startup是否应在索引打开前检查分片是否损坏，当检查到分片损坏将禁止分片被打开。 false: 默认值，打开索引时候不检查分片是否损坏 checksum：检查物理损坏 true：检查物理和逻辑损坏，这将消耗大量的内存和cpu fix：检查物理和逻辑损坏。有损坏的分片将被集群自动删除，这将导致数据丢失。该选项也许会造成数据丢失。使用时请考虑清楚。 检查分片在数据量大的索引会消耗更多的时间。 1index.codec:默认使用LZ4压缩方式存储数据，也可以设置为 best_compression，它使用 DEFLATE 方式以牺牲字段存储性能为代价来获得更高的压缩比例。 123index.routing_partition_size:自定义路由值可以转发的目的分片数。默认为 1，只能在索引创建时设置。此值必须小于 index.number_of_shards，除非 index.number_of_shards 值也为 1 动态索引设置：12index.number_of_replicas 每个主分片的副本数。默认为 1 12index.auto_expand_replicas 基于可用节点的数量自动分配副本数量。可以设置为以中划线分隔的最小值和最大值（例如 0-5）或设置最大值为 all（例如0-all）。默认为 false（即禁用此功能） 12index.refresh_interval 执行刷新操作的频率，这使得索引的最近更改可以被搜索。默认为 1 秒。可以设置为 -1 以禁用刷新。 12index.max_result_window 用于索引搜索的 from+size 的最大值。默认为 10000。搜索请求占用堆内存和时间与 from+size 的大小成正比，有此限制是为了防止内存溢出。请参阅 Scroll 或 Search After，以提高效率。 12index.max_rescore_window 在搜索此索引中 rescore 的 window_size 的最大值。默认为 \"index.max_result_window\" 设置的值即 10000。搜索请求占用堆内存和时间与 from+size 的大小成正比，有此限制是为了防止内存溢出。 12index.blocks.read_only 设置为 true 使索引和索引元数据为只读，false 为允许写入和元数据更改。 12index.blocks.read 设置为 true 可禁用对索引的读取操作。 12index.blocks.write 设置为 true 可禁用对索引的写入操作。 12index.blocks.metadata 设置为 true 可禁用索引元数据的读取和写入。 12index.max_refresh_listeners 索引的每个分片上可用的最大刷新侦听器数。这些侦听器用于实现 refresh=wait_for。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://blog.loveops.com/categories/ELK/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://blog.loveops.com/tags/elasticsearch/"}]},{"title":"mesos+marathon+docker安装文档","slug":"mesos-marathon-docker安装文档","date":"2016-11-23T13:44:14.000Z","updated":"2017-12-01T14:08:21.206Z","comments":true,"path":"2016/11/23/mesos-marathon-docker安装文档/","link":"","permalink":"http://blog.loveops.com/2016/11/23/mesos-marathon-docker安装文档/","excerpt":"","text":"系统环境ubuntu14.04 LTS 角色分配 IP地址 主机名 角色 192.168.9.100 mesos-master01 mesos-master,marathon,consul,es 192.168.9.101 mesos-master02 mesos-master,marathon,consul,es 192.168.9.102 mesos-master03 mesos-master,marathon,consul,es 192.168.9.104 mesos-slave01 mesos-slave,consul-client,registrator 192.168.9.105 mesos-slave02 mesos-slave,consul-client,registrator 192.168.9.106 mesos-slave03 mesos-slave,consul-client,registrator 192.168.9.107 mesos-slave04 mesos-slave,consul-client,registrator 环境准备：以下操作在所有主机： 设置时区设置为亚洲上海 1dpkg-reconfigure tzdata 设置时间同步，写入计划任务 1*/20 * * * * /usr/sbin/ntpdate pool.ntp.org &gt; /dev/null 2&gt;&amp;1 设置主机名，添加hosts1234567192.168.9.100 mesos-master01 192.168.9.101 mesos-master02 192.168.9.102 mesos-master03 192.168.9.104 mesos-slave01 192.168.9.105 mesos-slave02 192.168.9.106 mesos-slave03 192.168.9.107 mesos-slave04 安装docker1curl -sSL https://get.daocloud.io/docker | sh 添加mesos源1234sudo apt-key adv --keyserver keyserver.ubuntu.com --recv E56151BFDISTRO=$(lsb_release -is | tr '[:upper:]' '[:lower:]')CODENAME=$(lsb_release -cs)echo \"deb http://repos.mesosphere.io/$&#123;DISTRO&#125; $&#123;CODENAME&#125; main\" | sudo tee /etc/apt/sources.list.d/mesosphere.list 更新apt源1sudo apt-get update 安装mesos1sudo apt-get install mesos 配置文件一般为： 全局配置文件目录：/etc/mesos master配置文件目录：/etc/mesos-master slave配置文件目录：/etc/mesos-slave 为了使master正常工作，有三个必须配置的变量： ZooKeeper URL（zk） quorum work_dir 如需添加其他配置可以相应目录下创建相应文件夹比如：cluster 内容写集群名字，leader如果不跳转 需要在此目录配置 hostname 配置mesos-master以下只需要在9.100-102三台设置即可，ip地址修改为相应的ip地址 这里使用线上的zk集群1echo \"zk://192.168.9.21:2181,192.168.9.22:2181,192.168.9.25:2181/mesos\" &gt; /etc/mesos/zk 1echo \"192.168.9.101\" &gt; /etc/mesos-master/hostname 1echo \"prod\" &gt; /etc/mesos-master/cluster 启动mesos-master1service mesos-master start 配置mesos-slave1echo \"zk://192.168.9.21:2181,192.168.9.22:2181,192.168.9.25:2181/mesos\" &gt; /etc/mesos/zk 配置memsos-slave支持docker1echo 'docker,mesos' &gt; /etc/mesos-slave/containerizers 增加执行器超时时间，为了拉取镜像的时间1echo '10mins' &gt; /etc/mesos-slave/executor_registration_timeout 安装marathonmarathon新版本需要java1.8支持，先安装java 添加ppa安装java 123add-apt-repository ppa:webupd8team/javaapt-get updateapt-get install oracle-java8-installer 设置java1.8位默认java环境 1apt-get install oracle-java8-set-default 安装marathon 1apt-get install marathon 启动marathon 1service marathon start 安装consul下载consul二进制文件 1wget https://releases.hashicorp.com/consul/0.7.2/consul_0.7.2_linux_amd64.zip 解压文件，然后分发到每台机器上。 9.100-9.102 三台服务器启动server角色 1consul agent -server -bootstrap-expect 3 -data-dir /data/consul -dc=prod -bind=0.0.0.0 -client=0.0.0.0 -advertise=192.168.9.100 -ui 192.104-9.107 4台服务器上启动client角色 1consul agent -data-dir /data/consul -bind=0.0.0.0 -client=0.0.0.0 -dc=51idc-prod -advertise=192.168.9.104 -join 192.168.9.100 启动registrator 容器1docker run -d -it --name registrator --restart always --volume /var/run/docker.sock:/tmp/docker.sock gliderlabs/registrator -resync 60 -ip 192.168.9.105 consul://192.168.9.105:8500","categories":[{"name":"docker","slug":"docker","permalink":"http://blog.loveops.com/categories/docker/"}],"tags":[{"name":"docker mesos","slug":"docker-mesos","permalink":"http://blog.loveops.com/tags/docker-mesos/"}]},{"title":"Rsyslog-v8学习笔记七(RainerScript)","slug":"Rsyslog-v8学习笔记七-RainerScript","date":"2016-10-07T09:04:21.000Z","updated":"2017-12-15T09:05:10.796Z","comments":true,"path":"2016/10/07/Rsyslog-v8学习笔记七-RainerScript/","link":"","permalink":"http://blog.loveops.com/2016/10/07/Rsyslog-v8学习笔记七-RainerScript/","excerpt":"","text":"RainerScriptRainerScript是一种特别设计的脚本语言，非常适合处理网络事件和配置事件处理器。 它是用于rsyslog的主要配置语言。 请注意，RainerScript可能不会被当作rscript，因为这是别人的商标。从rsyslog 3.12.0开始，开始慢慢支持RainerScript（支持expression）， 在第5版中，支持“if … then”语句。 从rsyslog v6开始，基本达到全部支持。 Data Types （数据类型）RainerScript是一种无类型的语言。 这并不意味着你不需要关心类型。 当然，像“A”+“B”这样的表达式不会返回一个有效的结果，因为你不能真的添加两个字母（连接它们，使用连接运算符＆）。 但是，所有类型的转换都是由脚本解释器在需要时自动完成的。 Expressions （表达式）该语言支持任意复杂的表达式。 所有常用的操作符都支持。 操作的优先级如下（列表中较低的操作在列表中较高，例如在添加之前进行乘法。 1234567expressions in parenthesisnot, unary minus*, /, % (modulus, as in C)+, -, &amp; (string concatenation)==, !=, &lt;&gt;, &lt;, &gt;, &lt;=, &gt;=, contains (strings!), startswith (strings!)andor 例如, “not a == b” 返回的不是你想药的结果. 脚本处理器首先处理“not a” 并把返回的布尔值和b比较. 你需要的可能 “not (a == b)”. 你只是想测试两个值是否相等 , 建议用 “!=” 或者 “&lt;&gt;”. 两个效果相等，用哪个根据自己的喜好，所有测试a和b是否相等，应该用“a &lt;&gt; b”. “not” 运算符在比较表达式中也可以形成复杂的布尔表达式， 在这种情况下，最好用括号。 functions getenv(str) 像OS调用一样，返回环境变量的值（如果存在）。 如果不存在，则返回空字符串。以下示例可用于基于某个环境变量构建动态过滤器： 1if $msg contains getenv('TRIGGERVAR') then /path/to/errfile strlen(str) 返回提供字符串长度 tolower(str) 将提供的字符串转换为小写 cstr(expr) 将expr转换为字符串值 cnum(expr) 将expr转换为数字（整数）注：如果表达式不包含数值，则行为是未定义的。 wrap(str, wrapper_str) 返回由wrapper_str包装的str。 例如。 1wrap(\"foo bar\", \"##\") 结果： 1\"##foo bar##\" wrap(str, wrapper_str, escaper_str)返回由wrapper_str包装的str。 但是另外，任何出现在str中的wrapper_str都将被escaper_str替换。 例如。 1wrap(\"foo'bar\", \"'\", \"_\") 结果： 1\"'foo_bar'\" replace(str, substr_to_replace, replace_with)将所有substr_to_replace实例替换为replace_with的新字符串。 例如。 1replace(\"foo bar baz\", \" b\", \", B\") 结果 1\"foo, Bar, Baz\" re_match(expr, re) 返回1，如果expr匹配re，否则返回0。 使用POSIX ERE。 re_extract(expr, re, match, submatch, no-found) 通过正则表达式匹配从字符串（属性）提取数据。 使用POSIX ERE正则表达式。 变量“match”包含要使用的匹配的编号。 这允许拾取比第一个表达式匹配更多。 Submatch是匹配的子匹配（最多支持50个）。 “no-found”参数指定在找不到正则表达式的情况下要返回哪个字符串。 请注意，匹配和子匹配从零开始。 目前不可能通过一次调用提取多个子匹配。 field(str, delim, matchnbr) 返回一个基于字段的子字符串。 str是要搜索的字符串，delim是分隔符，matchnbr是搜索的匹配（第一个匹配从1开始）。 这与基于字段的属性替换选项类似。 7.3.7之前的版本只支持单个字符作为分隔符。 从版本7.3.7开始，可以使用完整的字符串作为分隔符。 如果使用单个字符作为分隔符，则delim是字段分隔符的数字ascii值（以便可以指定不可打印的字符）。 如果使用字符串作为分隔符，则要指定多字符字符串（例如“＃011”）。 请注意，当单个字符被指定为字符串字段（$ msg，“，”，3）时，将执行基于字符串的提取，这比等效的单字符字段（$ msg，44,3）提取性能更强。 例如。 12set $!usr!field = field($msg, 32, 3); -- 第三个字段，由空格分开set $!usr!field = field($msg, \"#011\", 2); -- 第二个字段，有 \"#011\"分开 exec_template 通过执行模板设置变量。 基本上，这可以很容易地提取属性的一些部分，并在以后使用它作为任何其他变量。 12template(name=\"extract\" type=\"string\" string=\"%msg:F:5%\")set $!xyz = exec_template(\"extract\"); 变量xyz 可以用于过滤中 : 1if $!xyz contains 'abc' then &#123;action()&#125; 或者创建动态的文件路径 : 1template(name=\"DynaFile\" type=\"string\" string=\"/var/log/%$!xyz%-data/%timereported%-%$!xyz%.log\") 更多信息请参考: http://www.rsyslog.com/how-to-use-set-variable-and-exec_template prifilt(constant) 模仿传统的基于PRI的过滤器（如“.”或“mail.info”）。 传统的过滤器字符串必须以常量字符串形式给出。 动态字符串评估是不允许的（出于性能原因）。 dyn_inc(bucket_name_literal_string, str) 递增在由bucket_name_literal_string标识的dyn-stats存储区中由str标识的计数器。 增量成功时返回0，任何其他返回值都表示增量失败。这里更新的计数器是由impstats报告的。除特殊情况（如内存分配失败等）外，由于度量标准基数被低估，递增可能失败。 Bucket被配置为支持最大基数（以防止滥用），并且在满时遇到新的（以前未见过的）度量名称（str）时拒绝增量操作。 在这里了解更多关于它的动态统计:http://www.rsyslog.com/doc/v8-stable/configuration/dyn_stats.html lookup(table_name_literal_string, key) 查找表是一个强大的构造，可以根据消息内容获取类信息。 它在一个数据文件的顶部工作，该数据文件将键（要查找）映射到值（查找的结果）。这个想法是使用消息属性（或它的衍生物）作为索引到表中，然后返回另一个值。 例如，$ fromhost-ip可以用作索引，表值代表服务器的类型或者它所在的部门或远程办公室。 在这里阅读更多关于它查找表:http://www.rsyslog.com/doc/v8-stable/configuration/lookup_tables.html num2ipv4 将整数转换为IPv4地址并以字符串形式返回地址。 输入是一个值在0到4294967295之间的整数。输出格式是’&gt;十进制&lt;.&gt;十进制&lt;.&gt;十进制&lt;.&gt;十进制&lt;’和’-1’，如果整数输入无效或函数遇到 问题。 ipv42num 将IPv4地址转换为整数并返回整数。 输入是一个字符串; 期望的地址格式可能包括开始和结束的空格，但是不能包含任何其他的字符（除了点）。 如果格式确实包含这些，则该函数将导致错误并返回-1。 ltrim 删除给定字符串开始处的任何空格。 输入是一个字符串，输出是从第一个非空格字符开始的相同字符串。 rtrim 删除给定字符串末尾的空格。 输入是一个字符串，输出是以最后一个非空格字符结尾的相同字符串。 format_time(unix_timestamp, format_str） 注意：这是实验性的代码 - 它可能会在8.30.0以后的版本中被删除或更改。 请密切关注ChangeLog的更新。 将UNIX时间戳转换为格式化的RFC 3164或RFC 3339日期/时间字符串。 第一个参数应该是一个整数值，表示1970-01-01T00：00：0Z（UNIX时代）以来的秒数。 第二个参数可以是“date-rfc3164”或“date-rfc3339”之一。 输出是一个包含格式化日期/时间的字符串。 日期/时间字符串以UTC表示（不提供时区转换）。 注意：如果函数的输入不是合适的UNIX时间戳，则将返回包含参数原始值的字符串，而不是格式化的日期/时间字符串。 1format_time(1507165811, \"date-rfc3164\") 结果 1Oct 5 01:10:11 另一个 1format_time(1507165811, \"date-rfc3339\") 结果 12017-10-05T01:10:11Z 在UNIX时间戳无效的情况下: 1format_time(\"foo\", \"date-rfc3339\") 产生原始值: 1foo parse_time(timestamp) 将RFC 3164或RFC 3339格式的日期/时间字符串转换为UNIX时间戳（表示自UNIX时代以来秒数的整数值：1970-01-01T00：00：0Z）。 如果函数的输入不是格式正确的RFC 3164或RFC 3339日期/时间字符串，或者无法解析，则返回0。 注意：此功能不支持包含年份或时区信息的特殊RFC 3164日期/时间。注意：RFC 3339日期/时间字符串中的小数秒（如果存在）将被丢弃。 1parse_time(\"Oct 5 01:10:11\") # Assumes the current year (2017, in this example) 结果 11507165811 另一种 1parse_time(\"2017-10-05T01:10:11+04:00\") 结果 11507151411 Control Structures （控制结构）RainerScript中的控制结构与C，Java，Javascript，Ruby，Bash等许多其他主流语言的语义类似。因此本节假定读者熟悉这样的结构的语义，并且在使用中描述RainerScript实现 例子形式而不是形式定义和详细的语义文档。 RainerScript支持以下控制结构： if 1234if ($msg contains \"important\") then &#123; if ( $.foo != \"\" ) then set $.foo = $.bar &amp; $.baz; action(type=\"omfile\" file=\"/var/log/important.log\" template=\"outfmt\")&#125; if/else-if/else 123456789if ($msg contains \"important\") then &#123; set $.foo = $.bar &amp; $.baz; action(type=\"omfile\" file=\"/var/log/important.log\" template=\"outfmt\")&#125; else if ($msg startswith \"slow-query:\") then &#123; action(type=\"omfile\" file=\"/var/log/slow_log.log\" template=\"outfmt\")&#125; else &#123; set $.foo = $.quux; action(type=\"omfile\" file=\"/var/log/general.log\" template=\"outfmt\")&#125; foreachForeach可以迭代数组和对象。 与数组迭代（有序）相反，对象迭代以任意顺序（无序）访问键值。 对于下面的foreach调用： 123foreach ($.i in $.collection) do &#123; ...&#125; 意识是 $.collection 是个数组 [1, “2”, {“a”: “b”}, 4], 指 $.i 将循环调用 1, “2”, {“a” : “b”} 和4. 当$ .collection包含一个对象{“a”：“b”，“c”：[1，2，3]，“d”：{“foo”：“bar”}} 结果将是$.i循环调用{“key”：“a”，“value”：“b”}，{“key”：“c”，“value”：[1，2，3]}和{“key”：“d” ，“value”：{“foo”：“bar”}}（不一定按顺序）。 在这种情况下，键和值将分别作为$.i!key和$.i!value进行访问。 这里是一个嵌套的foreach语句的例子： 12345678910foreach ($.quux in $!foo) do &#123; action(type=\"omfile\" file=\"./rsyslog.out.log\" template=\"quux\") foreach ($.corge in $.quux!bar) do &#123; reset $.grault = $.corge; action(type=\"omfile\" file=\"./rsyslog.out.log\" template=\"grault\") if ($.garply != \"\") then set $.garply = $.garply &amp; \", \"; reset $.garply = $.garply &amp; $.grault!baz; &#125;&#125; 请注意，在foreach-statement主体中的异步操作调用几乎总是将action.copyMsg设置为on。 这是因为在foreach中的动作调用通常要使用变量循环填充（在上面的例子中，$ .quux和$ .corge），这会导致消息变异，而异步动作必须看到消息，因为它是在 循环体，所以他们必须做一个副本，以保持安全的进一步修改随着迭代继续。 例如，使用基于链接列表的队列的异步操作调用将如下所示： 123foreach ($.quux in $!foo) do &#123; action(type=\"omfile\" file=\"./rsyslog.out.log\" template=\"quux\" queue.type=\"linkedlist\" action.copyMsg=\"on\")&#125; call 细节请参考：http://www.rsyslog.com/doc/v8-stable/rainerscript/rainerscript_call.html continue 一个NOP，很有用 例如 if语句中的一部分 configuration objects action() 动作对象是描述要执行的动作的主要手段。 global() 这用于设置全局配置参数。 有关详细信息，请参阅rsyslog全局配置对象 input() 输入对象是描述输入的主要手段，用于收集rsyslog处理的消息。 module() 模块对象用于加载插件。 parser() 解析器对象用于定义自定义解析器对象。 timezone() 时区对象用于定义时区设置。 Constant Strings字符串常量在很多地方都是必需的：比较，配置参数值和函数参数，这里列出几个重要的参数。 在常量字符串中，特殊字符是通过在它们前面加上反斜杠来进行转义的 - 就像在C编程语言或PHP中一样。 如果不确定如何正确转义，请使用RainerScript字符串转义在线工具。 Variable (Property) types 变量（属性）类型所有的rsyslog属性（参见列表的属性页面）都可以在RainerScript中使用，前缀为“$”，例如： 1set $.x！host = $ hostname; 另外，它也支持局部变量。局部变量是当前消息的本地变量，但不是消息属性（例如，“$！”，所有的JSON属性都不包含它们）。 只有消息JSON（CEE /Lumberjack）属性可以通过set，unset和reset语句来修改，而不是任何其他的消息属性。显然，局部变量也是可以修改的。 消息JSON属性名称以“$！”开头，其中bang字符表示根。 局部变量名称以“$.”开头，其中点表示根。 JSON属性和局部变量都可以在最后一个元素之前包含任意的深度路径。爆炸字符总是用作路径分隔符，不管它是一个消息属性还是一个局部变量。例如，“$！path1！path2！varname”是一个三层深度的消息属性，其中非常相似的“$ .path1！path2！varname”指定了一个三层深的局部变量。 rsyslog使用紧跟在美元符号后面的重音符或点符号来分隔不同的类型。 请注意，后缀分号需要指示表达式的结尾。如果没有给出，配置加载将失败并出现语法错误消息。 检查以下用法示例以了解这些语句的行为： set 设置局部变量或json属性的值，但是如果被寻址的变量已经包含一个值，它的行为就会有所不同，如下所示： 如果现有值和新值都是对象，则合并值，但将新值合并到根，而不是与给定键的值合并。 例如。 1234567891011set $.x!one = \"val_1\";# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125; &#125;set $.y!two = \"val_2\";# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125;, \"y\": &#123; \"two\": \"val_2\" &#125; &#125;set $.z!var = $.x;# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125;, \"y\": &#123; \"two\": \"val_2\" &#125;, \"z\": &#123; \"var\": &#123; \"one\": \"val_1\" &#125; &#125; &#125;set $.z!var = $.y;# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125;, \"y\": &#123; \"two\": \"val_2\" &#125;, \"z\": &#123; \"var\": &#123; \"one\": \"val_1\" &#125; &#125;, \"two\": \"val_2\" &#125;# note that the key *two* is at root level and not under *$.z!var*. 忽略新值如果旧值是一个对象，但新值不是一个对象（如字符串，数字等）。 例如： 1234set $.x!one = \"val_1\";set $.x = \"quux\";# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125; &#125;# note that \"quux\" was ignored 重置变量，如果旧值不是一个对象 123set $.x!val = \"val_1\";set $.x!val = \"quux\";# results in $. = &#123; \"x\": &#123; \"val\": \"quux\" &#125; &#125; unset 删除变量值. Eg: 123set $.x!val = \"val_1\";unset $.x!val;# results in $. = &#123; \"x\": &#123; &#125; &#125; reset 强制设置新的值，而不管最初包含的变量或甚至设置的变量。 例如。 12345678910111213# to contrast with the set example above, here is how results would look with resetset $.x!one = \"val_1\";set $.y!two = \"val_2\";set $.z!var = $.x;# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125;, \"y\": &#123; \"two\": \"val_2\" &#125;, \"z\": &#123; \"var\": &#123; \"one\": \"val_1\" &#125; &#125; &#125;# 'set' or 'reset' can be used interchangeably above(3 lines), they both have the same behaviour, as variable doesn't have an existing valuereset $.z!var = $.y;# results in $. = &#123; \"x\": &#123; \"one\": \"val_1\" &#125;, \"y\": &#123; \"two\": \"val_2\" &#125;, \"z\": &#123; \"var\": &#123; \"two\": \"val_2\" &#125; &#125; &#125;# note how the value of $.z!var was replacedreset $.x = \"quux\";# results in $. = &#123; \"x\": \"quux\", \"y\": &#123; \"two\": \"val_2\" &#125;, \"z\": &#123; \"var\": &#123; \"two\": \"val_2\" &#125; &#125; &#125; Lookup Tables查找表（http://www.rsyslog.com/doc/v8-stable/configuration/lookup_tables.html） 是一种功能强大的结构，用于根据消息内容获取“class”信息（例如，为不同的服务器类型，部门或远程办公室构建日志文件名称）。 General Queue Parameters队列参数可以和下面的语句一起使用： action() ruleset() main_queue() 队列需要在应该影响的动作或规则集中进行配置。如果没有配置，将使用默认值。因此，默认的规则集只有默认的主队列。 “特定操作”队列默认不设置。要充分了解队列参数及其交互方式，请务必阅读队列文档。http://www.rsyslog.com/doc/v8-stable/concepts/queues.html queue.filename name 要用于队列文件的文件名。请注意，这实际上只是文件名。不能在此参数中指定一个目录。如果文件应在特定的目录中创建，请为此指定queue.spoolDirectory。文件名用于构建队列文件以完成路径。 queue.spoolDirectory name 名称这是存储队列文件的目录。请注意，该目录必须存在，它不是由rsyslog自动创建的。如果没有指定spoolDirectory，则使用工作目录 queue.size number 这是消息数量中队列的最大大小。请注意，将队列大小设置为非常小的值（大约低于100个消息）不受支持，并可能导致不可预知的结果。有关此限制的当前状态的更多信息，请参阅rsyslog FAQ：“队列大小的下限”。默认取决于队列类型和rsyslog版本，如果你需要一个特定的值，请指定它。否则，rsyslog会选择它考虑的版本。例如，在rsyslog rsyslog 8.30.0中，规则集队列的缺省大小为50000，配置为非直接的动作队列的大小为1000。 queue.dequeuebatchsize number 默认128 queue.maxdiskspace number 所有队列文件一起在磁盘上使用的最大大小。 请注意，实际大小可能会稍大于配置的最大值，因为rsyslog从不写入部分队列记录。 queue.highwatermark number 这仅适用于磁盘辅助队列。 当队列填满这个数量的消息时，队列开始将消息假脱机到磁盘。 请注意，这不应该作为正常处理的一部分发生，因为磁盘队列模式比内存中队列模式慢得多。 对于输出操作目标在一段时间内脱机的情况，应该保留磁盘。 默认90％的队列大小 queue.lowwatermark number 默认70％的队列大小 queue.fulldelaymark number 队列应阻塞可延迟消息的消息数。 消息不再处理，直到队列再次有足够的空间。 如果消息是可延迟的取决于输入。 例如，通过imtcp收到的消息是可延迟的（因为TCP可以推回），但是通过imudp收到的消息不是（因为UDP不允许推回）。 这个设置背后的意图是在非延迟消息的几乎完整队列中留出一些空间，如果队列空间不足将会丢失。 请注意，如果您使用DA队列，则在高水位标记之后设置完全延迟标记将使队列永远不会为可延迟输入激活磁盘模式。 所以这可能不是你想要的。 队列大小的默认值为97％ queue.lightdelaymark number 默认70％的队列大小 queue.discardmark number 默认80％的队列大小 queue.discardseverity number numerical severity! default 8 (nothing discarded) queue.checkpointinterval number 每次队列写入磁盘时，默认情况下磁盘队列都不会更新管家结构。 这是出于性能原因。 在发生故障的情况下，数据将会丢失（除非数据通过文件结构被破坏）。 但是，可以将磁盘队列设置为在检查点上记录簿记信息（每n个记录），以使得这也可以是超可靠的。 如果检查点间隔设置为1，则不会丢失数据，但队列速度异常缓慢。 queue.syncqueuefiles on/off (default “off”) 在每次写入操作之后，通过发出(f)sync，可以使基于磁盘的队列非常可靠。 将参数设置为“on”时会发生这种情况。 激活这个选项有一个性能损失，所以不应该没有很好的理由打开。 请注意，惩罚也取决于queue.checkpointInterval频率。 queue.samplinginterval 此选项允许队列由特定间隔产生的事件填充。 它提供了一种对每个N个事件进行数据采样的方法，而不是全部处理，以减少资源使用（磁盘，带宽…）。此功能适用于8.23及更高版本。 queue.type [FixedArray/LinkedList/Direct/Disk] queue.workerthreads number 工作线程数，默认为1，建议1 queue.timeoutshutdown number 超时时间，单位ms（1000ms为1秒！），默认为0（不限制） queue.timeoutactioncompletion number 超时时间，单位ms（1000ms为1秒！），默认为1000，0表示不限制 queue.timeoutenqueue number 超时时间，单位ms（1000ms为1秒！），默认为2000，0表示不限制队列满时使用此超时值。 如果rsyslog在超时时间内不能排队消息，则消息被丢弃。 请注意，这是最后的设置（假设默认值用于队列设置或设置了适当的参数）：所有可延迟的输入（如imtcp或imfile）在此阶段已被推回。 此外，丢弃较低优先级的消息（如果已配置）已经发生。 所以如果我们没有足够快的超时，我们会遇到这样的情况之一： 如果使用imuxsock并且不涉及systemd日志，则系统将变得无响应，并且很可能需要硬复位。 如果使用带有imjournal转发的imuxsock是活动的，则由于日志丢弃它们而丢失消息（比rsyslog更具侵略性） 如果使用imjournal，日志将缓冲消息。 如果日志耗尽配置的空间，则消息将被丢弃。 所以在这种模式下丢弃被移到稍后的地方。 其他不可延迟的来源，如imudp也将失去信息所以提供这个设置是为了防止有问题的情况，这总是会导致消息丢失或系统挂起。对于行动队列，人们可能会争论是否更好地快速溢出到主队列。 如果需要的话，通过设置一个非常大的超时值，这很容易实现。 当然，主队列也是如此，但是如果你这样做的话，你已经被警告过了！ 换句话说，您可以使用默认值来考虑这种情况。 所有进度被阻止（无法传递讯息）： 所有可延迟的输入（tcp，relp，imfile，imjournal等）将会无限制地阻塞（假设queue.lightdelaymark和queue.fulldelaymark被设置为合理的，这是默认的）。 imudp将失去消息，因为操作系统将放弃他们 通过UDP或imuxsock到达rsyslog的消息，并且严重程度足以使其不被discardseverity过滤，将阻塞2秒，试图将消息放入队列中（希望发生某些事情可以使空间 在队列中），然后放下，以避免永久阻塞机器。 然后下一条待处理的消息也会被尝试2秒等等 如果进入动作队列，日志消息将在这2秒钟内保持在主队列中，而到达的其他日志则会在主队列中累积。 queue.timeoutworkerthreadshutdown number 超时时间，单位ms（1000ms为1秒！），默认为60000（1分钟） queue.workerthreadminimummessages number default queue size/number of workers queue.maxfilesize size_nbr default 1m queue.saveonshutdown on/off queue.dequeuetimebegin 单位微秒（1000000us是1秒！），默认为0（无延迟）。 简单的限速！ queue.dequeuetimeend number queue.samplinginterval number 动作队列的采样间隔。 此参数指定在排入队列之前将丢弃多少行日志。 默认为0。 例子： 以下是带有自己的队列的TCP转发操作示例。 123action(type=\"omfwd\" target=\"192.168.2.11\" port=\"10514\" protocol=\"tcp\" queue.filename=\"forwarding\" queue.size=\"1000000\" queue.type=\"LinkedList\" ) The rsyslog “call” statementrsyslog“call”语句用于将规则集绑定在一起。它是按照通常的编程语言“调用”语句建模的。把一个规则集想象成一个子程序（它到底是什么！），你就可以得到这个图像。 “call”语句可用于调用任何类型的规则集。如果规则集分配了队列，则消息将被发送到该队列并异步处理。否则，在规则集执行完成后，规则集将被同步执行，控制权在调用后立即返回。 请注意，对于“停止”语句，异步执行和同步执行之间存在重要区别。在异步运行时不会影响原始消息的处理。 “call”语句取代了不推荐的omruleset模块。它提供omruleset具有的所有功能，但以更高效的方式工作。请注意，omruleset是在v7之前的引擎的限制内调用规则集的一种破解。 “呼叫”是新引擎的干净解决方案。特别是对于没有关联队列（同步操作）的规则集，它没有开销（真的！）。 omruleset总是需要重复消息，通常意味着至少〜250字节的内存写入，一些分配和释放 - 以及更多的性能密集型操作。 语法：1call rulesetname 其中“rulesetname”是在配置中其他位置定义的规则集的名称。 如果调用是同步的还是异步取决于规则集参数。 这不能被“调用”语句覆盖。 相关链接Blog posting announcing “call” statement (with sample) http://blog.gerhards.net/2012/10/how-to-use-rsyslogs-ruleset-and-call.html The rsyslog “call_indirect” statementrsyslog“call_indirect”语句等价于“call”语句，不同的是被调用的规则集的名称不是常量，而是表达式，因此可以在运行时计算。 如果使用call_indirect时无法找到规则集名称，则会发出错误消息，并忽略call_indirect语句。 执行继续下一个语句。 语法：1call_indirect expression; “expression”是任何有效的表达是。 请参阅表达式了解更多信息 请注意，后缀分号需要指示表达式的结尾。 如果没有给出，配置加载将失败并出现语法错误消息 examples“call_indirect”潜在最有用的用例是基于消息变量调用规则集。 让我们假设您已经根据预期的系统日志标记命名了您的规则集。 那么你可以使用 1call_indirect $ syslogtag; 调用这些规则集。 但是，请注意，这可能会被恶意攻击者滥用，攻击者将注入无效的系统日志标记。 这尤其可以用来将消息流重定向到已知的标准规则集。 为了减轻这一点，规则集名称可以通过创建一个唯一的前缀（不要使用这个示例中的一个）稍微改变。 让我们假定使用前缀“changeme-”，那么所有的规则集应该以该字符串开始。 然后，可以使用以下呼叫： 1call_indirect“changeme-”＆$ syslogtag; 虽然可以通过常量名称调用规则集： 1call_indirect“my_ruleset”; 建议使用“call”语句，因为在这种情况下它提供了优越的性能。 附件信息我们需要有两个不同的语句，“call”和“call_indirect”，因为在添加“call_indirect”时已经存在“call”。 我们无法扩展“call”来支持表达式，因为这会破坏现有的配置。 在这种情况下，调用规则集将会失效，而调用“规则集”将不得不被使用。 因此，我们决定为这个用例添加额外的“call_indirect”语句。 global() configuration object全局配置对象允许设置全局参数。 请注意，每个参数只能设置一次，以后不能重新设置。 如果一个参数设置多次，行为是不可预知的。以下参数可以设置： action.reportSuspension - binary, default “on”, v7.5.8+ 如果启用（“on”）action 将在syslog.*下记录消息，当一个action暂停或恢复时。 通常连接到后端系统出现问题时，会发生这种情况。 如果禁用（“关闭”），则不会生成这些消息。 这些消息可以用于检测后端系统的问题。 最重要的是，频繁的暂停和恢复指向一个问题领域 action.reportSuspensionContinuation - binary, default “off”, v7.6.1+, v8.2.0+ 如果启用（“开”），该action不仅仅报告第一次暂停，但是每次暂停被延长。 否则，后续消息不会被记录。如果此设置设置为“on”，则action.reportSuspension也会自动打开为“on”。 workDirectory dropMsgsWithMaliciousDNSPtrRecords localHostname preserveFQDN defaultNetstreamDriverCAFile 对于TLS系统日志，可以验证机器密钥和证书的CA证书（请参见下文） defaultNetstreamDriverKeyFile 机器私钥 defaultNetstreamDriverCertFile 机器公钥 debug.gnutls (0-10; default:0) 除0以外的任何其他参数都会启用GnuTLS的调试消息。 给出的消息数量取决于参数的高度，0没有任何意义，10是非常多的。 警告！ 更高的参数可能会给出比需要更多的信息。 我们建议您首先使用小参数来防止发生。 如果启用通用调试，此参数仅起作用。 processInternalMessages binary (on/off) 这告诉rsyslog是否应该处理内部消息本身。 默认的操作模式（“关”）使rsyslog发送消息到系统日志接收器（如果它是唯一的实例，从那里接收它们）。 这也适用于systemd日志，并会使rsyslog消息显示在systemd状态控制信息中。 如果rsyslog的这个（实例）不是主实例，并且有另一个主要的日志系统，rsyslog内部消息将被插入到主实例的系统日志流中。 在这种情况下，设置为（“on”）将使您能够接收来自其实例的内部消息。 请注意，早期版本的rsyslog工作方式相反。 有关更改的更多信息可以在rsyslog-error-reporting-improved中找到。 stdlog.channelspec 允许设置liblogging-stdlog通道说明符字符串。 这又允许发送rsyslog日志消息到不同于系统默认值的目的地。 请注意，只有在processInternalMessages设置为“off”的情况下，此参数才有效。 否则，它会被默默地忽略。 defaultNetstreamDriver 设置”gtls”,开启TLSSet it to “gtls” to enable TLS for TLS syslog maxMessageSize rsyslog可以处理的最大消息大小。 默认值是8K。 超过最大尺寸的任何内容都将被截断。 janitor.interval [minutes], available since 8.3.3 设置管理员进程运行的时间间隔。 debug.onShutdown available in 7.5.8+ 如果启用（“on”），rsyslog将在请求系统关闭时记录调试消息。 这可以用来跟踪仅在关机期间发生的问题。 在正常操作期间，系统性能不受影响。 请注意，为使此选项有用，还必须设置debug.logFile参数（或相应的环境变量）。 debug.logFile available in 7.5.8+ 这用于指定调试日志文件名称。 它用于所有调试输出。 请注意，RSYSLOG_DEBUGLOG环境变量总是重写debug.logFile的值。 net.ipprotocol available in 8.6.0+ 这允许指示rsyslog仅使用IPv4或IPv6。 可能的值是“未指定的”，在这种情况下，使用两种协议，“ipv4-only”和“ipv6-only”，它们限制使用指定的协议。 默认是“未指定”。 注意：这取代了以前的-4和-6 rsyslogd命令行选项。 net.aclAddHostnameOnFail available in 8.6.0+ 如果“启用”，在ACL处理期间，出于性能原因，主机名被解析为IP地址。 如果在这个过程中DNS失败，主机名将被添加为通配符文本，一旦DNS重新启动，这将导致适当的，但稍慢的操作。 默认是“关”。 net.aclResolveHostname available in 8.6.0+ 如果“关闭”，则在ACL处理期间不要将主机名解析为IP地址。 默认开启 net.enableDNS [on/off] available in 8.6.0+ 默认开启 可以用来打开或关闭DNS名称解析。 net.permitACLWarning [on/off] available in 8.6.0+ 默认开启 如果“关闭”，则禁止从未授权的机器（不在AllowedSender列表中）收到消息时发出的警告。 parser.parseHostnameAndTag [on/off] available in 8.6.0+ 默认值：打开 这控制解析器试图解析来自消息的HOSTNAME和TAG字段。 默认是“开”，在这种情况下解析发生。 如果设置为“关”，则不解析这些字段。 请注意，这通常不是你想要的。 强烈建议只有当你确切知道你为什么这样做时，才能将此设置更改为“关闭”。 parser.permitSlashInHostname [on/off] available in 8.25.0+ 默认：关闭 这将控制是否允许在“程序名”属性中使用斜杠。 这个属性基于BSD概念，通过BSD syslogd源，在程序名称中不允许斜线。 但是，一些Linux工具（包括最重要的日志）在syslogtag中存储斜杠作为程序名称的一部分。 在这种情况下，程序名会在第一个斜杠处截断。 如果此设置更改为“开”，则允许斜线，并且不会终止程序名解析。 parser.permitSlashInProgramName [on/off] available in 8.25.0+ 默认：关闭 这将控制是否允许标签的静态部分中的斜杠。 如果该设置关闭，则标签中的值“app/foo [1234]”将解析程序名为“app”。 如果应用程序存储绝对路径名称，例如“/app/foo [1234]”，则programname属性将变为空（“”）。 如果您需要将斜线实际存储为程序名称的一部分，则应将此设置更改为“打开”以允许此设置。 然后，“/app/foo[1234]”的syslog标签将导致程序名为“/app/foo”。 senders.keepTrack [on/off] available 8.17.0+ 默认：关闭 如果打开，rsyslog跟踪已知的发件人，并通过impstats机制报告他们的统计数据。 保存活动发件人列表。 当检测到新的发件人时，会发出信息性消息。 只有在超时后才能从列表中清除发件人（请参阅senders.timoutAfter参数）。 请注意，当连接关闭时，我们不会有意删除发件人。 发件人跟踪的重点在于能够提供更长时间的数据。 因此，我们不希望仅仅因为发送者已经在短时间内断开（例如，重新启动）而丢弃信息。 发件人通过主机名进行跟踪（在连接建立时）。 注意：目前只有imptcp和imtcp支持发件人跟踪。 enders.timeoutAfter [seconds] available 8.17.0+ 默认：12小时（12 60 60秒） 指定发送者在哪段时间后被认为“已经离开”。 对于每个发件人，rsyslog都会记录最少收到的邮件的时间。 如果在该时间间隔内没有收到消息，则rsyslog会认为发送者不再存在。 然后它将a）发出警告信息（如果已配置）并且b）从主动发送者列表中清除它。 因此，一旦发送数据超时，发件人将不再被报告。 senders.reportGoneAway [on/off] available 8.17.0+ 默认：关闭 当发送者在发送者的时间间隔内已经接收到来自发送者的数据时，发出警告消息。 senders.reportNew [on/off] available 8.17.0+ 默认：关闭 如果发件人跟踪处于活动状态，请报告尚未在缓存中的发件人。 请注意，这意味着由于长时间不活动而超时的发件人在重新连接后也会被报告。 debug.unloadModules [on/off] available 8.17.0+ 默认值：打开 这主要是一个调试设置。 如果设置为“off”，rsyslog永远不会卸载任何模块（包括插件）。 这通常不会导致操作上的问题，但在极端的情况下可能会发生 这个设置的核心好处是它使valgrind堆栈跟踪可读。 在以前的版本中，只有通过特殊的构建选项才能使用相同的功能。 debug.files [ARRAY of filenames] available 8.29.0+ 默认值：无 这可以用来配置rsyslog只显示在某些文件中生成的调试输出。 如果该选项已设置，但没有给出文件名，则调试输出的行为就像关闭该选项一样。 但请注意，由于配置的工作方式，这可能不会影响前几个调试输出，而rsyslog正在读取配置。 为了达到最佳效果，我们建议在配置的最初阶段将此参数设置为最小化不需要的输出。 有关更多信息，请参阅debug.whitelist。 debug.whitelist [on/off] available 8.29.0+ 默认值：打开 该参数是debug.files的辅助参数。 如果在配置中使用了debug.files，那么debug.whitelist是一个开关，用于从显示调试输出中命名为白名单或黑名单的文件。 如果它被设置为打开，列出的文件将生成调试输出，但不会有其他文件。 如果参数设置为关，则反向原则适用。 有关更多信息，请参阅debug.files。 environment [ARRAY of environment variable=value strings] available 8.23.0+ 默认值：无 这允许通过rsyslog.conf设置环境变量。 这样做的主要动机是，对于许多库，默认值可以通过环境变量来设置，但是通过操作系统服务启动文件来设置它们在不同的平台上是很麻烦和不同的。 所以环境参数提供了一个方便的方法来设置这些变量。 一个常见的例子是设置http_proxy变量，例如 用于KSI签名或ElasticSearch。 这可以如下完成： 1global(environment=\"http_proxy=http://myproxy.example.net\") 请注意，以这种方式设置的环境变量必须包含等号，并且变量名称不得超过127个字符。 可以在单个全局语句中设置多个环境变量。 这是用常规的数组语法完成的，如下所示： 123global(environment=[\"http_proxy=http://myproxy.example.net\", \"another_one=this string is=ok!\" ) 像往常一样，空白在参数放置方面是不相关的。 所以上面的例子也可以写在一行上。 internalmsg.ratelimit.interval [positive integer] available 8.29.0+ 默认：5 指定将速率限制应用于由rsyslog生成的内部信息包（即错误信息）的时间间隔（以秒为单位）。 如果在该时间间隔内读取超过internalmsg.ratelimit.burst消息，则直至间隔结束的更多消息将被丢弃。 internalmsg.ratelimit.burst [positive integer] available 8.29.0+ Default: 500 指定将速率限制应用于由rsyslog生成的内部信息包（即错误信息）的时间间隔（以秒为单位）。 如果在该时间间隔内读取超过internalmsg.ratelimit.burst消息，则直至间隔结束的更多消息将被丢弃。 警告：遇到相应的语句时立即设置环境变量。 同样，模块在遇到模块加载语句时加载。 这可能会在rsyslog.conf中创建序列依赖关系。 为避免这种情况，强烈建议在rsyslog.conf的顶部设置环境变量。 而且，rsyslog相关的环境变量可能不适用，即使设置在顶部。 仍然将它们设置在操作系统启动文件中是最安全的。 请注意，rsyslog环境变量通常仅用于开发人员，因此几乎不需要为普通用户设置它们。 而且，许多设置（例如调试）也可用作配置对象。 errorMessagesToStderr.maxNumber [positive integer] available 8.30.0+ 默认：不限制 这允许对可以进入标准错误的消息的数量进行严格的限制。 如果没有别的，这个功能对测试平台是有帮助的。 它允许减少垃圾邮件的测试日志，同时仍然提供查看初始错误消息的能力。 对于一些实际的部署可能也是有用的。 variables.caseSensitve [boolean (on/off)] available 8.30.0+ 默认：关闭 这可以使变量区分大小写，对于一些特殊的输入数据可能需要哪些情况，只是字段名称的唯一区别。 请注意，在8.30之前的rsyslog版本中，缺省值为“on”，这经常导致用户混淆。 除了需要提及的情况之外，通常不需要将其切换回“开”。 这也是我们切换默认的原因。","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"Rsyslog-v8学习笔记六(过滤条件)","slug":"Rsyslog-v8学习笔记六-过滤条件","date":"2016-10-06T10:27:33.000Z","updated":"2017-12-13T10:28:50.567Z","comments":true,"path":"2016/10/06/Rsyslog-v8学习笔记六-过滤条件/","link":"","permalink":"http://blog.loveops.com/2016/10/06/Rsyslog-v8学习笔记六-过滤条件/","excerpt":"","text":"过滤条件Rsyslog 提供四种类型的过滤条件： “traditional” severity and facility based selectors（根据优先级和设施） property-based filters expression-based filters BSD-style blocks (not upward compatible) 选择器选择器是过滤系统日志消息的传统方式。它们被保留在rsyslog中，因为他们的原始语法是众所周知的，高效的，也需要与stock syslogd配置文件兼容。如果您只需要根据优先级和设施进行筛选，则应该使用选择器线进行筛选。 它们为这项工作提供了最好的表现。 选择器字段本身又由两部分组成，一个设施和一个优先级，由点号（“.”）隔开。这两个部分不区分大小写，也可以指定为十进制数字，但是最好不药这样做，会有警告信息 syslog（3）中描述了设施和优先级。下面提到的名称对应于/usr/include/syslog.h中类似的LOG_values。 设施必须是以下关键字之一： auth authpriv cron daemon kern lpr mail mark news security (same as auth) syslog user uucp local0-local7关键字security不应该再使用，mark仅供内部使用，因此不应在应用程序中使用。 无论如何，你可能想在这里指定和重定向这些消息。该工具指定产生该消息的子系统，即，如果使用syslog登录，则所有的邮件程序都将使用邮件工具（LOG_MAIL）进行登录。 优先级是以下关键字之一，按升序排列： debug info notice warning warn（与warning相同） err error（与err相同 cirt alter emerg panic（与emerg相同） 关键字error、 warn and panic已被弃用，不应再使用。 优先级定义了消息的严重程度。 原BSD syslogd的行为是根据给定的动作记录所有指定优先级和更高优先级的消息。 Rsyslogd表现相同，但有一些扩展。 除上述名称外，rsyslogd（8）还可以理解以下扩展：星号（“*”）代表所有设施或所有优先级，具体取决于它在何处使用（在期间之前或之后）。 关键字none表示给定设施没有优先权。 您可以使用逗号（“，”）运算符在一个语句中指定具有相同优先级模式的多个工具。 你可以指定尽可能多的需要的设施。请记住，只有来自这样的声明的设施部分被采取，优先部分将被跳过。 可以使用分号（“;”）分隔符为单个动作指定多个选择器。 请记住，选择器字段中的每个选择器都可以覆盖前面的选择器。 使用这种行为，你可以从模式中排除一些优先级。 Rsyslogd具有原始BSD源语法扩展，使其更直观。 您可以在每个优先级之前加上等号（“=”）来指定这个优先级，而不是上面的任何一个。 你也可以（都是有效的）在优先级之前用一个感叹号（“！”）来忽略所有的优先级，或者确切地说这个或者这个以及任何更高的优先级。 如果您使用两个扩展名，而感叹号必须在等号之前出现，请直观地使用它。 基于属性的过滤器基于属性的过滤器对rsyslogd是唯一的。 他们允许过滤任何属性，如HOSTNAME，syslogtag和msg。 所有当前支持的属性的列表可以在property replacer documentation中找到（但请记住只有属性，而不支持替换器）。 使用此过滤器，可以使用指定的比较操作，针对指定的值检查每个属性。 基于属性的过滤器必须以冒号开头。这告诉rsyslogd它是新的过滤器类型。 冒号后面必须跟着属性名称，逗号，比较操作的名称执行，另一个逗号，然后是比较的值。 这个值必须被引用。 逗号之间可以有空格和制表符。 属性名称和比较操作区分大小写，所以“msg”起作用，而“MSG”是一个无效的属性名称。 简言之，语法如下： 1:property, [!]compare-operation, \"value\" 比较的操作目前支持以下比较操作： contains 检查字符串中是否包含指定的值。 必须有完全匹配，不支持通配符。 sequal 比较提供的“值”字符串和属性内容是否完全相等。 与contains的区别在于包含只要在属性值内任何位置搜索到即可，而对于isequal必须是王权相同的。 因此，isequal对于像syslogtag或者FROMHOST这样的领域是非常有用的，你可能知道确切的内容。 startswith 检查指定值是否刚好是属性值的开始。 例如，如果您搜索“val” 1:msg, startswith, \"val\" “values are in this message”将匹配到，而“There are values in this message”将匹配不到，但是后者能匹配“contains”。请注意，“startswith”比正则表达式要快得多。 所以即使一旦实施，使用“startswith”也可能会有很大的意义（性能方面）。 regex将该属性与提供的POSIX BRE正则表达式进行比较。 ereregex将该属性与提供的POSIX ERE正则表达式进行比较。 你可以在比较操作之前使用感叹号（！），这个操作的结果是否定的。 例如，如果msg包含“This is a informative message”，下面的示例将不匹配： 1:msg, contains, \"error\" 这个是匹配的: 1:msg, !contains, \"error\" 如果您想要进行一些通用处理但排除某些特定事件，则使用否定可能很有用。 您可以结合使用丢弃操作。 比如： 123*.* /var/log/allmsgs-including-informational.log:msg, contains, \"informational\" ~*.* /var/log/allmsgs-but-informational.log 不要忽略第2行的”~”符号, 在这个例子中，所有的消息都被写入文件allmsgs-including-informational.log。 然后，包含字符串“informational”的所有消息都被丢弃。 这意味着“丢弃行”下方的配置文件行（我们示例中的编号2）将不会应用于此消息。 然后，所有剩余的行也将写入文件allmsgs-but-informational.log。 Value Part值是一个带引号的字符串。 它支持一些转义序列： \\” - 双引号 (e.g. “String with \\”Quotes\\””)\\ - 反斜线 (e.g. “C:\\tmp”)转义序列始终以反斜杠开始。 反斜杠字符必须转义。 那么上面列出的任何其他序列是无效的，并可能导致不可预知的结果。 可能“msg”是基于属性过滤器最突出的用例。 这是实际的消息文本。 如果您想根据某些消息内容（例如特定代码的存在）进行过滤，则可以通过以下方式轻松完成此操作： 1:msg, contains, \"ID-4711\" 当消息包含字符串“ID-4711”时，该过滤器将匹配。 请注意，比较区分大小写，所以如果消息中包含“id-4711”，则不匹配。 1:msg, regex, \"fatal .* error\" 此过滤器使用POSIX正则表达式。 当字符串包含“fatal”和“error”之间的任何内容（例如e.g. “fatal net error” 和 “fatal lib error” 但是 “fatal error”不行，因为正则表达式需要两个空格！ 正确获取基于属性过滤器有时可能具有挑战性。 为了帮助您尽可能地做到这一点，rsyslogd在评估过程中为所有基于属性的过滤器吐出调试信息。 要启用它，请在前台运行rsyslogd并指定“-d”选项。 基于属性的过滤器中目前不支持布尔运算‘message contains “ID17” or message contains “ID18”’）（除了上面的“not”外）。 请注意，虽然可以通过基于属性的过滤器来查询设施和严重性，但对于这些情况，使用经典选择器（参见上文）更为明智。 基于表达式的筛选器基于表达式的过滤器允许对任意复杂表达式进行过滤，包括布尔，算术和字符串操作。 表达式过滤器将演变成完整的配置脚本语言。 不幸的是，他们的语法在这个过程中会稍微改变。 所以如果你现在使用它们，你需要准备在一段时间后改变你的配置文件。 但是，我们尽可能快地实施脚本功能（也就是所需的阶段性工作）。 所以曝光时间可能不会太长。 基于表达式的过滤器在新行的第1列中用关键字“if”表示。 他们有这样的格式： 1if expr then action-part-of-selector-line “if”和“then”是必须存在的固定关键字。 “expr”是一个（可能相当复杂的）表达式。 请查看expression documentation 。“action-part-of-selector-line”是一个动作，就像你所知道的那样（例如 “/var/log/logfile” to write to that file）。 BSD风格 Blocks注意：由于技术原因，rsyslog v7 +不再支持BSD风格的blocks。所以强烈建议不要使用它们。 Rsyslogd在rsyslog.conf中支持BSD风格的blocks。通过程序或主机名规范将每一行的blocks与先前的blocks分离。一个blocks只会记录对应于给定的最新程序和主机名规范的消息。因此，一个选择“ppp”作为程序的blocks，紧接着是一个从主机名“dialhost”中选择消息的blcoks，然后第二个blocks将只在dialhost上记录来自ppp程序的消息。 程序规范是以’!prog’开始的行，下面的blocks将与来自该特定程序的syslog调用相关联。 “foo”的程序规范也将匹配内核记录的任何以“foo：”为前缀的消息。或者，程序规范“-foo”会使以下块应用于来自除指定程序之外的任何程序的消息。 “+ hostname”形式的主机名规范以及以下块将应用于从指定主机名接收到的消息。或者，主机名规范“-hostname”会使以下块应用于来自任何主机但指定的主机的消息。如果主机名称为“@”，则将使用本地主机名称。 （尚未实现）通过将程序或主机名称设置为“*”，可以重置程序或主机名称规范。 请注意，rsyslogd不支持BSD syslogd中的“#!prog”，“＃+ hostname”和“＃-hostname”语法。默认情况下，不设置主机名或程序。 实例12*.* /var/log/file1 # the traditional wayif $msg contains 'error' then /var/log/errlog # the expression-based way 现在，如果您想检查设施和严重性，则需要指定数值。 这些可以在RFC 5424中找到。如果你不喜欢，你当然也可以使用文本属性 - 只要确保使用正确的。 随着表达的支持增强，这将会改变。 例如，如果要过滤具有设备local0的消息，请以“DEVNAME”开头，并在其消息内容中包含“error1”或“error0”，您可以使用以下过滤器： 1if $syslogfacility-text == 'local0' and $msg startswith 'DEVNAME' and ($msg contains 'error1' or $msg contains 'error0') then /var/log/somelog 请注意，以上都必须在一行！ 如果你想存储除了那些包含“error1”或“error0”的消息，你只需要添加一个“not”： 1if $syslogfacility-text == 'local0' and $msg startswith 'DEVNAME' and not ($msg contains 'error1' or $msg contains 'error0') then /var/log/somelog 如果您想进行不区分大小写的比较，请使用“contains_i”和“startswith_i”而不是“contains”和“startswith”。 请注意，基于表达式的过滤器目前不支持正则表达式。 当函数支持被添加到表达式引擎时，这些将被添加（原因是正则表达式将是一个单独的可加载模块，这需要更多的前提条件才能实现）。","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"Rsyslog-v8学习笔记五(Property Replacer不匹配模式)","slug":"Rsyslog-v8学习笔记五-Property-Replacer不匹配模式","date":"2016-10-05T10:25:32.000Z","updated":"2017-12-13T10:27:05.884Z","comments":true,"path":"2016/10/05/Rsyslog-v8学习笔记五-Property-Replacer不匹配模式/","link":"","permalink":"http://blog.loveops.com/2016/10/05/Rsyslog-v8学习笔记五-Property-Replacer不匹配模式/","excerpt":"","text":"Property Replacer不匹配模式“不匹配模式”指定属性替换者应该返回哪个字符串，如果正则表达式没有找到搜索字符串。传统上，字符串“不匹配”被返回，但许多人抱怨这几乎是没有用的。不过，这种模式对于传统配置是“DFLT”的支持。 另外还有三种可能有用的模式：在一个（BLANK）中返回一个空白字符串。这对于将值插入数据库中是有用的，如果找不到表达式，则不应插入任何值。 类似的模式是返回字符串“0”的“ZERO”。这适用于数值。用例可能是基于防火墙规则记录流量日志，并通过正则表达式提取“字节传输”计数器。如果当前消息中没有“字节传输”计数器，则返回空字符串（数据库层可以变为零）可能是个好主意。 另一种模式是“FIELD”，其中返回完整的字段。这可能是有用的，如果没有匹配被认为是失败的，并且触发它的消息应该被记录。 如果有疑问，强烈建议使用rsyslog在线正则表达式检查器和生成器来查看这些选项的操作。使用该在线工具，您可以根据样本制作正则表达式并尝试不同的模式。 不匹配模式摘要 Mode Returned DFLT “NO MATCH” BLANK “” (empty string) ZERO “0” FIELD full content of original field 交互式工具： http://www.rsyslog.com/regex/","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"Rsyslog-v8学习笔记四(属性替换器)","slug":"Rsyslog-v8学习笔记四-属性替换器","date":"2016-10-04T10:24:15.000Z","updated":"2017-12-13T10:27:05.884Z","comments":true,"path":"2016/10/04/Rsyslog-v8学习笔记四-属性替换器/","link":"","permalink":"http://blog.loveops.com/2016/10/04/Rsyslog-v8学习笔记四-属性替换器/","excerpt":"","text":"属性替换器属性替换器是rsyslogd的字符串模板系统中的一个核心组件。系统日志消息具有许多定义良好的属性。每个属性都可以被属性替换器访问和操作。有了它，很容易只使用属性值的一部分或操纵该值，例如通过将所有字符转换为小写。 访问属性系统日志消息属性在模板中使用。他们可以通过两个%，由属性替换器修改。完整的语法如下所示： 1%property:fromChar:toChar:options% 可用属性属性替换器可以使用所有的rsyslog属性。 偏移量字段FromChar和toChar被用来构建子串。 他们指定应该复制的字符串内的偏移量。 偏移计数从1开始，所以如果您需要获取消息文本的前2个字符，则可以使用以下语法：“％msg：1：2％”。 如果你不想指定from和to，但是你想指定选项，你仍然需要包含冒号。 例如，如果要将完整的消息文本转换为小写，请使用“％msg :::小写字母％”。 如果你想从一个位置提取直到字符串结尾，你可以在toChar中放置一个美元符号（“$”）（例如％msg：10：$％，它将从位置10提取到结尾 字符串）。 也支持正则表达式。 要使用它们，您需要在FromChar中放置一个“R”。 这告诉rsyslog，正则表达式而不是基于位置的提取。然后必须在toChar中提供实际的正则表达式。 正则表达式后面必须跟着字符串“–end”。它表示正则表达式的结束，不会成为它的一部分。 如果使用正则表达式，则属性替换器将返回与正则表达式匹配的属性文本部分。 具有正则表达式的属性替换序列的示例是：“％msg:R:.Sev:.(.\\）[.*–end％” 在“R”之后可以指定一些参数。 用逗号分隔。 如下： 1R,&lt;regexp-type&gt;,&lt;submatch&gt;,&lt;nomatch&gt;,&lt;match-number&gt; 对于Posix的基本正则表达式，regexp-type是“BRE”，对于扩展的则是“ERE”。 字符串必须用大写字母表示。缺省值是“BRE”，以便与不支持ERE的rsyslog的早期版本保持一致。 子匹配标识要与结果一起使用的子匹配。 支持单个数字。 0是完整匹配，而1比9是acutal submatches。如果表达式在字符串中出现多次，则匹配号标识指定匹配哪个。 请注意，第一个匹配是0，第二个匹配是1等等。 最多支持10个匹配项（0-9）。 请注意，在submatch前面有match-number会更自然，但这会打破向后兼容性。 所以匹配号码必须在“不匹配”之后指定。 nomatch指定在找不到匹配的情况下应该使用的内容。 以下是ERE表达式的一个示例，它从消息字符串中获取第一个子匹配，并在未找到匹配的情况下用完整字段替换表达式： 1%msg:R,ERE,1,FIELD:for (vlan[0-9]\\*):--end% 这需要所述表达式的第二个匹配的第一个子匹配： 1%msg:R,ERE,1,FIELD,1:for (vlan[0-9]\\*):--end% 请注意：还有一个rsyslog正则表达式检查器/生成器在线工具可用。 使用该工具，您可以检查正则表达式，并生成有效的属性替换序列。 建议使用此工具。 根据所提供的版本，该工具可能无法涵盖所有场景，包括最常用的情况。 所以在要求苛刻的环境中手写表达式情仍然很有用。 而且，提取可以基于“filed”来完成。要做到这一点，把一个“F”放入FromChar。当前定义中的字段是由分隔符分隔的任何内容。分隔符默认为TAB（US-ASCII值9）。但是，如果可以通过在“F”之后立即指定逗号和分隔符的十进制US-ASCII值来更改为任何其他US-ASCII字符。例如，要使用逗号（“，”）作为分隔符，请使用此字段说明符：“F，44”。如果您的系统日志数据是分隔的，这是比通过正则表达式（实际上更快的方法）提取更快的方法。字段计数从1开始。字段零被接受，但总是会导致“字段未找到”错误。如果请求的字段数高于属性中的字段数，则会发生同样的情况。字段号必须放在“ToChar”参数中。从msg属性中提取第三个字段（用TAB分隔）的例子如下：“％msg：F：3％”。分号与分隔符相同的例子是“％msg：F，59：3％”。 字段的使用不允许选择子字符串，更不幸的是。为了解决这个问题，从6.3.9开始，可以为字符串指定fromPos和toPos。然而，这个语法是相当丑陋的，但它是将这种功能整合到已经存在的系统中的唯一方法。为此，在字段提取期间使用“fromPos”和“toPos”。让我们假设你想在前面的例子中提取从位置5到9的子字符串。然后，语法如下：“％msg：F，59,5：3,9％”。正如你所看到的，“F，59”表示字段模式，带有分号分隔符，“，5”表示从位置5开始。然后“3,9”表示字段3，字符串提取到位置9。 请注意，特殊字符“F”和“R”区分大小写。只有大写的情况下，小写会返回一个错误。序列中不允许有空格（这将导致错误消息，并不会提供预期的结果）。 每个字段分隔符的出现都会启动一个新的字段。但是，如果在字段分隔符之后添加加号（“+”），则多个分隔符（紧跟其他分隔符之后）会被视为单独的字段。这在syslog消息包含这样的序列的情况下可以是有用的。常见的情况可能是编写如下代码： 123int n, m;...syslog(LOG_ERR, \"%d test %6d\", n, m); 这将在系统日志消息中导致类似这样的事情：“1 test 2”，“1 test 23”，“1 test 234567” 正如你所看到的，这些字段是由空格字符分隔的，但其确切的数字是未知的。 他们可以适当地提取如下： 1\"%msg:F,32:2%\" to \"%msg:F,32+:2%\". 这个特点是由Zhuang Yuyao提出的，由他来执行。 它是在perl兼容正则表达式之后建模的。 属性选项属性选项不区分大小写。 目前，定义了以下选项： uppercase将属性转换为大写 lowercase将属性文本转换为小写 fixed-width更改toChar的行为，以便在源字符串较短的情况下使用空格填充源字符串，直到toChar的值。 这个特性是在rsyslog 8.13.0中引入的 json对值进行编码，以便可以在JSON字段内使用该值。 这意味着几个字符（根据JSON规范）正在被转义，例如US-ASCII LF被替换为“\\ n”。 json选项不能与jsonf或csv选项一起使用。 jsonf[:outname]（在6.3.9+中可用）这表示该属性应该表示为JSON字段。 这意味着不仅属性被写入，而是格式中完整的JSON字段 “fieldname”=”value” 其中在“outname”属性中给出了“fieldname”（如果没有分配属性名称，则为属性名称），value是属性替换操作的最终结果。 请注意，该值支持所有属性替换选项，如子字符串，大小写转换等。 值正确JSON转义，但字段名称目前不行，所以预计正确的字段名称配置。 jsonf选项不能与json或csv选项一起使用。 欲了解更多信息，你可以从Rainer的博客阅读这篇文章。http://blog.gerhards.net/2012/04/rsyslog-templates-json.html csv按照RFC 4180中的规定，以CSV格式格式化所得字段（完成所有修改后）。Rsyslog将始终使用双引号。 请注意，为了具有完整的CSV格式的文本，您需要定义一个适当的模板。 一个例子是这样的：”%syslogtag:::csv%,%msg:::csv%”最重要的是，你需要在模板内的字段之间提供逗号。 这个特性是在rsyslog 4.1.6中引入的。 drop-last-lf消息中的最后一个LF（如果有）将被丢弃。 对PIX特别有用。 date-utc在输出之前将数据转换为UTC（自8.18.0起可用） date-mysql格式为mysql日期 date-rfc3164格式为RFC 3164日期 date-rfc3164-buggyday类似于date-rfc3164，但是模拟了一个常见的编码错误：RFC 3164要求为单位数天写一个空格。 使用此选项，将写入零。 这种格式似乎被syslog-ng使用，而date-rfc3164-buggyday选项可以用于迁移场景，否则很多脚本需要调整。 建议在转发到远程主机时不要使用此选项 - 他们可能会将日期视为无效（尤其是严格按照RFC 3164进行解析时）。 这个特性是在rsyslog 4.6.2和v4以上版本和5.5.3以及所有版本中引入的。 date-rfc3339格式为RFC 3339日期 date-unixtimestamp格式化为一个unix时间戳（自纪元以来的秒数） date-year只是一个时间戳的年份（4位数字） date-month只是一个时间戳的月份（2位数字） date-day只是一个时间戳的天（2位数字） date-hour只是一个时间戳的小时（2位数字，24小时制） date-minute只是一个时间戳的分钟（2位数字） date-second只是时间戳的秒（2位数字） date-subseconds只是时间戳的亚秒（对于低精度时间戳，始终为0） date-tzoffshour只是时间戳的时区偏移小时部分（2位） date-tzoffsmin只是时区的时区偏移分钟部分（2位数字）。 请注意，这通常是0，但是有一些时区的偏移量不是按小时粒度的。 如果是这样，这是分钟的抵消。 date-tzoffsdirection只是时间戳的时区偏移方向部分。 这指定是否需要将时间戳添加（“+”）或减去（“ - ”）以获得UTC。 date-ordinal返回给定日期的序号，例如 1月2日是2 date-week返回周数 date-wday时间戳的周几。 这是一个数字，0 =星期天，1 =星期一，…，6 =星期六。 date-wdayname只是时间戳的星期几的缩写英文名称 (例如： “Mon”, “Sat”) escape-cc用转义序列替换控制字符（ASCII值为127，值小于32）。 序列是“＃”，其中charval是控制字符的3位十进制值。 例如，制表符将被替换为“＃009”。 注意：使用这个选项需要将$ EscapeControlCharactersOnReceive设置为off. space-cc用空格替换控制字符注意：使用这个选项需要将$ EscapeControlCharactersOnReceive设置为off。 drop-cc删除控制字符 - 结果字符串将不包含控制字符，转义序列或任何其他替换字符，如空间。 注意：使用这个选项需要将$ EscapeControlCharactersOnReceive设置为off。 compressspace将字符串内部的多个空格（US-ASCII SP字符）压缩为一个空格。 这种压缩发生在处理的非常晚的阶段。 最重要的是，它在子字符串提取后发生，所以FromChar和ToChar位置不受此选项的影响。 （从v8.18.0开始可用） sp-if-no-1st-sp这个选项看起来很可怕，应该不会被用户使用。对于给定的任何字段，它返回一个空格字符或根本没有字符。字段内容永远不会返回。如果（且仅当）字段内容的第一个字符不是空格，则返回空格。这个选项是解决根源于RFC 3164的问题的一种方法：3164在syslog标记序列和实际的消息文本之间没有指定分隔符。实际上几乎所有的实现都是由一个空格来划分的。从RFC 3164开始，这个空间是消息文本本身的一部分。这在构建消息时（例如写入磁盘或转发时）会导致问题。如果邮件不是从一个开始的，是否应该包含分隔空间？如果没有，标签之后紧跟着另一个非空格字符，这可能导致一些日志解析器误解标签和消息是什么。当klog模块被重新构建并且标签正确写入时，问题最终浮出水面。它也与其他消息源一起存在。解决方案是引入这个特殊的财产替代选项。现在，默认模板可以包含一个条件空间，只有在消息不是以一个开头的情况下才存在。虽然这不能解决所有问题，但在绝大多数情况下，它应该工作得很好。如果你阅读这个文本，不知道它在说什么 - 放松：这是一个很好的迹象，你永远不会需要这个选项。简单地忘掉它;） secpath-drop去掉字段内反斜线（例如，“a/b”变成“ab”）。 用于安全路径名的生成（使用动态文件）。 secpath-replace用下划线替换字段内的斜线。 （例如“a/b”变成“a_b”）。 用于安全路径名的生成（使用动态文件）。 要使用多个选项，只需将它们一个接一个地用逗号分隔。 例如“escape-cc，sp-if-no-1st-sp”。 如果一起使用冲突选项，则最后一个将覆盖前一个选项。 例如，使用“escape-cc，drop-cc”将使用drop-cc，“drop-cc，escape-cc”将使用escape-cc模式。","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"rsyslog-v8学习笔记三(Rsyslog属性)","slug":"rsyslog-v8学习笔记三-Rsyslog属性","date":"2016-10-03T14:14:18.000Z","updated":"2017-12-12T14:15:21.730Z","comments":true,"path":"2016/10/03/rsyslog-v8学习笔记三-Rsyslog属性/","link":"","permalink":"http://blog.loveops.com/2016/10/03/rsyslog-v8学习笔记三-Rsyslog属性/","excerpt":"","text":"Rsyslog属性rsyslog中的数据项称为“属性”。 他们可以有不同的起源。 最重要的是那些源于收到的消息。 但也有其他的。 无论何时您想要访问数据项目，都需要访问相应的属性。属性名称不区分大小写（在3.17.0之前，区分大小写）。属性用于： 模板 条件语句 message属性这些由rsyslog解析器从原始消息中提取。所有消息属性都以字母开头。以下是存在的消息属性： msg消息的MSG部分（又名“消息”;）） rawmsg消息原样。应该对调试有用，消息完全没有改变。请注意，EscapecontrolCharactersOnReceive是默认启用的，所以它可能与套接字中收到的不同。 rawmsg-after-pri与rawmsg几乎相同，但系统日志PRI被删除。如果不存在PRI，则rawmsg-after-pri与rawmsg相同。请注意，系统日志PRI是标题字段，其中包含有关syslog设施和严重性的信息。它被包含在”&lt;&gt;”中，例如“”。这个字段通常不会写入日志文件，但通常需要让接收者正确分类消息。有一些罕见的情况下，需要原始信息，但不是PRI。您可以使用此属性来获取该属性。一般来说，你应该知道你需要这种格式，否则远离财产。 hostname消息的主机名 sourcehostname的别名 fromhost消息来源的主机名（在中继链中，这是紧挨着我们而不一定是原始发送者的系统）。这是DNS解析的名称，除非DNS解析已被禁用。 fromhost-ip与fromhost相同，但始终作为IP地址。本地输入（如imklog）在此属性中使用127.0.0.1。 syslogtagTAG来自消息 programname标记的“static”部分，由BSD syslogd定义。例如，当TAG是“named[12345]”时，程序名是“named”。确切地说，程序名是由（以先发生者为准）终止： 12345- end of tag- nonprintable character- “：”- “[”- “/” 上面的定义是由FreeBSD的syslogd定义的 请注意，一些应用程序在标签的静态部分包括斜线，例如“app/ foo[1234]”。在这种情况下，程序名是“app”。如果是绝对路径像“/app/foo [1234]”，则程序名将变为空（“”）。如果您需要将斜杠作为程序名的一部分，则可以使用全局选项 1global(parser.permitSlashInProgramName=”on”) 开启以后，“/app/foo[1234]”的syslogtag将“/app/ foo”作为程序名。注意：此选项从rsyslogd版本8.25.0开始可用。 pri消息的PRI部分 - 未解码（单个值） pri-text消息的PRI部分以文本形式，括号中附有数字PRI（例如“local0.err ”） iutmonitorware InfoUnitType - 与MonitorWare后端交谈时使用（也适用于Adiscon LogAnalyzer） syslogfacility消息中的设施 - 以数字形式 syslogfacility-text消息中的设施 - 以文本形式 syslogseverity来自消息的严重性 - 以数字形式 syslogseverity-text来自消息的严重性 - 以文本形式 syslogprioritysyslogseverity的别名 - 包含历史原因（小心：它仍然是严重性，不是PRI！） syslogpriority-textsyslogseverity-text的别名 timegenerated邮件收到时的时间戳。始终在高分辨率 timereported来自消息的时间戳。分辨率取决于消息中提供的内容（大多数情况下只有几秒钟） timestamp时间报告的别名 protocol-versionIETF draft-ietf-syslog-protcol草案中的PROTCOL-VERSION字段的内容 structured-dataIETF草案draft-ietf-syslog-protocol中的STRUCTURED-DATA字段的内容 app-nameIETF draft-ietf-syslog-protocol中APP-NAME字段的内容 procidIETF草稿draft-ietf-syslog-protocol中的PROCID字段的内容 msgidIETF草案draft-ietf-syslog-protocol中的MSGID字段的内容 inputname生成消息的输入模块的名称（例如“imuxsock”，“imudp”）。请注意，并非所有模块都必须提供此属性。如果没有提供，它是一个空字符串。还要注意，输入模块可以提供任何喜欢的值。最重要的是，它不一定是模块的输入名称。内部来源也可以提供输入名称。目前，“rsyslogd”被定义为由rsyslogd内部生成的消息的输入名称，例如启动和关闭以及错误消息。当尝试根据消息来源过滤消息时，该属性被认为是有用的，例如，本地生成的消息（“rsyslogd”，“imuxsock”，“imklog”）应该到别处生成的消息到不同的地方。 jsonmesg 自rsyslog 8.3.0起可用,整个消息对象作为JSON表示。请注意，JSON字符串将不包含LF，它将包含此处指定为各自JSON容器的所有其他消息属性。 它还包含“$！”subtree中的所有消息变量（如果不存在，则可能为空）。 这个属性主要是作为一个接口到其他系统和工具，想要访问完整的属性集（即外部插件）。 请注意，它可能会多次包含相同的数据项。 例如，syslog标签的一部分将被包含在rawmsg，syslogtag和programname属性中。 因此，这个属性有一些额外的开销。 因此，建议仅在实际需要时才使用。 系统属性这些属性由rsyslog核心引擎提供。它们与消息无关。所有系统属性都以美元符号开始。 需要特别注意与时间相关的系统变量： timereported 包含消息头中包含的时间戳。理想情况下，它类似于在原始发件人创建邮件的时间。根据信息在中继链中的时间长短，这可能是相当古老的。 timegenerated 包含本地系统收到消息时的时间戳。这里“收到”实际上是指消息从操作系统移交给rsyslog的接收缓冲区的时间点，但在进行任何实际处理之前。这也意味着一条消息在被放入任何队列之前被“接收”。请注意，取决于输入，可能会发生一些最小的处理，例如从接收缓冲区中提取实际的消息内容。如果通过相同的接收缓冲区接收多个消息（例如基于TCP的syslog的常见情况），则它们具有相同的时间生成标记，因为它们实际上是同时接收的。 $now 不是来自消息。是处理消息的是系统时间。timegenerated和$now总是有小的差别，因为处理总是在接收之后发生。如果消息位于本地系统的队列中，那么两个消息之间的时间差可以是几秒钟（例如，由于消息突发和内存中的排队），消息在如果磁盘队列中，极端情况下时间差甚至是几小时，（例如由于数据库中断）。 timereported属性通常比timegenerated更早，但由于系统之间的时间和时区配置的差异，可能会完全不同。以下系统属性存在： $ BOMUTF-8编码的Unicode字节顺序掩码（BOM）。当字符集被认为是Unicode时，这在RFC5424支持的模板中可能是有用的。$ myhostname当前主机的名称，因为它知道自己（可能有用于通用的方式过滤） 时间相关系统属性所有这些时间系统属性都以本地时间变量（例如$ now）和UTC时间衍生出来的（例如$ now-utc）存在。 UTC变体始终可以通过追加“-utc”来使用。 请注意，在单个模板中，只能使用本地时间或UTC变量。 尽管可以在一个模板中混合两个变体，但不能保证它们提供的时间完全相同。 技术上的原因是rsyslog需要重新查询系统时间。 因此，我们强烈建议不要在同一个模板中混合两个变体。 请注意，在不同模板中使用将在每个模板中生成一致的时间戳。 但是，由于$now 在使用时总是提供本地系统时间，因此时间可能会提前，因此不同的模板可能具有不同的时间戳。 为了避免这种情况，请使用timegenerated。 $now当前日期标记，格式为YYYY-MM-DD $year当年 (4位数) $month当月 (2位数) $day当月的当天 (2位数) $hour当前的（24小时）时间（2位数） $hhour我们现在的半个小时。从0分到29分，从30分到59分总是1。 $qhour四分之一时间，很像$ HHOUR，但是取值范围从0到3（相当于一小时4刻钟） $minute当前分钟（2位）","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"rsyslog-v8学习笔记二(模板)","slug":"rsyslog-v8学习笔记二-模板","date":"2016-10-02T13:02:23.000Z","updated":"2017-12-12T13:04:54.420Z","comments":true,"path":"2016/10/02/rsyslog-v8学习笔记二-模板/","link":"","permalink":"http://blog.loveops.com/2016/10/02/rsyslog-v8学习笔记二-模板/","excerpt":"","text":"模板 模板是rsyslog的一个关键特性。它们允许用户自定义需要的任何格式。也用于生成动态文件名。 rsyslog中的每个输出都使用模板， 这适用于文件，用户消息等。数据库编写者期望它的模板是一个适当的SQL语句 - 所以这也是高度可定制的。您可能会问，如果没有指定模板，所有这些工作是如何进行的。好问题 ;）。但答案很简单。模板与硬编码到rsyslogd的stock syslogd格式兼容。所以如果没有指定模板，我们使用这些硬编码模板之一。在rsconf.c中搜索“template_”，你会发现硬编码的。 模板由template()语句指定。它们也可以通过$template老版本语句指定。 注意：模板的关键元素是rsyslog属性。请参阅rsyslog属性参考以获取可用列表。 模版处理 由于缺乏关于日志格式的标准化，当一个模板被指定时，它应该包含HEADER，如RFC5424中所定义的 记住这一点非常重要，以及如何理解rsyslog解析如何工作 例如，如果MSG字段被设置为“this：is message”而没有HOSTNAME，那么两个TAG都不被指定，output解析器会将消息拆分为： 12TAG:this:MSG:is a message template()语句template（）语句用于定义模板。请注意，这是一个静态语句，这意味着所有模板都是在rsyslog读取配置文件时定义的。因此，模板不受if语句或配置嵌套的影响。 模板语句的基本结构如下： 1template(parameters) 除了这个更简单的语法之外，列表模板（将在下面描述）支持扩展语法： 1template(parameters) &#123; list-descriptions &#125; 每个模板都有一个指定模板名称的参数名称和一个指定模板类型的参数类型。 name参数必须是唯一的，如果不是，行为是不可预知的。类型参数指定不同的模板类型。不同的类型只是使用不同的方式来指定模板内容。模板类型不影响（输出）插件可以用它做什么。因此，请使用最适合您需求的类型（从配置书写的角度来看！）。以下类型可用： list subtree string plugin 下面介绍各种类型： list在这种情况下，模板是由一系列常量和变量语句生成的。这些遵循大括号中的模板规范。这种类型也主要用于结构感知输出，如ommongodb。但是，它也适用于基于文本的输出。如果需要更复杂的属性替换，我们建议使用这种模式。在这种情况下，基于列表的模板语法比简单的基于字符串的语法清晰得多。 列表模板包含模板头（type =“list”），后面跟着常量和属性语句，用花括号表示它们所属的模板语句。正如名字所说，常量语句描述了常量文本和属性描述了属性访问。财产有很多选择，下面进一步描述。大多数这些选项只用于提取部分属性内容或修改所获得的文本（如仅将大小写更改为大写或小写）一个例子： 1234567template(name=\"tpl1\" type=\"list\") &#123; constant(value=\"Syslog MSG is: '\") property(name=\"msg\") constant(value=\"', \") property(name=\"timereported\" dateFormat=\"rfc3339\" caseConversion=\"lower\") constant(value=\"\\n\") &#125; #这个示例可能主要针对通常的基于文件的输出。 常量定义（constant statement） 这提供了一种指定常量文本的方法。它主要用于基于文本的输出，因此可以包含一些常量文本。 例如，如果为文件输出构建复杂的模板，通常需要用换行符来完成，可以通过常量语句来引入。 下面是rsylsog测试平台的实际使用案例： 1234template(name=\"outfmt\" type=\"list\") &#123; property(name=\"$!usr!msgnum\") constant(value=\"\\n\")&#125; 以下转义字符在常量文本中被识别： \\ - 单个反斜杠 \\ n - LF \\ ooo - （三个八进制数字） - 表示具有此数值的字符（例如\\ 101等于“A”）。 请注意，必须给出三个八进制数字（与一到三个是有效的语言不一样）。 虽然我们支持八进制表示法，但我们建议使用十六进制表示法，因为这更为人所知。 \\ xhh - （其中h是十六进制数字） - 表示具有此数值的字符（例如\\ x41等于“A”）。 请注意，必须给出两个十六进制数字（与一到三个是有效的语言不一样）。 其他的需要扩展 注意：如果一个不支持的字符出现在反斜杠之后，这会被视为错误。 在这种情况下行为是不可预测的。 为了帮助使用基于文本的输出和结构化输出的相同模板，创建结构化输出的名称/值树时，将忽略不带“outname”参数的常量文本，所以，如果你想提供一些常量文本，例如 到mongodb，你必须包括一个outname参数，如下所示： 1234template(name=\"outfmt\" type=\"list\") &#123; property(name=\"$!usr!msgnum\") constant(value=\"\\n\" outname=\"IWantThisInMyDB\")&#125; “常量”语句支持以下参数： value - 使用的常数值 outname - 输出字段名称（用于结构化输出） 属性定义 此字段用于包含属性的文本。 它可以访问所有的属性。 此外，选项允许指定仅属性的一部分或修改它。 它支持以下参数： name - 要访问的属性的名称 outname - 输出字段名称（用于结构化输出） dateformat - 日期格式（仅用于与日期相关的属性） date.inUTC - 日期应以UTC显示（请注意，由于必要的转换，这需要更多的性能）自8.18.0起可用。 caseconversion - 大小写转转，支持”lower”和”upper” controlcharacters - 控制字符. 支持 “escape”, 转义, “space”, 替换为空格, “drop”, 从字符串中删除 securepath - 用于创建适合在dynafile模板中使用的路径名 format - 指定格式 支持： 12345\"CSV\" 生成csv-data时使用“csv”“JSON” 格式适当的JSON内容（但没有字段标题）“jsonf” 格式为完整的json字段“jsonr” 避免了双重转义的价值，但使json字段的安全“jsonfr” “jsonr”和\"jsonf\"的组合的“jsonfr”。 position.from - 获取从这个位置开始的子串（1是第一个位置） position.to - 获得这个位置的子串 position.relativeToEnd - from和to的位置是相对于字符串的结尾，而不是通常的字符串开头。 （自rsyslog v7.3.10以后可用） fixedwidth - 改变position.to的行为，以便如果源字符串较短，则将源字符串的空格填充到position.to的值。 “on”或“off”（默认）（自rsyslog v8.13.0以后可用） compressspace - 将字符串内部的多个空格（US-ASCII SP字符）压缩为一个空格。 这种压缩发生在处理的非常晚的阶段。 最重要的是，它发生在子字符串提取后，所以position.from和position.to位置不受此选项的影响。 （从v8.18.0开始可用）。 field.number - 获取字段匹配 field.delimiter - 字段提取的分隔符 regex.expression - 正则表达式 regex.type - 正则表达式类型：扩展正则表达式或者基本表达式 regex.nomatchmode - 没匹配大埔的动作 regex.match - 使用匹配 regex.submatch - 使用submatch droplastlf - drop a trailing LF, if it is present mandatory - 表示一个字段是强制性的。如果设置为“on”，即使该数据为空，该字段也将始终存在于传递给结构化输出的数据中。如果“off”（默认）空字段不会传递到结构化输出。 这对于支持动态模式的输出（如ommongodb）特别有用。 spifno1stsp - RFC3164模板处理的专家选项 subtree自rsyslog 7.1.4起可用 在这种情况下，模板是基于完整（CEE）子树生成的。这种类型的模板对于知道如何处理层次结构的输出（如ommongodb）非常有用。使用该类型时，必须指定subtree参数子树，该参数会指示使用哪个subtree。例如template（name =“tpl1”type =“subtree” subtree =“$！”）包括所有CEE数据，而template（name =“tpl2”type =“subtree” subtree =“$！usr！tpl2”）包括只有以$!user!tpl2开头的subtree。使用这种类型的模板的核心思想是实际的数据是通过set和unset的脚本语句预制的，然后在模板内使用生成的结构。如果需要将完整的suntree直接放置到对象的根目录中，则必须使用此方法。使用所有其他模板类型，只能生成子容器。请注意，subtree类型也可以与基于文本的输出一起使用，如omfile。但是，您没有任何指定常量文本，因此不能包含换行符。因此，对于文本输出使用此模板类型通常仅对调试或非常特殊的情况（例如稍后由JSON解析器解释文本的位置）有用。 使用场景一个典型的用例是首先创建一个自定义的子树，然后将其包含到模板中，就像这个小例子一样： 123set $!usr!tpl2!msg = $msg;set $!usr!tpl2!dataflow = field($msg, 58, 2);template(name=\"tpl2\" type=\"subtree\" subtree=\"$!usr!tpl2\") 在这里，我们假设$ msg包含各种字段，并且来自字段的数据将作为字段内容与消息一起被提取和存储。 字符串（string）这非常类似于老版本的模板语句。它有一个必需的参数字符串，它保存要应用的模板字符串。 模板字符串是常量文本和替换变量的混合（请参阅属性替换器）。 当生成传递给插件的最终字符串时，这些变量将从消息或其他动态内容中获取。 基于字符串的模板是指定文本内容的好方法，特别是如果不需要对属性进行复杂的操作。这是一个基于字符串模板的示例： 123template(name=\"tpl3\" type=\"string\" string=\"%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg:::drop-last-lf%\\n\" ) 百分号（’％’）之间的文本由rsyslog属性替换器解释。 简而言之，它包含要使用的属性以及用于格式化和进一步处理的选项。 这与列表模板中的属性对象非常相似（它实际上是用不通方式表达大部分相同事物）。 百分号以外的所有内容都是不变的文本。就像上面的例子中，我们大多数属性值之间的空格。 在字符串的末尾，使用转义符。 转义符允许指定不可打印的字符。他们的工作非常类似于C和许多其他语言的转义符。 它们由反斜杠字符开始，后跟一个或多个指定实际字符的字符。 例如\\ 7是US-ASCII BEL字符，\\ n是一个换行符。 这个集合与C和Perl支持的类似，但是有一些限制。 plugin在这种情况下，模板由一个插件生成（然后称为“strgen”或“字符串生成器”）。 这种格式在编码时是固定的。虽然这是不灵活的，它提供了卓越的性能，这个是经常使用的原因（不是“常规”模板是慢的，但在非常苛刻的环境下，“最后一刻”可以有所作为）。 有关更多详细信息，请参阅插件的文档。 对于这种类型，必须指定参数插件，并且必须包含插件名称，因为它标识了自身。 请注意，插件必须在模板内部使用之前加载。 配置示例： 1template(name=\"tpl4\" type=\"plugin\" plugin=\"mystrgen\") options是可选的。 作为模板参数的一部分，它将影响整个模板。 具体见下面的细节。 请务必不要将模板选项与属性选项相混淆 - 后者由属性替换器处理，仅适用于SINGLE属性（而不适用于整个模板）。 模板选项不区分大小写。 目前定义的是： option.sql - 格式化适合于MySQL格式的SQL语句的字符串。 字符串中单引号（“’”）和反斜线将被转义符”\\”转义 请注意，在MySQL配置中，必须关闭NO_BACKSLASH_ESCAPES模式才能使这种格式起作用（这是默认设置）。 option.stdsql - 格式化适合要发送到符合标准的sql服务器的SQL语句的字符串。 这将在每个字段内用两个单引号（“’’”）替换单引号（“’”）。 如果在MySQL配置中启用了NO_BACKSLASH_ESCAPES，则必须与MySQL一起使用stdsql。 option.json - 格式化适合json语句的字符串。在每个字段内用两个单引号（“’’”）替换单引号（“’”）。 option.casesensitive - 将属性名称引用视为区分大小写。 默认值是“off”，其中所有属性名称引用在模板定义期间首先转换为小写。 将此选项打开后，将按照模板中的定义查找属性名称。 如果您具有包含大写字母的JSON（$！），local（！。）或global（$！\\ *）属性，请使用此选项。正常的Rsyslog属性是不区分大小写的，所以这个选项不需要正确引用那些属性。 使用选项option.sql，option.stdsql和option.json是互斥的。 同时使用多个可能导致不可预知的行为。 当使用模板写入数据库时​​，必须指定sql或stdsql选项，否则可能会发生注入。请注意，由于不幸的事实，有几家供应商违反了SQL标准，并引入了自己的逃生方法，所以不可能有一个单一的选择做所有的工作。所以你自己一定要确保你使用的是正确的格式。如果你选错了，你仍然很容易sql注入。请注意，数据库编写器会检查模板中是否存在sql选项。如果不存在，则写入数据库操作将被禁用。这是为了防止意外忘记它，然后变得容易受到SQL注入。 sql选项对于文件也是有用的 - 特别是如果你想将它们导入另一台机器上的数据库时，出于性能的考虑。但是，如果您没有真正的需求，就不要使用它 - 除此之外，处理时间会受到一些影响。不多，但在一个非常繁忙的系统上，您可能会注意到它。 写入数据库操作的默认模板具有设置的sql选项。 由于我们目前仅支持MySQL，并且SQL选项与默认的MySQL配置相匹配，所以这是一个不错的选择。 但是，如果您在MySQL配置中打开了NO_BACKSLASH_ESCAPES，则需要提供一个带有stdsql选项的模板。 否则，你将变得容易SQL注入。 12template (name=\"TraditionalFormat\" type=\"string\"string=\"%timegenerated% %HOSTNAME% %syslogtag%%msg%\\\\n\" 范例 写入文件的标准模板 12345678910template(name=\"FileFormat\" type=\"list\") &#123; property(name=\"timestamp\" dateFormat=\"rfc3339\") constant(value=\" \") property(name=\"hostname\") constant(value=\" \") property(name=\"syslogtag\") property(name=\"msg\" spifno1stsp=\"on\" ) property(name=\"msg\" droplastlf=\"on\" ) constant(value=\"\\n\") &#125; 等效的字符串模板如下所示：（请注意，模板字符串本身必须在一行上。） 123template(name=\"FileFormat\" type=\"string\" string= \"%TIMESTAMP% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg:::drop-last-lf%\\n\" ) 用于转发到远程主机的标准模板（RFC3164模式） 123456789101112template(name=\"ForwardFormat\" type=\"list\") &#123; constant(value=\"&lt;\") property(name=\"pri\") constant(value=\"&gt;\") property(name=\"timestamp\" dateFormat=\"rfc3339\") constant(value=\" \") property(name=\"hostname\") constant(value=\" \") property(name=\"syslogtag\" position.from=\"1\" position.to=\"32\") property(name=\"msg\" spifno1stsp=\"on\" ) property(name=\"msg\") &#125; 等效的字符串模板如下所示：（请注意，模板字符串本身必须在一行上。） 123template(name=\"forwardFormat\" type=\"string\" string=\"&lt;%PRI%&gt;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag:1:32%%msg:::sp-if-no-1st-sp%%msg%\" ) 用于写入MySQL数据库的标准模板： 1234567891011121314151617181920template(name=\"StdSQLformat\" type=\"list\" option.sql=\"on\") &#123; constant(value=\"insert into SystemEvents (Message, Facility, FromHost, Priority, DeviceReportedTime, ReceivedAt, InfoUnitID, SysLogTag)\") constant(value=\" values ('\") property(name=\"msg\") constant(value=\"', \") property(name=\"syslogfacility\") constant(value=\", '\") property(name=\"hostname\") constant(value=\"', \") property(name=\"syslogpriority\") constant(value=\", '\") property(name=\"timereported\" dateFormat=\"mysql\") constant(value=\"', '\") property(name=\"timegenerated\" dateFormat=\"mysql\") constant(value=\"', \") property(name=\"iut\") constant(value=\", '\") property(name=\"syslogtag\") constant(value=\"')\") &#125; 等效的字符串模板如下所示：（请注意，模板字符串本身必须在一行上。） 123template(name=\"stdSQLformat\" type=\"string\" option.sql=\"on\" string=\"insert into SystemEvents (Message, Facility, FromHost, Priority, DeviceReportedTime, ReceivedAt, InfoUnitID, SysLogTag) values ('%msg%', %syslogfacility%, '%HOSTNAME%', %syslogpriority%, '%timereported:::date-mysql%', '%timegenerated:::date-mysql%', %iut%, '%syslogtag%')\" ) 为omfile创建动态文件名： 可以使用模板来生成具有动态文件名称的操作。 例如，如果要将不同主机的系统日志消息拆分为不同的文件（每个主机一个），则可以定义以下模板： 1template (name=\"DynFile\" type=\"string\" string=\"/var/log/system-%HOSTNAME%.log\") 老版本的例子： 1$template DynFile,\"/var/log/system-%HOSTNAME%.log\" 这个模板可以在定义动作时使用。 这将动态生成类似一下文件“/var/log/system-localhost.log” 老版本格式在rsyslog的v6以前版本中，您需要使用$ template语句来配置模板。 它们提供了基于字符串和插件的模板。 传统语法在v7中可以继续使用，但是我们建议新编写的配置文件避免使用老版本格式。 传统和当前的配置语句可以在同一个配置文件中共存。 通用语法： 1$template name,param[,options] 其中“name”是模板名称，“param”是指定模板内容的单个参数。 可选的“options”部分用于设置模板选项。 string该参数与当前的字符串参数一样，例如： 1$template strtpl,\"PRI: %pri%, MSG: %msg%\\n\" 请注意，列表模板在老版本中不可用，所以您需要使用复杂的属性替换器构造来完成复杂的事情。 plugin 这相当于“插件”类型 -type指令。 这里的参数是插件的名字，前面加了一个等号。 一个例子是： 1$template plugintpl,=myplugin 保留的模板名称以“RSYSLOG_”开头的模板名称被保留用于rsyslog使用。一般不使用它们，否则可能会发生冲突（以及相当不可预知的行为）。您可以使用一小组预定义的模板，而无需对其进行定义： RSYSLOG_TraditionalFileFormat - 具有低精度时间戳的“旧式”默认日志文件格式 RSYSLOG_FileFormat - 与传统文件格式类似的现代风格日志文件格式，具有高精度时间戳和时区信息 RSYSLOG_TraditionalForwardFormat - 具有低精度时间戳的传统转发格式。如果您将消息发送到其他syslogd或rsyslogd版本3.12.5以下，则最有用。 RSYSLOG_SysklogdFileFormat - sysklogd兼容的日志文件格式。如果使用选项：$ SpaceLFOnReceive on，$ EscapeControlCharactersOnReceive off，$ DropTrailingLFOnReception off，则日志格式将符合sysklogd日志格式。 RSYSLOG_ForwardFormat - 与传统的高精度转发格式非常相似，但具有高精度时间戳和时区信息。建议在发送消息到rsyslog 3.12.5或更高版本时使用。 RSYSLOG_SyslogProtocol23Format - IETF的Internet-draft ietf-syslog-protocol-23中指定的格式，它非常接近实际的系统日志标准RFC5424（当RFC5424最终获得批准时，我们无法更新此模板， ）。这种格式包括几个改进。您可以使用rsyslog或syslogd的所有相对较新版本的格式。 RSYSLOG_DebugFormat - 用于解决属性问题的特殊格式。这种格式是为了写入日志文件。不要用于生产或远程转发。 老版本的基于字符串的模板样本本节提供了一些传统格式的默认模板，如第6版之前的rsyslog中所使用的。请注意，此格式仍受支持，因此不需要升级现有配置。 不过，强烈建议在制作新模板时不要使用旧版结构。 请注意，每个$ template语句都在一行中，但是可能会由于浏览器显示而在几行中断裂。由空行分隔。 请记住，换行符在传统格式中很重要。 12345$template FileFormat,\"%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg:::drop-last-lf%\\n\"$template TraditionalFileFormat,\"%TIMESTAMP% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg:::drop-last-lf%\\n\"$template ForwardFormat,\"&lt;%PRI%&gt;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag:1:32%%msg:::sp-if-no-1st-sp%%msg%\"$template TraditionalForwardFormat,\"&lt;%PRI%&gt;%TIMESTAMP% %HOSTNAME% %syslogtag:1:32%%msg:::sp-if-no-1st-sp%%msg%\"$template StdSQLFormat,\"insert into SystemEvents (Message, Facility, FromHost, Priority, DeviceReportedTime, ReceivedAt, InfoUnitID, SysLogTag) values ('%msg%', %syslogfacility%, '%HOSTNAME%', %syslogpriority%, '%timereported:::date-mysql%', '%timegenerated:::date-mysql%', %iut%, '%syslogtag%')\",SQL``","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"rsyslog-v8学习笔记一(基本结构)","slug":"rsyslog-v8学习笔记一-基本结构","date":"2016-10-01T13:00:08.000Z","updated":"2017-12-12T13:01:57.392Z","comments":true,"path":"2016/10/01/rsyslog-v8学习笔记一-基本结构/","link":"","permalink":"http://blog.loveops.com/2016/10/01/rsyslog-v8学习笔记一-基本结构/","excerpt":"","text":"基本结构本节描述rsyslog配置如何工作。把rsyslog想象成一个大的日志记录和事件处理工具集。它可以被认为是一个基本的处理框架，在数据流的方式上是固定的，但是在这个消息流的细节中是高度可定制的。在配置期间，通过定义和自定义rsyslog对象完成此定制 消息流和对象的快速概述消息在输入模块的帮助下输入rsyslog。然后，它们被传递给一个规则集，在那里有条件地应用规则。当规则匹配时，该消息被转移到一个动作，然后对该消息做一些事情，例如，将其写入文件，数据库或将其转发给远程主机。 处理原则 输入(input)提交收到的消息到规则集(rulesets),如果规则集没有特别绑定，则使用默认规则集,默认情况下，有一个规则集（RSYSLOG_DefaultRuleset） 额外的规则集可以是用户定义的,每个规则集都包含零个或多个规则规则集中虽然允许有零个规则，但是这没有什么意义。 一个规则由一个过滤器和一个动作列表组成，过滤器通过是否匹配而控制流量的能力，如果过滤器“匹配”（过滤器说“是”），则执行相应的动作列表。如果不匹配，没有什么特别的事情发生 规则集将从第一个到最后一个规则按顺序进行处理。所有的规则将得到充分的处理，不管过滤器是否匹配（在第一次匹配以后并不停止）。如果消息处理应该停止，则必须明确执行“丢弃”操作（波浪号或停止命令）。如果丢弃被执行，消息处理立即停止，将不再处理任何进一步的规则。 一个动作列表包含一个或多个动作，在动作列表中不可能有更多的过滤器要在列表中有多个动作，必须将＆符号放置在过滤器的位置，并且必须紧跟前一个动作，动作包括动作调用本身（例如“：omusrmsg：”）以及所有动作定义的配置语句（$ Action …指令），如果使用传统格式（请参见下文），则必须在要配置的操作前面指定$ Action …指令一些配置指令在应用之后自动引用它们以前的值，而另一些则不是。详细信息请参阅相应的文档。被警告，这目前并不总是适当的文件。 一般来说，rsyslog v5是严重过时的，它的原生配置语言是很难理解。 rsyslog项目强烈建议至少使用版本7，其中解决了这些问题，配置更容易。 传统配置语句（以$开头）不会影响RainerScript对象（例如动作） 配置文件 启动时，rsyslog默认从rsyslog.conf文件读取其配置。该文件可能包含引用以包含其他配置文件。 可以通过-f rsyslogd命令行选项指定不同的“根”配置文件。这通常在一些init脚本或类似的设施内完成。 语句类型Rsyslog同时支持三种不同类型的配置语句： sysklogd： 这是普通的旧格式，对于简单的用例还是非常有用的。请注意，某些结构不再受支持，因为它们与较新的功能不兼容。这些在兼容性文档中提到。 老版本的rsyslog：这些是以$开头的语句。他们设置了一些配置参数,例如actions操作。这是rsyslog的v6以前版本中唯一支持的格式。在v6及更高版本中仍然完全支持。请注意，一些插件和功能可能仍然只能通过传统格式（因为插件需要升级才能使用新的样式格式，并不是所有插件）。 RainerScript： 新的样式格式。这是用于更复杂情况的最好和最精确的格式。这个页面的其余部分假定基于RainerScript的rsyslog.conf。 rsyslog.conf文件由语句组成。对于旧式（sysklogd＆legacy rsyslog），行确实很重要。对于新的风格（RainerScript）行间距是无关紧要的。最重要的是，这意味着新的风格行为，所有其他对象可以按照用户的需要进行分割。 推荐使用的Statement类型 一般来说，建议使用RainerScript类型的语句，因为这些语句提供了清晰易读的流程控制，以及哪些参数处于活动状态。它们也没有包含文件的副作用，这可能是老版本rsyslog语句的主要障碍。 对于非常简单的事情，仍然建议使用sysklogd语句类型，特别是如果完整的配置包含这样简单的事情。比如写入文件（或转发）。在sysklogd中，配置如下： 12mail.info /var/log/mail.logmail.err @server.example.net 这个比较简单，许多人知道这个语法。甚至在编写新的配置文件中使用这些语法也是完全正确的。 根据经验，RainerScript配置语句应该以下场景中使用 需要配置参数（例如，老版本的action类型） 需要更详细的流程控制（例如，当多个actions必须在相同条件下嵌套时） 通常，以$开头的指令不建议使用。另外，一些设置和模块尚未转换为RainerScript。在这些情况下，必须使用传统语法。 注释配置文件中有两种注释的方法： #号开头的行 以 / 开头，以 /结尾 处理顺序指令从rsyslog.conf的顶部处理到底部。顺序很重要。例如，如果您停止处理消息，停止语句之后的所有语句都不会被评估。 流程控制语句流量控制由以下提供：控制语句和filter模块 变量操作语句变量操作是通过set，unset和reset语句来实现的，这些语句在后面详细介绍 输入模块儿每个输入都需要加载一个输入模块并为其定义一个监听器。完整的细节可以在rsyslog模块文档中找到。加载后，通过input（）对象定义输入 输出模块儿 outputs也被成为”actions”,必须要预先加载(比如输出到文件，几乎在每个rsyslog.conf中都使用)，其他的必须像输入一样加载。 通过action（type =“type”…）对象调用一个动作。 Type是强制性的，并且必须包含要调用的插件的名称（例如“omfile”或“ommongodb”）。其他参数可能存在。他们的类型和使用取决于问题的输出插件。 规则集和规则 规则集和规则构成了rsyslog处理的基础。总之，规则是rsyslog如何处理特定消息的一种方式。通常，在规则前面有一种过滤器（if语句）。规则的复杂嵌套是可能的，就像在编程语言中一样。 规则集是规则的容器。一个规则集可以包含许多规则。在编程语言的比喻中，人们可能会想到像程序一样的规则集。规则集可以“绑定”（分配）到特定的输入。在类推中，这意味着当一个消息通过这个输入进来时，绑定到它的“程序”（规则集）将被执行（但不是任何其他的！）。 详细可参考rsyslog规则集文档。为了快速参考，规则集定义如下： 12345ruleset(name=\"rulesetname\") &#123; action(type=\"omfile\" file=\"/path/to/file\") action(type=\"...\" ...) /* and so on... */&#125;","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"rsyslog","slug":"rsyslog","permalink":"http://blog.loveops.com/tags/rsyslog/"}]},{"title":"iptables详解","slug":"iptables详解","date":"2015-12-19T13:56:59.000Z","updated":"2017-12-19T14:57:56.178Z","comments":true,"path":"2015/12/19/iptables详解/","link":"","permalink":"http://blog.loveops.com/2015/12/19/iptables详解/","excerpt":"","text":"iptables介绍iptables 是一个配置linux内核防火墙的命令行工具，是netfilter项目的一部分，netfilter才是真正的防火墙框架，netfilter位于内核空间，iptables位于用户空间。一般情况下，我们说iptables也代指内核防火墙 iptables 4表5链4表： raw 用于配置数据包，raw 中的数据包不会被系统跟踪。 filter 用于配置数据包，raw 中的数据包不会被系统跟踪。 nat 用户网络地址转换 mangle 用于对特定数据包的修改 5链 prerouting input forward output postrouting iptables数据流向 通过上图可以看出数据包有三个流向： 到本机进程的报文: PREROUTING–&gt;INPUT 有本机转发的报文: PREROUTING–&gt;FORWORD–&gt;POSTROUTING 本机进程出去的报文： OUTPUT–&gt;POSTROUTING ipables语法：1iptables [-t table] command [match] [target/jump] command: 1234567891011121314151617-A, --append chain rule-specification 在所选择的链末添加规则。当源地址或目的地址是以名字而 不是ip地址的形式出现时，若这些名字可以被解析为多个地址，则这条规则会和所有可用的地址结合。-D, --delete chain rule-specification --delete chain rule-specification 从所选链中删除规则。有两种方法指定要删除的规则：一是 把规则完完整整地写出来，再就是指定规则在所选链中的序号（每条链的规则都各自从1被编号）。-I, --insert chain [rulenum] rule-specification 根据给出的规则序号向所选链中插入规则。如果序号为1， 规则会被插入链的头部，其实默认序号就是1。-R, --replace chain rulenum rule-specification 在所选中的链里指定的行上（每条链的规则都各自从1被编 号）替换规则。它主要的用处是试验不同的规则。当源地址或目的地址是以名字而不是ip地址的形式出现 时，若这些名字可以被解析为多个地址，则这条command会失败-F，--flush [chain] 清空所选的链。如果没有指定链，则清空指定表中的所有 链。如果什么都没有指定，就清空默认表所有的链。当然，也可以一条一条地删，但用这个command会快些。-Z, --zero [chain [rulenum]] 把指定链（如未指定，则认为是所有链）的所有计数器归 零。-N, --new-chain chain 新建一个用户自定义链，所用的名字不能和已有的链、target同名。-X, --delete-chain [chain] 删除指定的用户自定义链。这个链必须没有被引用，如果被 引用，在删除之前你必须删除或者替换与之有关的规则。如果没有给出参数，这条命令将会删除默认表所有 非内建的链。-P, --policy chain target 为链设置默认的target，这个target称作策略。所有不 符合规则的包都被强制使用这个策略。只有内建的链才可以使用规则。-L，--list [chain] 显示所选链的所有规则。如果没有指定链，则显示指定表中 的所有链。如果什么都没有指定，就显示默认表所有的链。与-L配合使用的-n 使输出中的IP地址和端口以数值的形式显示-v 显示详细信息--line-numbers 显示行号-x 使输出中的IP地址和端口以数值的形式显示 match：通用匹配1234-s 源地址 可以是ip地址或则 network/mask-d 目的地址 可以是ip地址或则 network/mask-i 进入网卡地址 例如：eth0-o 出去网卡地址 例如：eth0 扩展匹配隐式扩展1234567891011-p tcp --sport 源端口，也可以是端口范围，比如：1000-2000 --dport 目的端口，也可以是端口范围，比如：1000-2000 --tcp-flags --syn-p udp --sport 源端口，也可以是端口范围，比如：1000-2000 --dport 目的端口，也可以是端口范围，比如：1000-2000 -p icmp --icmp-type 常见的 0: echo-reply , 8: echo-request 显示扩展显式匹配必须用-m或–match装载，比如要使用状态匹配 就必须使用-m state。有些匹配还需要指定协议，有些就不需要，比如连接状态就不要 123456789101112131415-m state --state 有4种状态INVALID ： 意味着这个包没有已知的流或连接与之关 联，也可能是它包含的数据或包头有问题ESTABLISHED ： 一个已经建立的链接NEW ：建立一个新的链接RELATED ： 包正在建立一个新的连接，这个连接是和一个已建立的连接相关的-m multiport –source-port 源端口多端口匹配，最多可以指定15个端口，以英文逗号分 隔，注意没有空格。使用时必须有-p tcp或-p udp为前提条 件。 –destination-port 目的端口多端口匹配，使用方法和源端口多端口匹配一样， 唯一的区别是它匹配的是目的端口。 –port 同端口多端口匹配，意思就是它匹配的是那种源端口和目的 端口是同一个端口的包，比如：端口80到端口80的包，110到110的包等。使用方法和源端口多端口匹配一 样。-m mac –mac-source 基于包的MAC源地址匹配包，地址格式只能是XX:XX:XX:XX:XX:XX，当然它也可以用英文感叹号取反，如–mac- source ! 00:00:00:00:00:01，意思很简单了，就是除此之外的地址都可接受嘛。注意，因为 MAC addresses只用于Ethernet类型的网络，所以这个match只能用于Ethernet接 口。而且，它还只能在PREROUTING，FORWARD 和INPUT链里使用。 jump/target ACCEPT ++这个target不需要进一步的选项。只要一个数据包的匹配规范已经完全满足，并且我们指定ACCEPT作为target，规则就被接受，并且不会继续遍历当前链或者同一个表中的其他链。但是请注意，一个链中接受的数据包仍然可以穿过其他表中的链，并且仍然可以在这里DROP。这个target没有什么特别之处，也不需要，也没有可能为目标增加选项。要使用这个目标，我们只需指定-j ACCEPT。++ DROP DROP的目标就如字面意思一样，它会丢弃数据包，不会执行任何进一步的处理。完美匹配规则的数据包然后被丢弃将被阻止。请注意，此操作在某些情况下可能会产生不必要的影响，因为它可能会在任一主机上留下死穴。在可能的情况下，更好的解决方案是使用REJECT目标，尤其是当您想要阻止端口扫描程序获取太多信息时，例如在过滤的端口上等等。还要注意的是，如果一个数据包在子链上采取了DROP动作，那么数据包将不会在任何主链中或在任何其他表中被处理。换句话说，数据包完全死了。正如我们以前所看到的，目标不会向任何方向发送任何类型的信息，也不会向路由器等中介发送任何信息。 REJECT 拦阻该数据包，并返回数据包通知对方，可以返回的数据包有几个选择：ICMP port-unreachable、ICMP echo-reply 或是tcp-reset（这个数据包包会要求对方关闭联机），进行完此处理动作后，将不再比对其它规则，直接中断过滤程序。 范例如下： 1iptables -A INPUT -p TCP --dport 22 -j REJECT --reject-with ICMP echo-reply –reject-with参数说明拒绝的原因 SNAT 改写封包来源 IP 为某特定 IP 或 IP 范围，可以指定 port 对应的范围，进行完此处理动作后，将直接跳往下一个规则炼（mangle:postrouting） 1iptables -t nat -A POSTROUTING -p tcp -o eth0 -j SNAT --to-source 192.168.10.15-192.168.10.160:2100-3200 DNAT DNAT目标被用来做目标网络地址转换，这意味着它被用来重写数据包的目标IP地址。如果数据包匹配，这是规则的目标，则数据包以及同一个数据流中的所有后续数据包将被转换，然后路由到正确的设备，主机或网络。这个目标可以是非常有用的，例如，当你有一个主机在局域网内运行你的网络服务器，但没有真正的IP给它，将在互联网上工作。然后你可以告诉防火墙将所有的数据包转发到它自己的HTTP端口，然后转发到局域网内的真实网络服务器上。我们也可以指定一个完整的目标IP地址范围，DNAT机制将为每个流随机选择目的IP地址。因此，我们可以通过这样做来处理一种负载平衡。 请注意，DNAT目标仅在nat表中的PREROUTING和OUTPUT链中可用，以及从任何列出的链中调用的任何链。请注意，包含DNAT目标的链可能不能用于任何其他链，如POSTROUTING链。 参数： 123456--to-destinationiptables -t nat -A PREROUTING -p tcp -d 15.45.23.67 --dport 80 -j DNAT --to-destination 192.168.1.1-192.168.1.10--to-destination参数告诉DNAT机制，要指向的真是的目的地址或者地址范围。上面例子即是把目的地址为15.45.23.67端口为80的所有包，到转发到192.168.1.1到192.168.1.10的80端口 MASQUERADE 改写封包来源IP为防火墙的IP，可以指定port 对应的范围，进行完此处理动作后，直接跳往下一个规则链（mangle:postrouting）。这个功能与 SNAT 略有不同，当进行IP 伪装时，不需指定要伪装成哪个 IP，IP 会从网卡直接读取，当使用拨接连线时，IP 通常是由 ISP 公司的 DHCP服务器指派的，这个时候 MASQUERADE 特别有用。范例如下： 1iptables -t nat -A POSTROUTING -p TCP -j MASQUERADE --to-ports 21000-31000 REDIRECT 将封包重新导向到另一个端口（PNAT），进行完此处理动作后，将会继续比对其它规则。这个功能可以用来实作透明代理 或用来保护web 服务器。例如： 1iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT--to-ports 8081 参考：http://www.zsythink.net/archives/1199http://www.iptables.info/en/structure-of-iptables.html","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://blog.loveops.com/tags/iptables/"}]},{"title":"OSX无共享的密钥情况下连接基于L2TP协议的VPN","slug":"OSX无共享的密钥情况下连接基于L2TP协议的VPN","date":"2015-11-23T13:28:01.000Z","updated":"2017-12-01T14:08:46.130Z","comments":true,"path":"2015/11/23/OSX无共享的密钥情况下连接基于L2TP协议的VPN/","link":"","permalink":"http://blog.loveops.com/2015/11/23/OSX无共享的密钥情况下连接基于L2TP协议的VPN/","excerpt":"","text":"OSX需要配置的VPN（基于L2TP协议的IPSec），没有共享密钥的情况下，需要修改配置：在/etc/ppp目录下新建一个文件options : 1：cd /etc/ppp2：sudo vi options 写人如下内容： plugin L2TP.ppp l2tpnoipsec 保存后退出，最后把高级设置里面”通过VPN连接发送所有流量“钩上。 这时再点击连接就可以成功了","categories":[{"name":"mac","slug":"mac","permalink":"http://blog.loveops.com/categories/mac/"}],"tags":[{"name":"mac","slug":"mac","permalink":"http://blog.loveops.com/tags/mac/"}]},{"title":"sed学习笔记","slug":"sed学习笔记","date":"2015-11-22T14:23:37.000Z","updated":"2017-12-01T14:08:21.187Z","comments":true,"path":"2015/11/22/sed学习笔记/","link":"","permalink":"http://blog.loveops.com/2015/11/22/sed学习笔记/","excerpt":"","text":"sed 替换123456789101112131415161718192021222324252627282930➜ ~ cat a.txt The quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dog➜ ~ sed 's/dog/cat/' a.txt ##替换每行出现的第一处The quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy cat➜ ~ sed 's/dog/cat/2' a.txt ##替换每行出现的第二处➜ ~ sed 's/dog/cat/g' a.txt ##全局替换➜ ~ sed -n 's/dog/cat/p' a.txt ##-n选项禁止sed输出，-p输出替换掉行➜ ~ sed 's/dog/cat/w b.txt' a.txt ## w 保存输出到后面的文件➜ ~ sed '2s/dog/cat/' a.txt ##只替换第二行➜ ~ sed '2，3s/dog/cat/2' a.txt ##替换第二行和第三行➜ ~ sed '2，$s/dog/cat/2' a.txt ##替换第二行到最后一行➜ ~ sed '/dog/s/dog/cat/' a.txt ##先查出有dog的行，再进行替换➜ ~ sed '2，3&#123;s/dog/cat/ s/brown/grown&#125;' a.txt ##命令组合 sed 删除123456789101112131415161718192021222324252627➜ ~ cat a.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4.➜ ~ sed 'd' a.txt ## 删除文件内容➜ ~ sed '3d' a.txt ## 删除第三行This is line number 1.This is line number 2.This is line number 4.➜ ~ sed '2,3d' a.txt ## 删除第二和第三行This is line number 1.This is line number 4.➜ ~ sed '2,$d' a.txt ## 从第二行删掉到最后一行This is line number 1.➜ ~ sed '/number 1/d' a.txt ##找到number 1 的行，然后删除This is line number 2.This is line number 3.This is line number 4.➜ ~ sed '/1/,/3/d' a.txt ## 查到包含1的行和包含3之间的行，然后删除他们之间的行包括指定的行This is line number 4. 插入和附加1234567[root@zk1 ~]# echo \"Test Line 2\" | sed 'i\\Test Line 1' ##插入会出现数据流前面Test Line 1Test Line 2[root@zk1 ~]# echo \"Test Line 2\" | sed 'a\\Test Line 1' ##插入会出现数据流后面Test Line 2Test Line 1","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.loveops.com/categories/linux/"}],"tags":[{"name":"sed","slug":"sed","permalink":"http://blog.loveops.com/tags/sed/"}]}]}